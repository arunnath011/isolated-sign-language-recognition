{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUAFAfyIXJzj",
        "outputId": "d7994f75-d0ec-4d6d-9b7f-a539054eb213"
      },
      "id": "KUAFAfyIXJzj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.14.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e90f11039b41cd50927a090aee216f3d686ddb30ed0e591031e6f2a9fa8455c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.19.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# If you're running this in Google Colab or Jupyter Notebook, you can use this line to log in to WandB\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "57BwI4MFXOzb",
        "outputId": "d4ac39c5-bba7-4dcb-9b33-aa07a9cb67e8"
      },
      "id": "57BwI4MFXOzb",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrtWK4Wzfw6J",
        "outputId": "8fe1c4fa-5f42-42b6-d67f-be0d090c6534"
      },
      "id": "DrtWK4Wzfw6J",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK248WnDjlTm",
        "outputId": "82e985e1-d964-49b6-d612-01fc2a2a546d"
      },
      "id": "WK248WnDjlTm",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "856a4495-55f2-4dd0-a5a3-208bdd9af48d",
      "metadata": {
        "tags": [],
        "id": "856a4495-55f2-4dd0-a5a3-208bdd9af48d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# from itables import init_notebook_mode\n",
        "# init_notebook_mode(all_interactive=True, connected=True)\n",
        "\n",
        "import os\n",
        "\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import itertools\n",
        "# os.environ['TF_XLA_FLAGS'] = '--tf_xla_disable_xla_devices'\n",
        "import tensorflow as tf\n",
        "\n",
        "# #pytorch model\n",
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# import torch.nn as nn\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "from matplotlib import animation\n",
        "from pathlib import Path\n",
        "import IPython\n",
        "from IPython import display\n",
        "from IPython.core.display import display, HTML, Javascript\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "# import mediapipe as mp\n",
        "# from mediapipe.framework.formats import landmark_pb2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dba57b07-22aa-4ba7-a054-bd0c3715fc58",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dba57b07-22aa-4ba7-a054-bd0c3715fc58",
        "outputId": "8eaad617-5a1f-4e20-e188-177136e0a4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_disable_xla_devices'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #only run this if data_chunks doest exist\n",
        "# import numpy as np\n",
        "# import os\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def save_chunks(data, labels, chunk_size, output_dir):\n",
        "#     num_samples = len(data)\n",
        "#     num_chunks = (num_samples + chunk_size - 1) // chunk_size\n",
        "    \n",
        "#     if not os.path.exists(output_dir):\n",
        "#         os.makedirs(output_dir)\n",
        "    \n",
        "#     for i in tqdm(range(num_chunks), desc=\"Saving Chunks\"):\n",
        "#         start = i * chunk_size\n",
        "#         end = min((i + 1) * chunk_size, num_samples)\n",
        "        \n",
        "#         chunk_data = data[start:end]\n",
        "#         chunk_labels = labels[start:end]\n",
        "        \n",
        "#         np.save(os.path.join(output_dir, f'feature_data_{i}.npy'), chunk_data)\n",
        "#         np.save(os.path.join(output_dir, f'feature_labels_{i}.npy'), chunk_labels)\n",
        "\n",
        "# # Update the file paths to point to your Google Drive\n",
        "# drive_path = '/content/drive/My Drive/W251_Project/'\n",
        "\n",
        "# x_data = np.load(os.path.join(drive_path, 'feature_data.npy'))\n",
        "# y_data = np.load(os.path.join(drive_path, 'feature_labels.npy'))\n",
        "# chunk_size = 1000  # Adjust this value based on your memory constraints\n",
        "# output_dir = os.path.join(drive_path, 'data_chunks')\n",
        "\n",
        "# save_chunks(x_data, y_data, chunk_size, output_dir)\n"
      ],
      "metadata": {
        "id": "qYE9U8OVFLA4"
      },
      "id": "qYE9U8OVFLA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "480a95bb-9467-4699-8977-558880952dee",
      "metadata": {
        "tags": [],
        "id": "480a95bb-9467-4699-8977-558880952dee"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive/My Drive/W251_Project/'\n",
        "output_dir = os.path.join(drive_path, 'data_chunks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3706d987-b720-452c-b6d3-cc72cab301b9",
      "metadata": {
        "tags": [],
        "id": "3706d987-b720-452c-b6d3-cc72cab301b9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def data_generator(x_file_paths, y_file_paths):\n",
        "    for x_file_path, y_file_path in zip(x_file_paths, y_file_paths):\n",
        "        x_data = np.load(x_file_path)\n",
        "        y_data = np.load(y_file_path)\n",
        "\n",
        "        for x, y in zip(x_data, y_data):\n",
        "            yield np.transpose(x, (2, 0, 1)), y\n",
        "\n",
        "def create_dataset(x_file_paths, y_file_paths, batch_size):\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(x_file_paths, y_file_paths),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(3, 37, 192), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        "        )\n",
        "    )\n",
        "    dataset = dataset.shuffle(buffer_size=10000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "\n",
        "x_file_paths = sorted(glob(os.path.join(output_dir, 'feature_data_*.npy')))\n",
        "y_file_paths = sorted(glob(os.path.join(output_dir, 'feature_labels_*.npy')))\n",
        "file_paths = list(zip(x_file_paths, y_file_paths))\n",
        "\n",
        "train_file_paths, test_file_paths = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
        "train_x_file_paths, train_y_file_paths = zip(*train_file_paths)\n",
        "test_x_file_paths, test_y_file_paths = zip(*test_file_paths)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = create_dataset(train_x_file_paths, train_y_file_paths, batch_size)\n",
        "test_dataset = create_dataset(test_x_file_paths, test_y_file_paths, batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cb5ce4cb-aa89-4210-bbbc-076bab1a6295",
      "metadata": {
        "tags": [],
        "id": "cb5ce4cb-aa89-4210-bbbc-076bab1a6295"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, Flatten\n",
        "\n",
        "def transformer_encoder(input_shape, num_heads, ff_dim, dropout_rate):\n",
        "    inputs = Input(shape=tuple(input_shape))\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=input_shape[-1])(inputs, inputs)\n",
        "    attn_output = Dropout(dropout_rate)(attn_output)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
        "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
        "    ff_output = Dropout(dropout_rate)(ff_output)\n",
        "    ff_output = Dense(input_shape[-1])(ff_output)  # Add this line to match the dimensions\n",
        "    out2 = LayerNormalization(epsilon=1e-6)(out1 + ff_output)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=out2)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_spbt(input_shape, num_classes, num_heads, ff_dim, dropout_rate, num_encoders):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    encoder_input_shape = input_shape\n",
        "    for _ in range(num_encoders):\n",
        "        x = transformer_encoder(encoder_input_shape, num_heads, ff_dim, dropout_rate)(x)\n",
        "        encoder_input_shape = x.shape[1:]  # Update the input shape for the next encoder\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "01d7f88b-0ccf-4781-9038-e66442710b83",
      "metadata": {
        "tags": [],
        "id": "01d7f88b-0ccf-4781-9038-e66442710b83"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "def get_all_x_y_file_paths(x_file_pattern, y_file_pattern):\n",
        "    x_file_paths = sorted(glob(x_file_pattern))\n",
        "    y_file_paths = sorted(glob(y_file_pattern))\n",
        "    \n",
        "    if len(x_file_paths) != len(y_file_paths):\n",
        "        raise ValueError(\"The number of X and y files does not match.\")\n",
        "    \n",
        "    return list(zip(x_file_paths, y_file_paths))\n",
        "\n",
        "\n",
        "# Function to extract unique class count from the dataset\n",
        "def get_unique_class_count(dataset):\n",
        "    unique_classes = set()\n",
        "    for _, label in dataset.unbatch().as_numpy_iterator():\n",
        "        unique_classes.add(label)\n",
        "    return len(unique_classes)\n",
        "\n",
        "# Get all X and y file paths\n",
        "all_file_paths = get_all_x_y_file_paths(os.path.join(drive_path, 'data_chunks/feature_data_*.npy'), os.path.join(drive_path, 'data_chunks/feature_labels_*.npy'))\n",
        "\n",
        "\n",
        "# Split the file paths into training and testing sets\n",
        "train_file_paths, test_file_paths = train_test_split(all_file_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate X and y file paths for train and test datasets\n",
        "train_x_file_paths, train_y_file_paths = zip(*train_file_paths)\n",
        "test_x_file_paths, test_y_file_paths = zip(*test_file_paths)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = create_dataset(train_x_file_paths, train_y_file_paths, batch_size)\n",
        "test_dataset = create_dataset(test_x_file_paths, test_y_file_paths, batch_size)\n",
        "\n",
        "# Define model parameters\n",
        "input_dim = 192 * 3\n",
        "# num_classes = get_unique_class_count(train_dataset)\n",
        "num_classes = 250\n",
        "num_heads = 9\n",
        "ff_dim = 2048\n",
        "dropout_rate = 0.3\n",
        "num_encoders = 6\n",
        "epochs=20\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up WandB configuration\n",
        "config = dict(\n",
        "    batch_size=batch_size,\n",
        "    num_classes=num_classes,\n",
        "    num_heads=num_heads,\n",
        "    ff_dim=ff_dim,\n",
        "    dropout_rate=dropout_rate,\n",
        "    num_encoders=num_encoders,\n",
        ")\n",
        "\n",
        "# Initialize WandB run\n",
        "wandb.init(project='W251_finalproject', config=config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ndLyxrm4Zu3i",
        "outputId": "1f634300-8263-4d65-ae7d-5a801b78cef8"
      },
      "id": "ndLyxrm4Zu3i",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreynard011\u001b[0m (\u001b[33mw251-asl-fp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230414_023526-vr5x8c0d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/w251-asl-fp/W251_finalproject/runs/vr5x8c0d' target=\"_blank\">genial-shape-2</a></strong> to <a href='https://wandb.ai/w251-asl-fp/W251_finalproject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/w251-asl-fp/W251_finalproject' target=\"_blank\">https://wandb.ai/w251-asl-fp/W251_finalproject</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/w251-asl-fp/W251_finalproject/runs/vr5x8c0d' target=\"_blank\">https://wandb.ai/w251-asl-fp/W251_finalproject/runs/vr5x8c0d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/w251-asl-fp/W251_finalproject/runs/vr5x8c0d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa0b80578e0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class WarmUpCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "#     def __init__(self, initial_learning_rate, warmup_steps, total_steps, alpha=0.0):\n",
        "#         super(WarmUpCosineDecay, self).__init__()\n",
        "        \n",
        "#         self.initial_learning_rate = initial_learning_rate\n",
        "#         self.warmup_steps = warmup_steps\n",
        "#         self.total_steps = total_steps\n",
        "#         self.alpha = alpha\n",
        "    \n",
        "#     def __call__(self, step):\n",
        "#         step_float = tf.cast(step, tf.float32)\n",
        "#         warmup_steps_float = tf.cast(self.warmup_steps, tf.float32)\n",
        "\n",
        "#         def warmup_phase():\n",
        "#             return step_float * self.initial_learning_rate / warmup_steps_float\n",
        "        \n",
        "#         def cosine_decay_phase():\n",
        "#             decay_steps = tf.math.maximum(step_float - warmup_steps_float, 1)\n",
        "#             decay_steps = tf.math.minimum(decay_steps, self.total_steps)\n",
        "#             cosine_decay = 0.5 * (1 + tf.math.cos(tf.constant(np.pi) * decay_steps / self.total_steps))\n",
        "#             decayed = (1 - self.alpha) * cosine_decay + self.alpha\n",
        "#             return self.initial_learning_rate * decayed\n",
        "        \n",
        "#         return tf.cond(step_float < warmup_steps_float, warmup_phase, cosine_decay_phase)\n",
        "    \n",
        "#     def get_config(self):\n",
        "#         return {\n",
        "#             \"initial_learning_rate\": self.initial_learning_rate,\n",
        "#             \"warmup_steps\": self.warmup_steps,\n",
        "#             \"total_steps\": self.total_steps,\n",
        "#             \"alpha\": self.alpha,\n",
        "#         }\n",
        "\n",
        "# # Example usage:\n",
        "# initial_learning_rate = 0.001\n",
        "# warmup_steps = 1000\n",
        "# total_steps = 10000\n",
        "# alpha = 0.0001\n",
        "\n",
        "# lr_schedule = WarmUpCosineDecay(initial_learning_rate, warmup_steps, total_steps, alpha)\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# Compile and train your model\n",
        "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(train_dataset, epochs=epochs, validation_data=test_dataset, verbose=1)\n"
      ],
      "metadata": {
        "id": "EnUrTsiSfSQQ"
      },
      "id": "EnUrTsiSfSQQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "initial_learning_rate = 0.0001\n",
        "decay_steps = 32150\n",
        "alpha = 0.0001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps,\n",
        "    alpha=alpha\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# #model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jzu74rL0rIBz"
      },
      "id": "jzu74rL0rIBz",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fd6ad2ff-692d-4a7b-80dd-bd3e3717e4f4",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd6ad2ff-692d-4a7b-80dd-bd3e3717e4f4",
        "outputId": "f19b8f0a-ab53-4b56-a5a1-3c0689c5e9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3, 37, 192)]      0         \n",
            "                                                                 \n",
            " model (Functional)          (None, 3, 37, 192)        2121920   \n",
            "                                                                 \n",
            " model_1 (Functional)        (None, 3, 37, 192)        2121920   \n",
            "                                                                 \n",
            " model_2 (Functional)        (None, 3, 37, 192)        2121920   \n",
            "                                                                 \n",
            " model_3 (Functional)        (None, 3, 37, 192)        2121920   \n",
            "                                                                 \n",
            " model_4 (Functional)        (None, 3, 37, 192)        2121920   \n",
            "                                                                 \n",
            " model_5 (Functional)        (None, 3, 37, 192)        2121920   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 21312)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 250)               5328250   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,059,770\n",
            "Trainable params: 18,059,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_spbt(input_shape=(3, 37, 192), num_classes=num_classes, num_heads=num_heads, ff_dim=ff_dim, dropout_rate=dropout_rate, num_encoders=num_encoders)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1d911fe3-ddd6-48ef-9515-e22b36b1ee51",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d911fe3-ddd6-48ef-9515-e22b36b1ee51",
        "outputId": "ecab4bd4-02cc-4e8e-9bd3-eedbf159fd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "   1179/Unknown - 152s 76ms/step - loss: 4.2371 - accuracy: 0.1457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 72). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230414_023526-vr5x8c0d/files/model-best)... Done. 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1180/1180 [==============================] - 197s 114ms/step - loss: 4.2367 - accuracy: 0.1458 - val_loss: 2.7822 - val_accuracy: 0.3671\n",
            "Epoch 2/20\n",
            "1179/1180 [============================>.] - ETA: 0s - loss: 2.2962 - accuracy: 0.4479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 72). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230414_023526-vr5x8c0d/files/model-best)... Done. 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1180/1180 [==============================] - 98s 79ms/step - loss: 2.2960 - accuracy: 0.4479 - val_loss: 2.0240 - val_accuracy: 0.5168\n",
            "Epoch 3/20\n",
            "1179/1180 [============================>.] - ETA: 0s - loss: 1.7108 - accuracy: 0.5745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 72). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230414_023526-vr5x8c0d/files/model-best)... Done. 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1180/1180 [==============================] - 95s 77ms/step - loss: 1.7108 - accuracy: 0.5745 - val_loss: 1.7247 - val_accuracy: 0.5888\n",
            "Epoch 4/20\n",
            "1179/1180 [============================>.] - ETA: 0s - loss: 1.3641 - accuracy: 0.6530"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 72). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230414_023526-vr5x8c0d/files/model-best)... Done. 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1180/1180 [==============================] - 95s 77ms/step - loss: 1.3642 - accuracy: 0.6530 - val_loss: 1.5620 - val_accuracy: 0.6210\n",
            "Epoch 5/20\n",
            "1179/1180 [============================>.] - ETA: 0s - loss: 1.1088 - accuracy: 0.7125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 72). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230414_023526-vr5x8c0d/files/model-best)... Done. 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1180/1180 [==============================] - 95s 77ms/step - loss: 1.1090 - accuracy: 0.7125 - val_loss: 1.4757 - val_accuracy: 0.6470\n",
            "Epoch 6/20\n",
            "1179/1180 [============================>.] - ETA: 0s - loss: 0.9184 - accuracy: 0.7575"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 72). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230414_023526-vr5x8c0d/files/model-best)... Done. 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1180/1180 [==============================] - 96s 78ms/step - loss: 0.9184 - accuracy: 0.7575 - val_loss: 1.4402 - val_accuracy: 0.6657\n",
            "Epoch 7/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.7526 - accuracy: 0.7963 - val_loss: 1.5181 - val_accuracy: 0.6664\n",
            "Epoch 8/20\n",
            "1180/1180 [==============================] - 80s 65ms/step - loss: 0.6149 - accuracy: 0.8326 - val_loss: 1.4729 - val_accuracy: 0.6807\n",
            "Epoch 9/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.4952 - accuracy: 0.8625 - val_loss: 1.4900 - val_accuracy: 0.6925\n",
            "Epoch 10/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.3963 - accuracy: 0.8881 - val_loss: 1.5059 - val_accuracy: 0.6965\n",
            "Epoch 11/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.3123 - accuracy: 0.9110 - val_loss: 1.5118 - val_accuracy: 0.7021\n",
            "Epoch 12/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.2417 - accuracy: 0.9302 - val_loss: 1.5828 - val_accuracy: 0.6919\n",
            "Epoch 13/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.1875 - accuracy: 0.9459 - val_loss: 1.5797 - val_accuracy: 0.7042\n",
            "Epoch 14/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.1398 - accuracy: 0.9600 - val_loss: 1.6316 - val_accuracy: 0.7033\n",
            "Epoch 15/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.1055 - accuracy: 0.9714 - val_loss: 1.6431 - val_accuracy: 0.7127\n",
            "Epoch 16/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.0816 - accuracy: 0.9779 - val_loss: 1.6708 - val_accuracy: 0.7112\n",
            "Epoch 17/20\n",
            "1180/1180 [==============================] - 81s 65ms/step - loss: 0.0581 - accuracy: 0.9853 - val_loss: 1.6903 - val_accuracy: 0.7200\n",
            "Epoch 18/20\n",
            "1180/1180 [==============================] - 83s 66ms/step - loss: 0.0426 - accuracy: 0.9899 - val_loss: 1.6855 - val_accuracy: 0.7209\n",
            "Epoch 19/20\n",
            "1180/1180 [==============================] - 82s 66ms/step - loss: 0.0315 - accuracy: 0.9929 - val_loss: 1.7283 - val_accuracy: 0.7236\n",
            "Epoch 20/20\n",
            "1180/1180 [==============================] - 82s 66ms/step - loss: 0.0219 - accuracy: 0.9957 - val_loss: 1.7320 - val_accuracy: 0.7269\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history=model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_dataset,verbose=1,\n",
        "    callbacks=[WandbCallback()]\n",
        ")\n",
        "\n",
        "\n",
        "# history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6613a487-d7c0-4861-89b6-20421eba7525",
      "metadata": {
        "tags": [],
        "id": "6613a487-d7c0-4861-89b6-20421eba7525",
        "outputId": "49888bc1-2d83-4bb4-ff9f-edd903d3434e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54702708-0da3-4248-8444-a720ead2f722",
      "metadata": {
        "id": "54702708-0da3-4248-8444-a720ead2f722"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4508e874",
   "metadata": {
    "papermill": {
     "duration": 0.016723,
     "end_time": "2023-03-27T13:49:08.191855",
     "exception": false,
     "start_time": "2023-03-27T13:49:08.175132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hello Fellow Kagglers,\n",
    "\n",
    "This notebook demonstrates the data processing and training process in Tensorflow.\n",
    "\n",
    "I am excited about this competition, because my Master Thesis was on sign language recognition.\n",
    "\n",
    "**Data Processing**\n",
    "\n",
    "Only lips, hands and arm pose coordinates are used.\n",
    "\n",
    "A custom Tensorflow layer handles the data processing. In short, it filters all frames without coordinates for the hands and downsamples the input to 32 frames if it is too long.\n",
    "\n",
    "**Model**\n",
    "\n",
    "A transformer based model is used. The embedding layer makes an ambedding per landmark(lips/left hand/right hand/arm pose) and merges these embedding with fully connected layers. The transformer consists of just 2 blocks with a simple mean pooling and fully connected layers for classification.\n",
    "\n",
    "\n",
    "**V2**\n",
    "\n",
    "* Learnable attention weights for each landmark\n",
    "* Removed layer normalisation in embedding to prevent double layer normalisation at the end of embedding and start of transformer\n",
    "* Removed additional fully connected layer in head before classification layer\n",
    "\n",
    "**V3**\n",
    "\n",
    "* Using all data for training\n",
    "* Increased final embedding size 384 -> 512\n",
    "* Added 10% dropout in classification layer\n",
    "* Increased number of epoch 50 -> 100\n",
    "* Number of transformer heads 8 -> 4\n",
    "\n",
    "If you have any feedback or questions, please feel free to leave a comment.\n",
    "\n",
    "Expect updates in the coming weeks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf87375-3103-443d-9e2c-dacd6b4b35a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow_addons\n",
    "# !pip install -q wandb\n",
    "# !pip install -q pyarrow\n",
    "# !pip install -q fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b76172",
   "metadata": {
    "papermill": {
     "duration": 8.299082,
     "end_time": "2023-03-27T13:49:16.506249",
     "exception": false,
     "start_time": "2023-03-27T13:49:08.207167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 03:10:54.686107: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 03:10:55.318877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "\n",
    "import layers\n",
    "from utils.Utils import print_shape_dtype, pd_read_s3_parquet, upload_file, get_dataset_partitions_tf \n",
    "from layers.PreprocessLayerV2 import PreprocessLayerV2\n",
    "\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import boto3\n",
    "import io\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f10409-8ef5-46dc-9fb8-42d556084308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6783996",
   "metadata": {
    "papermill": {
     "duration": 0.014594,
     "end_time": "2023-03-27T13:49:16.606639",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.592045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bdb3a65-55b9-40d5-b6c5-28144c027589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf792f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeanna-emery\u001b[0m (\u001b[33mw251-asl-fp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Weights and Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100e9f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f2820ddbff44e1ae6d72c76a5ed354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669213583372765, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/isolated-sign-language-recognition/modeling/wandb/run-20230416_220933-9hoj8usk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk' target=\"_blank\">divine-hill-2</a></strong> to <a href='https://wandb.ai/w251-asl-fp/w251-demery1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/w251-asl-fp/w251-demery1' target=\"_blank\">https://wandb.ai/w251-asl-fp/w251-demery1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk' target=\"_blank\">https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/w251-asl-fp/w251-demery1/runs/9hoj8usk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc2d1b0aa40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR = './logs/fit'\n",
    "wandb.tensorboard.patch(root_logdir= LOG_DIR)\n",
    "wandb.init(project='w251-GISLR-Final', \n",
    "           config=config,\n",
    "          sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09a2354",
   "metadata": {
    "papermill": {
     "duration": 0.024174,
     "end_time": "2023-03-27T13:49:16.646131",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.621957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_VAL = True\n",
    "\n",
    "DIM_NAMES = ['x', 'y']\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6a97b",
   "metadata": {
    "papermill": {
     "duration": 0.023506,
     "end_time": "2023-03-27T13:50:42.146814",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.123308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056ca475-bca9-445b-a5b2-739e07cfcb42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867a7a48-171b-4456-81ac-01e4cd4c5049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "AWS_S3_BUCKET_2 = \"asl-project-bucket2\"\n",
    "\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd018bc-0b73-47d1-a657-c85a7924a5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (94477, 38, 454), dtype: float32\n",
      "y shape: (94477,), dtype: int32\n",
      "NON_EMPTY_FRAME_IDXS shape: (94477, 38), dtype: float32\n",
      "# NaN Values X: 0\n"
     ]
    }
   ],
   "source": [
    "# data_version = config[\"DATA_VERSION\"]\n",
    "\n",
    "data_version = 6\n",
    "\n",
    "\n",
    "X = s3_client.get_object(Bucket=AWS_S3_BUCKET_2, Key=f'processed-data/v{data_version}/X.npy')\n",
    "X = np.load(io.BytesIO(X['Body'].read()))\n",
    "\n",
    "y = s3_client.get_object(Bucket=AWS_S3_BUCKET_2, Key=f'processed-data/v{data_version}/y.npy')\n",
    "y = np.load(io.BytesIO(y['Body'].read()))\n",
    "\n",
    "NON_EMPTY_FRAME_IDXS = s3_client.get_object(Bucket=AWS_S3_BUCKET_2, Key=f'processed-data/v{data_version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "NON_EMPTY_FRAME_IDXS = np.load(io.BytesIO(NON_EMPTY_FRAME_IDXS['Body'].read()))\n",
    "    \n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f5d751e-ffa1-4a1e-b4fe-24994aa7a5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Read in from local filesystem instead since reading from S3 takes too long. \n",
    "\n",
    "# X = np.load(\"./X.npy\")\n",
    "# y = np.load(\"./y.npy\")\n",
    "# NON_EMPTY_FRAME_IDXS = np.load(\"./NON_EMPTY_FRAME_IDXS.npy\")\n",
    "\n",
    "# print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "# print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429150ec-4fd3-472d-a447-3198e1327673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_sample(X, y, NON_EMPTY_FRAME_IDXS, batch_size=config[\"BATCH_SIZE\"]): #TODO: Change this in config.\n",
    "    \n",
    "#     # Arrays to store batch in\n",
    "#     X_batch = np.zeros([batch_size, config[\"INPUT_SIZE\"], config[\"N_COLS\"], config[\"N_DIMS\"]], dtype=np.float32)\n",
    "#     y_batch = np.arange(0, batch_size, dtype=np.int32)\n",
    "#     non_empty_frame_idxs_batch = np.zeros([batch_size, config[\"INPUT_SIZE\"]], dtype=np.float32)\n",
    "    \n",
    "#     # Dictionary mapping ordinally encoded sign to corresponding sample indices\n",
    "#     CLASS2IDXS = {}\n",
    "#     for i in range(config[\"NUM_CLASSES\"]):\n",
    "#         CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n",
    "            \n",
    "#     while True:\n",
    "#         # Fill batch arrays\n",
    "#         for i in range(config[\"NUM_CLASSES\"]):\n",
    "#             idxs = np.random.choice(CLASS2IDXS[i], n)\n",
    "#             X_batch[i*n:(i+1)*n] = X[idxs]\n",
    "#             non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n",
    "        \n",
    "#         yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d776d9f-553a-483b-ae3e-6d819fc6f8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # LIPS\n",
    "# LIPS_MEAN_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "# LIPS_MEAN_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "# LIPS_STD_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "# LIPS_STD_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(15, config[\"N_DIMS\"]*6))\n",
    "   \n",
    "# for col, ll in enumerate(tqdm( np.transpose(X[:,:,LIPS_IDXS], [2,3,0,1]).reshape([LIPS_IDXS.size, config[\"N_DIMS\"], -1]) )):\n",
    "#     for dim, l in enumerate(ll):\n",
    "#         v = l[np.nonzero(l)]\n",
    "#         if dim == 0: # X\n",
    "#             LIPS_MEAN_X[col] = v.mean()\n",
    "#             LIPS_STD_X[col] = v.std()\n",
    "#         if dim == 1: # Y\n",
    "#             LIPS_MEAN_Y[col] = v.mean()\n",
    "#             LIPS_STD_Y[col] = v.std()\n",
    "        \n",
    "#         axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "        \n",
    "# for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "#     ax.set_title(f'Lips {dim_name.upper()} Dimension', size=24)\n",
    "#     ax.tick_params(axis='x', labelsize=8)\n",
    "#     ax.grid(axis='y')\n",
    "\n",
    "# plt.subplots_adjust(hspace=0.50)\n",
    "# plt.show()\n",
    "\n",
    "# LIPS_MEAN = np.array([LIPS_MEAN_X, LIPS_MEAN_Y]).T\n",
    "# LIPS_STD = np.array([LIPS_STD_X, LIPS_STD_Y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "783dbd1e-d5b0-4d00-90c5-f91389b16843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # LEFT HAND\n",
    "# LEFT_HANDS_MEAN_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "# LEFT_HANDS_MEAN_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "# LEFT_HANDS_STD_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "# LEFT_HANDS_STD_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "# # RIGHT HAND\n",
    "# RIGHT_HANDS_MEAN_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "# RIGHT_HANDS_MEAN_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "# RIGHT_HANDS_STD_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "# RIGHT_HANDS_STD_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(15, config[\"N_DIMS\"]*6))\n",
    "   \n",
    "# for col, ll in enumerate(tqdm( np.transpose(X[:,:,HAND_IDXS], [2,3,0,1]).reshape([HAND_IDXS.size, config[\"N_DIMS\"], -1]) )):\n",
    "#     for dim, l in enumerate(ll):\n",
    "#         v = l[np.nonzero(l)]\n",
    "#         if dim == 0: # X\n",
    "#             if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
    "#                 LEFT_HANDS_MEAN_X[col] = v.mean()\n",
    "#                 LEFT_HANDS_STD_X[col] = v.std()\n",
    "#             else:\n",
    "#                 RIGHT_HANDS_MEAN_X[col - LEFT_HAND_IDXS.size] = v.mean()\n",
    "#                 RIGHT_HANDS_STD_X[col - LEFT_HAND_IDXS.size] = v.std()\n",
    "#         if dim == 1: # Y\n",
    "#             if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
    "#                 LEFT_HANDS_MEAN_Y[col] = v.mean()\n",
    "#                 LEFT_HANDS_STD_Y[col] = v.std()\n",
    "#             else: # RIGHT HAND\n",
    "#                 RIGHT_HANDS_MEAN_Y[col - LEFT_HAND_IDXS.size] = v.mean()\n",
    "#                 RIGHT_HANDS_STD_Y[col - LEFT_HAND_IDXS.size] = v.std()\n",
    "        \n",
    "#         axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "        \n",
    "# for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "#     ax.set_title(f'Hands {dim_name.upper()} Dimension', size=24)\n",
    "#     ax.tick_params(axis='x', labelsize=8)\n",
    "#     ax.grid(axis='y')\n",
    "\n",
    "# plt.subplots_adjust(hspace=0.50)\n",
    "# plt.show()\n",
    "\n",
    "# LEFT_HANDS_MEAN = np.array([LEFT_HANDS_MEAN_X, LEFT_HANDS_MEAN_Y]).T\n",
    "# LEFT_HANDS_STD = np.array([LEFT_HANDS_STD_X, LEFT_HANDS_STD_Y]).T\n",
    "# RIGHT_HANDS_MEAN = np.array([RIGHT_HANDS_MEAN_X, RIGHT_HANDS_MEAN_Y]).T\n",
    "# RIGHT_HANDS_STD = np.array([RIGHT_HANDS_STD_X, RIGHT_HANDS_STD_Y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa676cb1-f20c-4314-8430-c435e493d7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # POSE\n",
    "# POSE_MEAN_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "# POSE_MEAN_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "# POSE_STD_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "# POSE_STD_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(15, config[\"N_DIMS\"]*6))\n",
    "   \n",
    "# for col, ll in enumerate(tqdm( np.transpose(X[:,:,POSE_IDXS], [2,3,0,1]).reshape([POSE_IDXS.size, config[\"N_DIMS\"], -1]) )):\n",
    "#     for dim, l in enumerate(ll):\n",
    "#         v = l[np.nonzero(l)]\n",
    "#         if dim == 0: # X\n",
    "#             POSE_MEAN_X[col] = v.mean()\n",
    "#             POSE_STD_X[col] = v.std()\n",
    "#         if dim == 1: # Y\n",
    "#             POSE_MEAN_Y[col] = v.mean()\n",
    "#             POSE_STD_Y[col] = v.std()\n",
    "        \n",
    "#         axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "        \n",
    "# for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "#     ax.set_title(f'Pose {dim_name.upper()} Dimension', size=24)\n",
    "#     ax.tick_params(axis='x', labelsize=8)\n",
    "#     ax.grid(axis='y')\n",
    "\n",
    "# plt.subplots_adjust(hspace=0.50)\n",
    "# plt.show()\n",
    "\n",
    "# POSE_MEAN = np.array([POSE_MEAN_X, POSE_MEAN_Y]).T\n",
    "# POSE_STD = np.array([POSE_STD_X, POSE_STD_Y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db809f",
   "metadata": {
    "papermill": {
     "duration": 0.027558,
     "end_time": "2023-03-27T13:50:42.374837",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.347279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad349c1a",
   "metadata": {
    "papermill": {
     "duration": 0.039339,
     "end_time": "2023-03-27T13:50:42.441202",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.401863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRANSFORMERV1 = True\n",
    "\n",
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "FACE_UNITS = 384\n",
    "HANDS_UNITS = 384\n",
    "POSE_UNITS = 384\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = 512\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = 2\n",
    "MLP_RATIO = 2\n",
    "NUM_HEADS = 4\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = 0.0\n",
    "MLP_DROPOUT_RATIO = 0.05\n",
    "CLASSIFIER_DROPOUT_RATIO = 0.1\n",
    "\n",
    "# Initiailizers\n",
    "# INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "# INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "ACTIVATION = tf.keras.activations.gelu\n",
    "\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a522f03-d5fb-4a49-a45d-936f38ab8021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FACE_IDXS = [0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467]\n",
    "POSE_IDXS = np.arange(489, 514)\n",
    "LEFT_HAND_IDXS = np.arange(468, 489)\n",
    "RIGHT_HAND_IDXS = np.arange(522, 543)\n",
    "\n",
    "# All landmarks that are used for modeling. \n",
    "LANDMARK_IDXS = np.concatenate((FACE_IDXS, POSE_IDXS, LEFT_HAND_IDXS, RIGHT_HAND_IDXS))\n",
    "\n",
    "# Indicies after landmarks have been filtered. \n",
    "FACE_START = 0\n",
    "LEFT_HAND_START = len(FACE_IDXS)\n",
    "POSE_START = LEFT_HAND_START + len(LEFT_HAND_IDXS)\n",
    "RIGHT_HAND_START = POSE_START + len(POSE_IDXS)\n",
    "\n",
    "# Length of landmarks.\n",
    "FACE_LEN = len(FACE_IDXS)\n",
    "POSE_LEN = POSE_IDXS.size\n",
    "LEFT_HAND_LEN = LEFT_HAND_IDXS.size\n",
    "RIGHT_HAND_LEN = RIGHT_HAND_IDXS.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ca5c18",
   "metadata": {
    "papermill": {
     "duration": 0.043124,
     "end_time": "2023-03-27T13:50:42.896486",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.853362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=tf.float32, name='FRAMES')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([config[\"INPUT_SIZE\"]], dtype=tf.float32, name='NON_EMPTY_FRAME_IDXS')\n",
    "    \n",
    "    # Attention Mask\n",
    "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=2)\n",
    "    \n",
    "    # Slice out face indicies       \n",
    "    face = tf.slice(frames, [0, 0, FACE_START], [-1, config[\"INPUT_SIZE\"], FACE_LEN * 2])\n",
    "    # face = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], FACE_LEN*2])\n",
    "    \n",
    "     # Slice out left_hand indicies\n",
    "    left_hand = tf.slice(frames, [0, 0, LEFT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], LEFT_HAND_LEN * 2])\n",
    "    # left_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(LEFT_HAND_IDXS)*2])\n",
    "\n",
    "    # Slice out pose indicies\n",
    "    pose = tf.slice(frames, [0, 0, POSE_START * 2], [-1, config[\"INPUT_SIZE\"], POSE_LEN * 2])\n",
    "    # pose = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(POSE_IDXS)*2])\n",
    "\n",
    "    # Slice out right_hand indicies\n",
    "    right_hand = tf.slice(frames, [0, 0, RIGHT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], RIGHT_HAND_LEN * 2])\n",
    "    # right_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(RIGHT_HAND_IDXS)*2])\n",
    "    \n",
    "    embedding_layer = layers.Embedding(config[\"INPUT_SIZE\"], FACE_UNITS, HANDS_UNITS, POSE_UNITS, UNITS, ACTIVATION)\n",
    "    x = embedding_layer(face, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
    "    transformer_input_shape = x.shape\n",
    "    \n",
    "    if (TRANSFORMERV1):\n",
    "        # Encoder Transformer Blocks\n",
    "        transformer_layer = layers.Transformer(NUM_BLOCKS, LAYER_NORM_EPS, UNITS, MLP_RATIO, MLP_DROPOUT_RATIO, ACTIVATION)\n",
    "        x = transformer_layer(x, mask)\n",
    "    else:\n",
    "        encoder_input_shape = transformer_input_shape\n",
    "        for _ in range(NUM_BLOCKS):\n",
    "            x = layers.TransformerV2(encoder_input_shape, NUM_HEADS, UNITS, MLP_DROPOUT_RATIO, LAYER_NORM_EPS)(x)\n",
    "            encoder_input_shape = x.shape[1:]  # Update the input shape for the next encoder\n",
    "    \n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classifier Dropout\n",
    "    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(config[\"NUM_CLASSES\"], activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Simple Categorical Crossentropy Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=config[\"LEARNING_RATE\"], weight_decay=config[\"WEIGHT_DECAY\"])\n",
    "    \n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fab16c-ad10-4575-bf6e-ccf907827ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 03:13:34.418405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.439669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.441885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.445298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.447250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.449015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.957064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.958128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.958903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-17 03:13:34.959629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20561 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "2023-04-17 03:13:34.961685: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "with tf.device('CPU'):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({\"FRAMES\": X, \"NON_EMPTY_FRAME_IDXS\": NON_EMPTY_FRAME_IDXS}, y))\n",
    "    \n",
    "# with tf.device('CPU'):\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices(({\"FRAMES\": X[:100], \"NON_EMPTY_FRAME_IDXS\": NON_EMPTY_FRAME_IDXS[:100]}, y[:100]))\n",
    "\n",
    "train, validation, test = get_dataset_partitions_tf(dataset, X.shape[0], train_split=0.8, val_split=0.1, \n",
    "                                                test_split=0.1, shuffle=True, shuffle_size=10000, seed=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27aa2083-7d68-4b75-abcf-507c57843739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inputs = X[:2]\n",
    "# attn_output = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "# attn_output = tf.keras.layers.Dropout(.10)(attn_output)\n",
    "# out1 = tf.keras.layers.LayerNormalization(epsilon=.000001)(inputs + attn_output)\n",
    "# ff_output = tf.keras.layers.Dense(512, activation='relu')(out1)\n",
    "# ff_output = tf.keras.layers.Dropout(.10)(ff_output)\n",
    "# ff_output = tf.keras.layers.Dense(inputs.shape[-1])(ff_output)  # Add this line to match the dimensions\n",
    "# out2 = tf.keras.layers.LayerNormalization(epsilon=.000001)(out1 + ff_output)\n",
    "# out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d2355b-115e-43ce-b5ae-d8a4d590b1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "# model.evaluate(dataset.batch(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb430b06",
   "metadata": {
    "papermill": {
     "duration": 0.371176,
     "end_time": "2023-03-27T13:50:48.643574",
     "exception": false,
     "start_time": "2023-03-27T13:50:48.272398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Plot model summary\n",
    "# model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4739d7f8",
   "metadata": {
    "papermill": {
     "duration": 0.828156,
     "end_time": "2023-03-27T13:50:49.508884",
     "exception": false,
     "start_time": "2023-03-27T13:50:48.680728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a152a4b",
   "metadata": {
    "papermill": {
     "duration": 0.038958,
     "end_time": "2023-03-27T13:50:49.587880",
     "exception": false,
     "start_time": "2023-03-27T13:50:49.548922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba2f93f5",
   "metadata": {
    "papermill": {
     "duration": 13.677198,
     "end_time": "2023-03-27T13:51:03.302900",
     "exception": false,
     "start_time": "2023-03-27T13:50:49.625702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N = 32\n",
    "# y_pred = model.predict(dummy_dataset, verbose=VERBOSE, steps=N).flatten()\n",
    "\n",
    "# plt.figure(figsize=(12,5))\n",
    "# plt.title(f'Softmax Output Initialized Model | Âµ={y_pred.mean():.3f}, Ïƒ={y_pred.std():.3f}', pad=25)\n",
    "# pd.Series(y_pred).plot(kind='hist', bins=128, label='Class Probability')\n",
    "# plt.xlim(0, max(y_pred) * 1.1)\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9779f",
   "metadata": {
    "papermill": {
     "duration": 0.038802,
     "end_time": "2023-03-27T13:51:03.381634",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.342832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "490cdcb6",
   "metadata": {
    "papermill": {
     "duration": 0.049275,
     "end_time": "2023-03-27T13:51:03.469275",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.420000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=config[\"N_EPOCHS\"], warm_method='log'):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        if warm_method == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6401784",
   "metadata": {
    "papermill": {
     "duration": 0.738209,
     "end_time": "2023-03-27T13:51:04.245805",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.507596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lr_schedule(lr_schedule, epochs):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot([None] + lr_schedule + [None])\n",
    "    # X Labels\n",
    "    x = np.arange(1, epochs + 1)\n",
    "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
    "    plt.xlim([1, epochs])\n",
    "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
    "    \n",
    "    # Increase y-limit for better readability\n",
    "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
    "    \n",
    "    # Title\n",
    "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
    "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
    "    \n",
    "    # Plot Learning Rates\n",
    "    for x, val in enumerate(lr_schedule):\n",
    "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
    "            if x < len(lr_schedule) - 1:\n",
    "                if lr_schedule[x - 1] < val:\n",
    "                    ha = 'right'\n",
    "                else:\n",
    "                    ha = 'left'\n",
    "            elif x == 0:\n",
    "                ha = 'right'\n",
    "            else:\n",
    "                ha = 'left'\n",
    "            plt.plot(x + 1, val, 'o', color='black');\n",
    "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
    "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
    "    \n",
    "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
    "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=config[\"N_WARMUP_EPOCHS\"], lr_max=config[\"LEARNING_RATE\"], num_cycles=0.50) for step in range(config[\"N_EPOCHS\"])]\n",
    "# Plot Learning Rate Schedule\n",
    "# plot_lr_schedule(LR_SCHEDULE, epochs=config[\"N_EPOCHS\"])\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bded92c-bc32-4ffc-b79d-e3bd8029d177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom callback to update weight decay with learning rate\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, wd_ratio=config['WD_RATIO']):\n",
    "        self.step_counter = 0\n",
    "        self.wd_ratio = wd_ratio\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
    "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e550a63",
   "metadata": {
    "papermill": {
     "duration": 0.040725,
     "end_time": "2023-03-27T13:51:04.330003",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.289278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Decay Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9eca4",
   "metadata": {
    "papermill": {
     "duration": 0.040431,
     "end_time": "2023-03-27T13:51:04.501979",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.461548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "742d7ae0",
   "metadata": {
    "papermill": {
     "duration": 6.727547,
     "end_time": "2023-03-27T13:51:11.270673",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.543126",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%timeit -n 100\n",
    "# # Verify model prediction is <<<100ms\n",
    "# model.predict_on_batch({ 'FRAMES': X[:1], 'NON_EMPTY_FRAME_IDXS': NON_EMPTY_FRAME_IDXS[:1] })\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97185a5",
   "metadata": {
    "papermill": {
     "duration": 0.040685,
     "end_time": "2023-03-27T13:51:11.352812",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.312127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909bf11",
   "metadata": {
    "papermill": {
     "duration": 0.040524,
     "end_time": "2023-03-27T13:51:11.789064",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.748540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd83cf56",
   "metadata": {
    "papermill": {
     "duration": 2852.852405,
     "end_time": "2023-03-27T14:38:44.682355",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.829950",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " NON_EMPTY_FRAME_IDXS (InputLay  [(None, 38)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " FRAMES (InputLayer)            [(None, 38, 454)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, 38)          0           ['NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.slice (TFOpLambda)          (None, 38, 320)      0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_1 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_3 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_2 (TFOpLambda)        (None, 38, 50)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 38)           0           ['tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 38, 512)      1244420     ['tf.slice[0][0]',               \n",
      "                                                                  'tf.slice_1[0][0]',             \n",
      "                                                                  'tf.slice_3[0][0]',             \n",
      "                                                                  'tf.slice_2[0][0]',             \n",
      "                                                                  'NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 38, 1)        0           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " transformer (Transformer)      (None, 38, 512)      4205568     ['embedding[0][0]',              \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 38, 512)      0           ['transformer[0][0]',            \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 512)         0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None, 1)           0           ['tf.expand_dims[0][0]']         \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 512)          0           ['tf.math.reduce_sum[0][0]',     \n",
      "                                                                  'tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          128250      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,578,238\n",
      "Trainable params: 5,578,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 22:11:22.472479: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n",
      "2023-04-16 22:11:23.416890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-16 22:11:25.991129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [94477,38]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 22:11:27.083142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - ETA: 0s - loss: 5.1806 - acc: 0.0394 - top_5_acc: 0.1252 - top_10_acc: 0.1931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 22:11:55.685621: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n",
      "2023-04-16 22:11:59.153339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [94477]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 36s 237ms/step - loss: 5.1806 - acc: 0.0394 - top_5_acc: 0.1252 - top_10_acc: 0.1931 - val_loss: 3.8708 - val_acc: 0.1648 - val_top_5_acc: 0.4054 - val_top_10_acc: 0.5355 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 9.998903417374228e-05.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 2/150\n",
      "148/148 [==============================] - 31s 212ms/step - loss: 3.2153 - acc: 0.2759 - top_5_acc: 0.5555 - top_10_acc: 0.6738 - val_loss: 2.4596 - val_acc: 0.4366 - val_top_5_acc: 0.7117 - val_top_10_acc: 0.7995 - lr: 9.9989e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 9.995614150494293e-05.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 3/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 2.3532 - acc: 0.4451 - top_5_acc: 0.7256 - top_10_acc: 0.8104 - val_loss: 1.9618 - val_acc: 0.5433 - val_top_5_acc: 0.7890 - val_top_10_acc: 0.8543 - lr: 9.9956e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 9.990133642141359e-05.\n",
      "learning rate: 9.99e-05, weight decay: 5.00e-06\n",
      "Epoch 4/150\n",
      "148/148 [==============================] - 32s 212ms/step - loss: 1.9524 - acc: 0.5301 - top_5_acc: 0.7897 - top_10_acc: 0.8570 - val_loss: 1.7126 - val_acc: 0.5953 - val_top_5_acc: 0.8243 - val_top_10_acc: 0.8786 - lr: 9.9901e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 9.982464296247522e-05.\n",
      "learning rate: 9.98e-05, weight decay: 4.99e-06\n",
      "Epoch 5/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.7040 - acc: 0.5853 - top_5_acc: 0.8243 - top_10_acc: 0.8797 - val_loss: 1.6034 - val_acc: 0.6169 - val_top_5_acc: 0.8352 - val_top_10_acc: 0.8894 - lr: 9.9825e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 9.972609476841367e-05.\n",
      "learning rate: 9.97e-05, weight decay: 4.99e-06\n",
      "Epoch 6/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.5178 - acc: 0.6285 - top_5_acc: 0.8484 - top_10_acc: 0.8972 - val_loss: 1.4511 - val_acc: 0.6503 - val_top_5_acc: 0.8556 - val_top_10_acc: 0.8998 - lr: 9.9726e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 9.96057350657239e-05.\n",
      "learning rate: 9.96e-05, weight decay: 4.98e-06\n",
      "Epoch 7/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.3732 - acc: 0.6590 - top_5_acc: 0.8671 - top_10_acc: 0.9092 - val_loss: 1.3704 - val_acc: 0.6737 - val_top_5_acc: 0.8637 - val_top_10_acc: 0.9059 - lr: 9.9606e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 9.946361664814943e-05.\n",
      "learning rate: 9.95e-05, weight decay: 4.97e-06\n",
      "Epoch 8/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.2582 - acc: 0.6837 - top_5_acc: 0.8797 - top_10_acc: 0.9184 - val_loss: 1.2373 - val_acc: 0.7005 - val_top_5_acc: 0.8841 - val_top_10_acc: 0.9172 - lr: 9.9464e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 9.929980185352526e-05.\n",
      "learning rate: 9.93e-05, weight decay: 4.96e-06\n",
      "Epoch 9/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.1567 - acc: 0.7084 - top_5_acc: 0.8926 - top_10_acc: 0.9275 - val_loss: 1.2107 - val_acc: 0.7075 - val_top_5_acc: 0.8859 - val_top_10_acc: 0.9206 - lr: 9.9300e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 9.911436253643445e-05.\n",
      "learning rate: 9.91e-05, weight decay: 4.96e-06\n",
      "Epoch 10/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.0718 - acc: 0.7290 - top_5_acc: 0.9021 - top_10_acc: 0.9346 - val_loss: 1.1485 - val_acc: 0.7286 - val_top_5_acc: 0.8879 - val_top_10_acc: 0.9236 - lr: 9.9114e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 9.890738003669029e-05.\n",
      "learning rate: 9.89e-05, weight decay: 4.95e-06\n",
      "Epoch 11/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.9934 - acc: 0.7483 - top_5_acc: 0.9121 - top_10_acc: 0.9411 - val_loss: 1.1066 - val_acc: 0.7280 - val_top_5_acc: 0.8962 - val_top_10_acc: 0.9271 - lr: 9.8907e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 9.867894514365802e-05.\n",
      "learning rate: 9.87e-05, weight decay: 4.93e-06\n",
      "Epoch 12/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.9249 - acc: 0.7632 - top_5_acc: 0.9196 - top_10_acc: 0.9466 - val_loss: 1.0654 - val_acc: 0.7442 - val_top_5_acc: 0.9016 - val_top_10_acc: 0.9329 - lr: 9.8679e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 9.842915805643155e-05.\n",
      "learning rate: 9.84e-05, weight decay: 4.92e-06\n",
      "Epoch 13/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.8563 - acc: 0.7800 - top_5_acc: 0.9275 - top_10_acc: 0.9518 - val_loss: 1.0266 - val_acc: 0.7508 - val_top_5_acc: 0.9048 - val_top_10_acc: 0.9344 - lr: 9.8429e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 9.815812833988291e-05.\n",
      "learning rate: 9.82e-05, weight decay: 4.91e-06\n",
      "Epoch 14/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.7995 - acc: 0.7958 - top_5_acc: 0.9338 - top_10_acc: 0.9561 - val_loss: 0.9592 - val_acc: 0.7670 - val_top_5_acc: 0.9158 - val_top_10_acc: 0.9402 - lr: 9.8158e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 9.786597487660337e-05.\n",
      "learning rate: 9.79e-05, weight decay: 4.89e-06\n",
      "Epoch 15/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.7357 - acc: 0.8113 - top_5_acc: 0.9406 - top_10_acc: 0.9614 - val_loss: 0.9479 - val_acc: 0.7738 - val_top_5_acc: 0.9145 - val_top_10_acc: 0.9426 - lr: 9.7866e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 9.755282581475769e-05.\n",
      "learning rate: 9.76e-05, weight decay: 4.88e-06\n",
      "Epoch 16/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.6953 - acc: 0.8202 - top_5_acc: 0.9445 - top_10_acc: 0.9642 - val_loss: 0.9716 - val_acc: 0.7707 - val_top_5_acc: 0.9103 - val_top_10_acc: 0.9372 - lr: 9.7553e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 9.721881851187406e-05.\n",
      "learning rate: 9.72e-05, weight decay: 4.86e-06\n",
      "Epoch 17/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.6498 - acc: 0.8330 - top_5_acc: 0.9499 - top_10_acc: 0.9680 - val_loss: 0.9457 - val_acc: 0.7799 - val_top_5_acc: 0.9143 - val_top_10_acc: 0.9371 - lr: 9.7219e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 9.686409947459458e-05.\n",
      "learning rate: 9.69e-05, weight decay: 4.84e-06\n",
      "Epoch 18/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.6051 - acc: 0.8424 - top_5_acc: 0.9546 - top_10_acc: 0.9713 - val_loss: 0.9244 - val_acc: 0.7825 - val_top_5_acc: 0.9164 - val_top_10_acc: 0.9413 - lr: 9.6864e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 9.648882429441257e-05.\n",
      "learning rate: 9.65e-05, weight decay: 4.82e-06\n",
      "Epoch 19/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.5630 - acc: 0.8533 - top_5_acc: 0.9595 - top_10_acc: 0.9746 - val_loss: 0.8894 - val_acc: 0.7849 - val_top_5_acc: 0.9200 - val_top_10_acc: 0.9465 - lr: 9.6489e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 9.609315757942503e-05.\n",
      "learning rate: 9.61e-05, weight decay: 4.80e-06\n",
      "Epoch 20/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.5167 - acc: 0.8666 - top_5_acc: 0.9635 - top_10_acc: 0.9774 - val_loss: 0.8627 - val_acc: 0.8000 - val_top_5_acc: 0.9236 - val_top_10_acc: 0.9466 - lr: 9.6093e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 9.567727288213005e-05.\n",
      "learning rate: 9.57e-05, weight decay: 4.78e-06\n",
      "Epoch 21/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.4830 - acc: 0.8731 - top_5_acc: 0.9679 - top_10_acc: 0.9798 - val_loss: 0.8241 - val_acc: 0.8009 - val_top_5_acc: 0.9297 - val_top_10_acc: 0.9499 - lr: 9.5677e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 9.524135262330098e-05.\n",
      "learning rate: 9.52e-05, weight decay: 4.76e-06\n",
      "Epoch 22/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.4484 - acc: 0.8825 - top_5_acc: 0.9714 - top_10_acc: 0.9829 - val_loss: 0.8190 - val_acc: 0.8112 - val_top_5_acc: 0.9279 - val_top_10_acc: 0.9478 - lr: 9.5241e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 9.478558801197065e-05.\n",
      "learning rate: 9.48e-05, weight decay: 4.74e-06\n",
      "Epoch 23/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.4149 - acc: 0.8926 - top_5_acc: 0.9746 - top_10_acc: 0.9843 - val_loss: 0.8306 - val_acc: 0.8064 - val_top_5_acc: 0.9292 - val_top_10_acc: 0.9501 - lr: 9.4786e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 9.431017896156074e-05.\n",
      "learning rate: 9.43e-05, weight decay: 4.72e-06\n",
      "Epoch 24/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3835 - acc: 0.9003 - top_5_acc: 0.9775 - top_10_acc: 0.9867 - val_loss: 0.8233 - val_acc: 0.8087 - val_top_5_acc: 0.9288 - val_top_10_acc: 0.9515 - lr: 9.4310e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 9.381533400219318e-05.\n",
      "learning rate: 9.38e-05, weight decay: 4.69e-06\n",
      "Epoch 25/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3596 - acc: 0.9062 - top_5_acc: 0.9799 - top_10_acc: 0.9885 - val_loss: 0.8025 - val_acc: 0.8174 - val_top_5_acc: 0.9320 - val_top_10_acc: 0.9524 - lr: 9.3815e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 9.330127018922194e-05.\n",
      "learning rate: 9.33e-05, weight decay: 4.67e-06\n",
      "Epoch 26/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3299 - acc: 0.9143 - top_5_acc: 0.9832 - top_10_acc: 0.9904 - val_loss: 0.7981 - val_acc: 0.8216 - val_top_5_acc: 0.9330 - val_top_10_acc: 0.9528 - lr: 9.3301e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.276821300802534e-05.\n",
      "learning rate: 9.28e-05, weight decay: 4.64e-06\n",
      "Epoch 27/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.3063 - acc: 0.9209 - top_5_acc: 0.9848 - top_10_acc: 0.9909 - val_loss: 0.8019 - val_acc: 0.8207 - val_top_5_acc: 0.9319 - val_top_10_acc: 0.9517 - lr: 9.2768e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.221639627510076e-05.\n",
      "learning rate: 9.22e-05, weight decay: 4.61e-06\n",
      "Epoch 28/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.2776 - acc: 0.9286 - top_5_acc: 0.9871 - top_10_acc: 0.9927 - val_loss: 0.7638 - val_acc: 0.8355 - val_top_5_acc: 0.9359 - val_top_10_acc: 0.9567 - lr: 9.2216e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.164606203550497e-05.\n",
      "learning rate: 9.16e-05, weight decay: 4.58e-06\n",
      "Epoch 29/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.2626 - acc: 0.9323 - top_5_acc: 0.9887 - top_10_acc: 0.9937 - val_loss: 0.7910 - val_acc: 0.8246 - val_top_5_acc: 0.9373 - val_top_10_acc: 0.9567 - lr: 9.1646e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 9.105746045668521e-05.\n",
      "learning rate: 9.11e-05, weight decay: 4.55e-06\n",
      "Epoch 30/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.2341 - acc: 0.9392 - top_5_acc: 0.9910 - top_10_acc: 0.9956 - val_loss: 0.7409 - val_acc: 0.8394 - val_top_5_acc: 0.9377 - val_top_10_acc: 0.9573 - lr: 9.1057e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 9.045084971874738e-05.\n",
      "learning rate: 9.05e-05, weight decay: 4.52e-06\n",
      "Epoch 31/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.2114 - acc: 0.9469 - top_5_acc: 0.9920 - top_10_acc: 0.9960 - val_loss: 0.7609 - val_acc: 0.8350 - val_top_5_acc: 0.9378 - val_top_10_acc: 0.9587 - lr: 9.0451e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 8.982649590120982e-05.\n",
      "learning rate: 8.98e-05, weight decay: 4.49e-06\n",
      "Epoch 32/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.2018 - acc: 0.9494 - top_5_acc: 0.9934 - top_10_acc: 0.9965 - val_loss: 0.7818 - val_acc: 0.8310 - val_top_5_acc: 0.9365 - val_top_10_acc: 0.9570 - lr: 8.9826e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 8.9184672866292e-05.\n",
      "learning rate: 8.92e-05, weight decay: 4.46e-06\n",
      "Epoch 33/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1823 - acc: 0.9542 - top_5_acc: 0.9944 - top_10_acc: 0.9972 - val_loss: 0.7321 - val_acc: 0.8482 - val_top_5_acc: 0.9425 - val_top_10_acc: 0.9591 - lr: 8.9185e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 8.852566213878947e-05.\n",
      "learning rate: 8.85e-05, weight decay: 4.43e-06\n",
      "Epoch 34/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1636 - acc: 0.9600 - top_5_acc: 0.9955 - top_10_acc: 0.9977 - val_loss: 0.7091 - val_acc: 0.8514 - val_top_5_acc: 0.9402 - val_top_10_acc: 0.9587 - lr: 8.8526e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 8.784975278258783e-05.\n",
      "learning rate: 8.78e-05, weight decay: 4.39e-06\n",
      "Epoch 35/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1541 - acc: 0.9623 - top_5_acc: 0.9961 - top_10_acc: 0.9981 - val_loss: 0.7147 - val_acc: 0.8537 - val_top_5_acc: 0.9422 - val_top_10_acc: 0.9626 - lr: 8.7850e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 8.715724127386972e-05.\n",
      "learning rate: 8.72e-05, weight decay: 4.36e-06\n",
      "Epoch 36/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1371 - acc: 0.9670 - top_5_acc: 0.9969 - top_10_acc: 0.9984 - val_loss: 0.7268 - val_acc: 0.8527 - val_top_5_acc: 0.9443 - val_top_10_acc: 0.9603 - lr: 8.7157e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 8.644843137107059e-05.\n",
      "learning rate: 8.64e-05, weight decay: 4.32e-06\n",
      "Epoch 37/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1340 - acc: 0.9672 - top_5_acc: 0.9971 - top_10_acc: 0.9987 - val_loss: 0.7456 - val_acc: 0.8491 - val_top_5_acc: 0.9409 - val_top_10_acc: 0.9588 - lr: 8.6448e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 8.572363398164017e-05.\n",
      "learning rate: 8.57e-05, weight decay: 4.29e-06\n",
      "Epoch 38/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1184 - acc: 0.9720 - top_5_acc: 0.9979 - top_10_acc: 0.9990 - val_loss: 0.7251 - val_acc: 0.8531 - val_top_5_acc: 0.9413 - val_top_10_acc: 0.9578 - lr: 8.5724e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 8.498316702566828e-05.\n",
      "learning rate: 8.50e-05, weight decay: 4.25e-06\n",
      "Epoch 39/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.1099 - acc: 0.9744 - top_5_acc: 0.9983 - top_10_acc: 0.9991 - val_loss: 0.7090 - val_acc: 0.8570 - val_top_5_acc: 0.9447 - val_top_10_acc: 0.9616 - lr: 8.4983e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 8.422735529643444e-05.\n",
      "learning rate: 8.42e-05, weight decay: 4.21e-06\n",
      "Epoch 40/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.1023 - acc: 0.9759 - top_5_acc: 0.9984 - top_10_acc: 0.9993 - val_loss: 0.7108 - val_acc: 0.8555 - val_top_5_acc: 0.9442 - val_top_10_acc: 0.9620 - lr: 8.4227e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 8.345653031794292e-05.\n",
      "learning rate: 8.35e-05, weight decay: 4.17e-06\n",
      "Epoch 41/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0938 - acc: 0.9785 - top_5_acc: 0.9988 - top_10_acc: 0.9995 - val_loss: 0.7069 - val_acc: 0.8609 - val_top_5_acc: 0.9470 - val_top_10_acc: 0.9604 - lr: 8.3457e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 8.267103019950529e-05.\n",
      "learning rate: 8.27e-05, weight decay: 4.13e-06\n",
      "Epoch 42/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0827 - acc: 0.9819 - top_5_acc: 0.9989 - top_10_acc: 0.9994 - val_loss: 0.6872 - val_acc: 0.8655 - val_top_5_acc: 0.9486 - val_top_10_acc: 0.9620 - lr: 8.2671e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 8.18711994874345e-05.\n",
      "learning rate: 8.19e-05, weight decay: 4.09e-06\n",
      "Epoch 43/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0812 - acc: 0.9821 - top_5_acc: 0.9989 - top_10_acc: 0.9995 - val_loss: 0.7278 - val_acc: 0.8623 - val_top_5_acc: 0.9428 - val_top_10_acc: 0.9595 - lr: 8.1871e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 8.105738901391552e-05.\n",
      "learning rate: 8.11e-05, weight decay: 4.05e-06\n",
      "Epoch 44/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0786 - acc: 0.9825 - top_5_acc: 0.9991 - top_10_acc: 0.9995 - val_loss: 0.7038 - val_acc: 0.8621 - val_top_5_acc: 0.9461 - val_top_10_acc: 0.9616 - lr: 8.1057e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 8.022995574311876e-05.\n",
      "learning rate: 8.02e-05, weight decay: 4.01e-06\n",
      "Epoch 45/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0746 - acc: 0.9834 - top_5_acc: 0.9992 - top_10_acc: 0.9995 - val_loss: 0.7065 - val_acc: 0.8643 - val_top_5_acc: 0.9473 - val_top_10_acc: 0.9622 - lr: 8.0230e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 7.938926261462366e-05.\n",
      "learning rate: 7.94e-05, weight decay: 3.97e-06\n",
      "Epoch 46/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0722 - acc: 0.9834 - top_5_acc: 0.9993 - top_10_acc: 0.9997 - val_loss: 0.7216 - val_acc: 0.8668 - val_top_5_acc: 0.9478 - val_top_10_acc: 0.9620 - lr: 7.9389e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 7.85356783842216e-05.\n",
      "learning rate: 7.85e-05, weight decay: 3.93e-06\n",
      "Epoch 47/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0634 - acc: 0.9861 - top_5_acc: 0.9994 - top_10_acc: 0.9997 - val_loss: 0.7031 - val_acc: 0.8710 - val_top_5_acc: 0.9475 - val_top_10_acc: 0.9621 - lr: 7.8536e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 7.766957746216721e-05.\n",
      "learning rate: 7.77e-05, weight decay: 3.88e-06\n",
      "Epoch 48/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0608 - acc: 0.9868 - top_5_acc: 0.9995 - top_10_acc: 0.9998 - val_loss: 0.7039 - val_acc: 0.8709 - val_top_5_acc: 0.9471 - val_top_10_acc: 0.9628 - lr: 7.7670e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 7.679133974894983e-05.\n",
      "learning rate: 7.68e-05, weight decay: 3.84e-06\n",
      "Epoch 49/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0570 - acc: 0.9879 - top_5_acc: 0.9995 - top_10_acc: 0.9998 - val_loss: 0.7030 - val_acc: 0.8694 - val_top_5_acc: 0.9493 - val_top_10_acc: 0.9626 - lr: 7.6791e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 7.590135046865651e-05.\n",
      "learning rate: 7.59e-05, weight decay: 3.80e-06\n",
      "Epoch 50/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0543 - acc: 0.9884 - top_5_acc: 0.9997 - top_10_acc: 0.9999 - val_loss: 0.6899 - val_acc: 0.8772 - val_top_5_acc: 0.9500 - val_top_10_acc: 0.9639 - lr: 7.5901e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 7.500000000000001e-05.\n",
      "learning rate: 7.50e-05, weight decay: 3.75e-06\n",
      "Epoch 51/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0484 - acc: 0.9900 - top_5_acc: 0.9996 - top_10_acc: 0.9998 - val_loss: 0.7066 - val_acc: 0.8769 - val_top_5_acc: 0.9490 - val_top_10_acc: 0.9623 - lr: 7.5000e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 7.408768370508576e-05.\n",
      "learning rate: 7.41e-05, weight decay: 3.70e-06\n",
      "Epoch 52/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0476 - acc: 0.9898 - top_5_acc: 0.9996 - top_10_acc: 0.9997 - val_loss: 0.6925 - val_acc: 0.8751 - val_top_5_acc: 0.9496 - val_top_10_acc: 0.9627 - lr: 7.4088e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 7.316480175599309e-05.\n",
      "learning rate: 7.32e-05, weight decay: 3.66e-06\n",
      "Epoch 53/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0536 - acc: 0.9875 - top_5_acc: 0.9996 - top_10_acc: 0.9998 - val_loss: 0.6821 - val_acc: 0.8787 - val_top_5_acc: 0.9517 - val_top_10_acc: 0.9642 - lr: 7.3165e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 7.223175895924638e-05.\n",
      "learning rate: 7.22e-05, weight decay: 3.61e-06\n",
      "Epoch 54/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0433 - acc: 0.9911 - top_5_acc: 0.9997 - top_10_acc: 0.9999 - val_loss: 0.6735 - val_acc: 0.8799 - val_top_5_acc: 0.9524 - val_top_10_acc: 0.9649 - lr: 7.2232e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 7.128896457825364e-05.\n",
      "learning rate: 7.13e-05, weight decay: 3.56e-06\n",
      "Epoch 55/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0385 - acc: 0.9922 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6560 - val_acc: 0.8825 - val_top_5_acc: 0.9540 - val_top_10_acc: 0.9683 - lr: 7.1289e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 7.033683215379002e-05.\n",
      "learning rate: 7.03e-05, weight decay: 3.52e-06\n",
      "Epoch 56/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0400 - acc: 0.9920 - top_5_acc: 0.9997 - top_10_acc: 0.9998 - val_loss: 0.6815 - val_acc: 0.8818 - val_top_5_acc: 0.9528 - val_top_10_acc: 0.9654 - lr: 7.0337e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 6.937577932260515e-05.\n",
      "learning rate: 6.94e-05, weight decay: 3.47e-06\n",
      "Epoch 57/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0352 - acc: 0.9933 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6785 - val_acc: 0.8823 - val_top_5_acc: 0.9537 - val_top_10_acc: 0.9664 - lr: 6.9376e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 6.840622763423391e-05.\n",
      "learning rate: 6.84e-05, weight decay: 3.42e-06\n",
      "Epoch 58/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0325 - acc: 0.9936 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6452 - val_acc: 0.8899 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9676 - lr: 6.8406e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 6.742860236609077e-05.\n",
      "learning rate: 6.74e-05, weight decay: 3.37e-06\n",
      "Epoch 59/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0302 - acc: 0.9943 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6855 - val_acc: 0.8833 - val_top_5_acc: 0.9502 - val_top_10_acc: 0.9648 - lr: 6.7429e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 6.644333233692916e-05.\n",
      "learning rate: 6.64e-05, weight decay: 3.32e-06\n",
      "Epoch 60/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0381 - acc: 0.9919 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6918 - val_acc: 0.8830 - val_top_5_acc: 0.9518 - val_top_10_acc: 0.9673 - lr: 6.6443e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 6.545084971874738e-05.\n",
      "learning rate: 6.55e-05, weight decay: 3.27e-06\n",
      "Epoch 61/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0357 - acc: 0.9925 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6680 - val_acc: 0.8849 - val_top_5_acc: 0.9542 - val_top_10_acc: 0.9663 - lr: 6.5451e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 6.445158984722358e-05.\n",
      "learning rate: 6.45e-05, weight decay: 3.22e-06\n",
      "Epoch 62/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0345 - acc: 0.9924 - top_5_acc: 0.9997 - top_10_acc: 0.9999 - val_loss: 0.6907 - val_acc: 0.8807 - val_top_5_acc: 0.9548 - val_top_10_acc: 0.9671 - lr: 6.4452e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 6.344599103076329e-05.\n",
      "learning rate: 6.34e-05, weight decay: 3.17e-06\n",
      "Epoch 63/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0294 - acc: 0.9943 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6709 - val_acc: 0.8876 - val_top_5_acc: 0.9529 - val_top_10_acc: 0.9661 - lr: 6.3446e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 6.243449435824276e-05.\n",
      "learning rate: 6.24e-05, weight decay: 3.12e-06\n",
      "Epoch 64/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0318 - acc: 0.9936 - top_5_acc: 0.9997 - top_10_acc: 0.9998 - val_loss: 0.6951 - val_acc: 0.8842 - val_top_5_acc: 0.9516 - val_top_10_acc: 0.9644 - lr: 6.2434e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 6.141754350553279e-05.\n",
      "learning rate: 6.14e-05, weight decay: 3.07e-06\n",
      "Epoch 65/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0248 - acc: 0.9954 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6611 - val_acc: 0.8886 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9686 - lr: 6.1418e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 6.0395584540887963e-05.\n",
      "learning rate: 6.04e-05, weight decay: 3.02e-06\n",
      "Epoch 66/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0263 - acc: 0.9946 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6769 - val_acc: 0.8896 - val_top_5_acc: 0.9536 - val_top_10_acc: 0.9660 - lr: 6.0396e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 5.9369065729286245e-05.\n",
      "learning rate: 5.94e-05, weight decay: 2.97e-06\n",
      "Epoch 67/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0242 - acc: 0.9953 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.6602 - val_acc: 0.8914 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9690 - lr: 5.9369e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 5.833843733580512e-05.\n",
      "learning rate: 5.83e-05, weight decay: 2.92e-06\n",
      "Epoch 68/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0230 - acc: 0.9954 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6995 - val_acc: 0.8853 - val_top_5_acc: 0.9536 - val_top_10_acc: 0.9668 - lr: 5.8338e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.730415142812059e-05.\n",
      "learning rate: 5.73e-05, weight decay: 2.87e-06\n",
      "Epoch 69/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0246 - acc: 0.9947 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6825 - val_acc: 0.8895 - val_top_5_acc: 0.9529 - val_top_10_acc: 0.9667 - lr: 5.7304e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.6266661678215216e-05.\n",
      "learning rate: 5.63e-05, weight decay: 2.81e-06\n",
      "Epoch 70/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0233 - acc: 0.9951 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.7234 - val_acc: 0.8845 - val_top_5_acc: 0.9511 - val_top_10_acc: 0.9659 - lr: 5.6267e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 5.522642316338268e-05.\n",
      "learning rate: 5.52e-05, weight decay: 2.76e-06\n",
      "Epoch 71/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0191 - acc: 0.9963 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6695 - val_acc: 0.8923 - val_top_5_acc: 0.9554 - val_top_10_acc: 0.9676 - lr: 5.5226e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 5.418389216661579e-05.\n",
      "learning rate: 5.42e-05, weight decay: 2.71e-06\n",
      "Epoch 72/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0156 - acc: 0.9976 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.8929 - val_top_5_acc: 0.9560 - val_top_10_acc: 0.9660 - lr: 5.4184e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 5.313952597646568e-05.\n",
      "learning rate: 5.31e-05, weight decay: 2.66e-06\n",
      "Epoch 73/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0160 - acc: 0.9973 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6435 - val_acc: 0.8954 - val_top_5_acc: 0.9570 - val_top_10_acc: 0.9703 - lr: 5.3140e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 5.209378268645998e-05.\n",
      "learning rate: 5.21e-05, weight decay: 2.60e-06\n",
      "Epoch 74/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0138 - acc: 0.9981 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6613 - val_acc: 0.8985 - val_top_5_acc: 0.9563 - val_top_10_acc: 0.9676 - lr: 5.2094e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 5.104712099416785e-05.\n",
      "learning rate: 5.10e-05, weight decay: 2.55e-06\n",
      "Epoch 75/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0150 - acc: 0.9974 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.8961 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9690 - lr: 5.1047e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 5e-05.\n",
      "learning rate: 5.00e-05, weight decay: 2.50e-06\n",
      "Epoch 76/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0155 - acc: 0.9974 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6792 - val_acc: 0.8918 - val_top_5_acc: 0.9548 - val_top_10_acc: 0.9678 - lr: 5.0000e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 4.895287900583216e-05.\n",
      "learning rate: 4.90e-05, weight decay: 2.45e-06\n",
      "Epoch 77/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0161 - acc: 0.9970 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6445 - val_acc: 0.8995 - val_top_5_acc: 0.9578 - val_top_10_acc: 0.9701 - lr: 4.8953e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 4.790621731354003e-05.\n",
      "learning rate: 4.79e-05, weight decay: 2.40e-06\n",
      "Epoch 78/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0138 - acc: 0.9979 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.7033 - val_acc: 0.8919 - val_top_5_acc: 0.9543 - val_top_10_acc: 0.9657 - lr: 4.7906e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 4.6860474023534335e-05.\n",
      "learning rate: 4.69e-05, weight decay: 2.34e-06\n",
      "Epoch 79/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0185 - acc: 0.9966 - top_5_acc: 0.9998 - top_10_acc: 0.9999 - val_loss: 0.7221 - val_acc: 0.8862 - val_top_5_acc: 0.9512 - val_top_10_acc: 0.9650 - lr: 4.6860e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 4.5816107833384234e-05.\n",
      "learning rate: 4.58e-05, weight decay: 2.29e-06\n",
      "Epoch 80/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0156 - acc: 0.9971 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6437 - val_acc: 0.8974 - val_top_5_acc: 0.9600 - val_top_10_acc: 0.9694 - lr: 4.5816e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 4.477357683661734e-05.\n",
      "learning rate: 4.48e-05, weight decay: 2.24e-06\n",
      "Epoch 81/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0123 - acc: 0.9979 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6814 - val_acc: 0.8989 - val_top_5_acc: 0.9543 - val_top_10_acc: 0.9661 - lr: 4.4774e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 4.373333832178478e-05.\n",
      "learning rate: 4.37e-05, weight decay: 2.19e-06\n",
      "Epoch 82/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0137 - acc: 0.9976 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6875 - val_acc: 0.8970 - val_top_5_acc: 0.9543 - val_top_10_acc: 0.9677 - lr: 4.3733e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 4.269584857187943e-05.\n",
      "learning rate: 4.27e-05, weight decay: 2.13e-06\n",
      "Epoch 83/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0103 - acc: 0.9987 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.9023 - val_top_5_acc: 0.9580 - val_top_10_acc: 0.9687 - lr: 4.2696e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 4.166156266419489e-05.\n",
      "learning rate: 4.17e-05, weight decay: 2.08e-06\n",
      "Epoch 84/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0099 - acc: 0.9984 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6644 - val_acc: 0.8972 - val_top_5_acc: 0.9559 - val_top_10_acc: 0.9667 - lr: 4.1662e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 4.063093427071376e-05.\n",
      "learning rate: 4.06e-05, weight decay: 2.03e-06\n",
      "Epoch 85/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0075 - acc: 0.9992 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6578 - val_acc: 0.9017 - val_top_5_acc: 0.9574 - val_top_10_acc: 0.9681 - lr: 4.0631e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 3.960441545911204e-05.\n",
      "learning rate: 3.96e-05, weight decay: 1.98e-06\n",
      "Epoch 86/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0085 - acc: 0.9988 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6690 - val_acc: 0.8980 - val_top_5_acc: 0.9566 - val_top_10_acc: 0.9678 - lr: 3.9604e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 3.858245649446721e-05.\n",
      "learning rate: 3.86e-05, weight decay: 1.93e-06\n",
      "Epoch 87/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0090 - acc: 0.9987 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6944 - val_acc: 0.8934 - val_top_5_acc: 0.9537 - val_top_10_acc: 0.9663 - lr: 3.8582e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 3.756550564175727e-05.\n",
      "learning rate: 3.76e-05, weight decay: 1.88e-06\n",
      "Epoch 88/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0126 - acc: 0.9979 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.8966 - val_top_5_acc: 0.9555 - val_top_10_acc: 0.9658 - lr: 3.7566e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 3.655400896923672e-05.\n",
      "learning rate: 3.66e-05, weight decay: 1.83e-06\n",
      "Epoch 89/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0127 - acc: 0.9978 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6621 - val_acc: 0.9013 - val_top_5_acc: 0.9570 - val_top_10_acc: 0.9682 - lr: 3.6554e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 3.554841015277641e-05.\n",
      "learning rate: 3.55e-05, weight decay: 1.78e-06\n",
      "Epoch 90/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0072 - acc: 0.9990 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6493 - val_acc: 0.9004 - val_top_5_acc: 0.9579 - val_top_10_acc: 0.9691 - lr: 3.5548e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 3.4549150281252636e-05.\n",
      "learning rate: 3.45e-05, weight decay: 1.73e-06\n",
      "Epoch 91/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0058 - acc: 0.9995 - top_5_acc: 0.9999 - top_10_acc: 0.9999 - val_loss: 0.6619 - val_acc: 0.9001 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9695 - lr: 3.4549e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 3.355666766307084e-05.\n",
      "learning rate: 3.36e-05, weight decay: 1.68e-06\n",
      "Epoch 92/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0055 - acc: 0.9994 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.9032 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9677 - lr: 3.3557e-05\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 3.257139763390925e-05.\n",
      "learning rate: 3.26e-05, weight decay: 1.63e-06\n",
      "Epoch 93/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0045 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6584 - val_acc: 0.9018 - val_top_5_acc: 0.9582 - val_top_10_acc: 0.9701 - lr: 3.2571e-05\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 3.1593772365766105e-05.\n",
      "learning rate: 3.16e-05, weight decay: 1.58e-06\n",
      "Epoch 94/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0047 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.9048 - val_top_5_acc: 0.9584 - val_top_10_acc: 0.9714 - lr: 3.1594e-05\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 3.062422067739485e-05.\n",
      "learning rate: 3.06e-05, weight decay: 1.53e-06\n",
      "Epoch 95/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0045 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6603 - val_acc: 0.9019 - val_top_5_acc: 0.9564 - val_top_10_acc: 0.9688 - lr: 3.0624e-05\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 2.9663167846209998e-05.\n",
      "learning rate: 2.97e-05, weight decay: 1.48e-06\n",
      "Epoch 96/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0046 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6593 - val_acc: 0.9042 - val_top_5_acc: 0.9574 - val_top_10_acc: 0.9691 - lr: 2.9663e-05\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 2.8711035421746367e-05.\n",
      "learning rate: 2.87e-05, weight decay: 1.44e-06\n",
      "Epoch 97/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0041 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.9036 - val_top_5_acc: 0.9579 - val_top_10_acc: 0.9701 - lr: 2.8711e-05\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 2.776824104075364e-05.\n",
      "learning rate: 2.78e-05, weight decay: 1.39e-06\n",
      "Epoch 98/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0041 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6508 - val_acc: 0.9042 - val_top_5_acc: 0.9579 - val_top_10_acc: 0.9704 - lr: 2.7768e-05\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.6835198244006927e-05.\n",
      "learning rate: 2.68e-05, weight decay: 1.34e-06\n",
      "Epoch 99/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0034 - acc: 0.9998 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6623 - val_acc: 0.9036 - val_top_5_acc: 0.9558 - val_top_10_acc: 0.9694 - lr: 2.6835e-05\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.591231629491423e-05.\n",
      "learning rate: 2.59e-05, weight decay: 1.30e-06\n",
      "Epoch 100/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0034 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6284 - val_acc: 0.9077 - val_top_5_acc: 0.9612 - val_top_10_acc: 0.9715 - lr: 2.5912e-05\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 2.500000000000001e-05.\n",
      "learning rate: 2.50e-05, weight decay: 1.25e-06\n",
      "Epoch 101/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0043 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6723 - val_acc: 0.9026 - val_top_5_acc: 0.9582 - val_top_10_acc: 0.9694 - lr: 2.5000e-05\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 2.4098649531343497e-05.\n",
      "learning rate: 2.41e-05, weight decay: 1.20e-06\n",
      "Epoch 102/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0036 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6628 - val_acc: 0.9042 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9682 - lr: 2.4099e-05\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 2.3208660251050158e-05.\n",
      "learning rate: 2.32e-05, weight decay: 1.16e-06\n",
      "Epoch 103/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0033 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6687 - val_acc: 0.9030 - val_top_5_acc: 0.9580 - val_top_10_acc: 0.9701 - lr: 2.3209e-05\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 2.23304225378328e-05.\n",
      "learning rate: 2.23e-05, weight decay: 1.12e-06\n",
      "Epoch 104/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0041 - acc: 0.9996 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.9016 - val_top_5_acc: 0.9574 - val_top_10_acc: 0.9698 - lr: 2.2330e-05\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 2.1464321615778422e-05.\n",
      "learning rate: 2.15e-05, weight decay: 1.07e-06\n",
      "Epoch 105/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0034 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6428 - val_acc: 0.9049 - val_top_5_acc: 0.9586 - val_top_10_acc: 0.9706 - lr: 2.1464e-05\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 2.061073738537635e-05.\n",
      "learning rate: 2.06e-05, weight decay: 1.03e-06\n",
      "Epoch 106/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0051 - acc: 0.9993 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6920 - val_acc: 0.9029 - val_top_5_acc: 0.9576 - val_top_10_acc: 0.9674 - lr: 2.0611e-05\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 1.977004425688126e-05.\n",
      "learning rate: 1.98e-05, weight decay: 9.89e-07\n",
      "Epoch 107/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0049 - acc: 0.9994 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6196 - val_acc: 0.9058 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9722 - lr: 1.9770e-05\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 1.8942610986084486e-05.\n",
      "learning rate: 1.89e-05, weight decay: 9.47e-07\n",
      "Epoch 108/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0035 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6394 - val_acc: 0.9081 - val_top_5_acc: 0.9591 - val_top_10_acc: 0.9709 - lr: 1.8943e-05\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 1.8128800512565513e-05.\n",
      "learning rate: 1.81e-05, weight decay: 9.06e-07\n",
      "Epoch 109/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0034 - acc: 0.9997 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.7000 - val_acc: 0.9021 - val_top_5_acc: 0.9570 - val_top_10_acc: 0.9689 - lr: 1.8129e-05\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 1.7328969800494726e-05.\n",
      "learning rate: 1.73e-05, weight decay: 8.66e-07\n",
      "Epoch 110/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0029 - acc: 0.9998 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6630 - val_acc: 0.9057 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9693 - lr: 1.7329e-05\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 1.6543469682057106e-05.\n",
      "learning rate: 1.65e-05, weight decay: 8.27e-07\n",
      "Epoch 111/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0021 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6980 - val_acc: 0.9037 - val_top_5_acc: 0.9566 - val_top_10_acc: 0.9677 - lr: 1.6543e-05\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 1.5772644703565565e-05.\n",
      "learning rate: 1.58e-05, weight decay: 7.89e-07\n",
      "Epoch 112/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6450 - val_acc: 0.9100 - val_top_5_acc: 0.9618 - val_top_10_acc: 0.9715 - lr: 1.5773e-05\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 1.5016832974331724e-05.\n",
      "learning rate: 1.50e-05, weight decay: 7.51e-07\n",
      "Epoch 113/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0017 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6648 - val_acc: 0.9062 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9686 - lr: 1.5017e-05\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 1.4276366018359844e-05.\n",
      "learning rate: 1.43e-05, weight decay: 7.14e-07\n",
      "Epoch 114/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6321 - val_acc: 0.9072 - val_top_5_acc: 0.9606 - val_top_10_acc: 0.9725 - lr: 1.4276e-05\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 1.3551568628929434e-05.\n",
      "learning rate: 1.36e-05, weight decay: 6.78e-07\n",
      "Epoch 115/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0019 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6767 - val_acc: 0.9043 - val_top_5_acc: 0.9578 - val_top_10_acc: 0.9697 - lr: 1.3552e-05\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 1.2842758726130283e-05.\n",
      "learning rate: 1.28e-05, weight decay: 6.42e-07\n",
      "Epoch 116/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6652 - val_acc: 0.9044 - val_top_5_acc: 0.9597 - val_top_10_acc: 0.9704 - lr: 1.2843e-05\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 1.2150247217412186e-05.\n",
      "learning rate: 1.22e-05, weight decay: 6.08e-07\n",
      "Epoch 117/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6735 - val_acc: 0.9076 - val_top_5_acc: 0.9591 - val_top_10_acc: 0.9687 - lr: 1.2150e-05\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 1.1474337861210543e-05.\n",
      "learning rate: 1.15e-05, weight decay: 5.74e-07\n",
      "Epoch 118/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0025 - acc: 0.9998 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6658 - val_acc: 0.9056 - val_top_5_acc: 0.9581 - val_top_10_acc: 0.9709 - lr: 1.1474e-05\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 1.0815327133708015e-05.\n",
      "learning rate: 1.08e-05, weight decay: 5.41e-07\n",
      "Epoch 119/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0025 - acc: 0.9999 - top_5_acc: 0.9999 - top_10_acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.9086 - val_top_5_acc: 0.9589 - val_top_10_acc: 0.9706 - lr: 1.0815e-05\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 1.0173504098790187e-05.\n",
      "learning rate: 1.02e-05, weight decay: 5.09e-07\n",
      "Epoch 120/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0020 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.9059 - val_top_5_acc: 0.9590 - val_top_10_acc: 0.9701 - lr: 1.0174e-05\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 9.549150281252633e-06.\n",
      "learning rate: 9.55e-06, weight decay: 4.77e-07\n",
      "Epoch 121/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0016 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6540 - val_acc: 0.9075 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9711 - lr: 9.5492e-06\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 8.9425395433148e-06.\n",
      "learning rate: 8.94e-06, weight decay: 4.47e-07\n",
      "Epoch 122/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0018 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.9089 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9678 - lr: 8.9425e-06\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 8.353937964495029e-06.\n",
      "learning rate: 8.35e-06, weight decay: 4.18e-07\n",
      "Epoch 123/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0016 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6356 - val_acc: 0.9060 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9718 - lr: 8.3539e-06\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 7.783603724899257e-06.\n",
      "learning rate: 7.78e-06, weight decay: 3.89e-07\n",
      "Epoch 124/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0015 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6769 - val_acc: 0.9044 - val_top_5_acc: 0.9580 - val_top_10_acc: 0.9680 - lr: 7.7836e-06\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 7.2317869919746705e-06.\n",
      "learning rate: 7.23e-06, weight decay: 3.62e-07\n",
      "Epoch 125/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0014 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.9095 - val_top_5_acc: 0.9596 - val_top_10_acc: 0.9714 - lr: 7.2318e-06\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 6.698729810778065e-06.\n",
      "learning rate: 6.70e-06, weight decay: 3.35e-07\n",
      "Epoch 126/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0015 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.9064 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9692 - lr: 6.6987e-06\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 6.184665997806832e-06.\n",
      "learning rate: 6.18e-06, weight decay: 3.09e-07\n",
      "Epoch 127/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0017 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6674 - val_acc: 0.9067 - val_top_5_acc: 0.9569 - val_top_10_acc: 0.9681 - lr: 6.1847e-06\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 5.689821038439263e-06.\n",
      "learning rate: 5.69e-06, weight decay: 2.84e-07\n",
      "Epoch 128/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0013 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.9084 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9717 - lr: 5.6898e-06\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 5.214411988029355e-06.\n",
      "learning rate: 5.21e-06, weight decay: 2.61e-07\n",
      "Epoch 129/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.9070 - val_top_5_acc: 0.9590 - val_top_10_acc: 0.9700 - lr: 5.2144e-06\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 4.758647376699032e-06.\n",
      "learning rate: 4.76e-06, weight decay: 2.38e-07\n",
      "Epoch 130/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6343 - val_acc: 0.9086 - val_top_5_acc: 0.9613 - val_top_10_acc: 0.9723 - lr: 4.7586e-06\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 4.322727117869951e-06.\n",
      "learning rate: 4.32e-06, weight decay: 2.16e-07\n",
      "Epoch 131/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6670 - val_acc: 0.9098 - val_top_5_acc: 0.9589 - val_top_10_acc: 0.9691 - lr: 4.3227e-06\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 3.90684242057498e-06.\n",
      "learning rate: 3.91e-06, weight decay: 1.95e-07\n",
      "Epoch 132/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.9127 - val_top_5_acc: 0.9619 - val_top_10_acc: 0.9723 - lr: 3.9068e-06\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 3.511175705587433e-06.\n",
      "learning rate: 3.51e-06, weight decay: 1.76e-07\n",
      "Epoch 133/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6844 - val_acc: 0.9055 - val_top_5_acc: 0.9594 - val_top_10_acc: 0.9699 - lr: 3.5112e-06\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 3.1359005254054273e-06.\n",
      "learning rate: 3.14e-06, weight decay: 1.57e-07\n",
      "Epoch 134/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6135 - val_acc: 0.9102 - val_top_5_acc: 0.9635 - val_top_10_acc: 0.9739 - lr: 3.1359e-06\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 2.7811814881259503e-06.\n",
      "learning rate: 2.78e-06, weight decay: 1.39e-07\n",
      "Epoch 135/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6669 - val_acc: 0.9079 - val_top_5_acc: 0.9601 - val_top_10_acc: 0.9698 - lr: 2.7812e-06\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 2.4471741852423237e-06.\n",
      "learning rate: 2.45e-06, weight decay: 1.22e-07\n",
      "Epoch 136/150\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6813 - val_acc: 0.9075 - val_top_5_acc: 0.9576 - val_top_10_acc: 0.9697 - lr: 2.4472e-06\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 2.134025123396638e-06.\n",
      "learning rate: 2.13e-06, weight decay: 1.07e-07\n",
      "Epoch 137/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6576 - val_acc: 0.9086 - val_top_5_acc: 0.9609 - val_top_10_acc: 0.9717 - lr: 2.1340e-06\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 1.841871660117095e-06.\n",
      "learning rate: 1.84e-06, weight decay: 9.21e-08\n",
      "Epoch 138/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6678 - val_acc: 0.9056 - val_top_5_acc: 0.9590 - val_top_10_acc: 0.9699 - lr: 1.8419e-06\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 1.5708419435684462e-06.\n",
      "learning rate: 1.57e-06, weight decay: 7.85e-08\n",
      "Epoch 139/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 0.0012 - acc: 0.9999 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6599 - val_acc: 0.9079 - val_top_5_acc: 0.9604 - val_top_10_acc: 0.9705 - lr: 1.5708e-06\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 1.3210548563419856e-06.\n",
      "learning rate: 1.32e-06, weight decay: 6.61e-08\n",
      "Epoch 140/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.9141e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.9104 - val_top_5_acc: 0.9603 - val_top_10_acc: 0.9708 - lr: 1.3211e-06\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 1.0926199633097157e-06.\n",
      "learning rate: 1.09e-06, weight decay: 5.46e-08\n",
      "Epoch 141/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0011 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6863 - val_acc: 0.9081 - val_top_5_acc: 0.9577 - val_top_10_acc: 0.9683 - lr: 1.0926e-06\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 8.856374635655695e-07.\n",
      "learning rate: 8.86e-07, weight decay: 4.43e-08\n",
      "Epoch 142/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.9442e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6368 - val_acc: 0.9100 - val_top_5_acc: 0.9598 - val_top_10_acc: 0.9718 - lr: 8.8564e-07\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 7.001981464747565e-07.\n",
      "learning rate: 7.00e-07, weight decay: 3.50e-08\n",
      "Epoch 143/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 0.0010 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6307 - val_acc: 0.9106 - val_top_5_acc: 0.9604 - val_top_10_acc: 0.9714 - lr: 7.0020e-07\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 5.363833518505834e-07.\n",
      "learning rate: 5.36e-07, weight decay: 2.68e-08\n",
      "Epoch 144/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.6860e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6662 - val_acc: 0.9085 - val_top_5_acc: 0.9583 - val_top_10_acc: 0.9689 - lr: 5.3638e-07\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 3.9426493427611177e-07.\n",
      "learning rate: 3.94e-07, weight decay: 1.97e-08\n",
      "Epoch 145/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.4263e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6162 - val_acc: 0.9142 - val_top_5_acc: 0.9626 - val_top_10_acc: 0.9726 - lr: 3.9426e-07\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 2.7390523158633554e-07.\n",
      "learning rate: 2.74e-07, weight decay: 1.37e-08\n",
      "Epoch 146/150\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 9.1748e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6699 - val_acc: 0.9104 - val_top_5_acc: 0.9585 - val_top_10_acc: 0.9699 - lr: 2.7391e-07\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 1.753570375247815e-07.\n",
      "learning rate: 1.75e-07, weight decay: 8.77e-09\n",
      "Epoch 147/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.7266e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6580 - val_acc: 0.9084 - val_top_5_acc: 0.9587 - val_top_10_acc: 0.9705 - lr: 1.7536e-07\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 9.866357858642205e-08.\n",
      "learning rate: 9.87e-08, weight decay: 4.93e-09\n",
      "Epoch 148/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.4557e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.9074 - val_top_5_acc: 0.9597 - val_top_10_acc: 0.9712 - lr: 9.8664e-08\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 4.385849505708084e-08.\n",
      "learning rate: 4.39e-08, weight decay: 2.19e-09\n",
      "Epoch 149/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.8476e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6528 - val_acc: 0.9094 - val_top_5_acc: 0.9603 - val_top_10_acc: 0.9709 - lr: 4.3858e-08\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 1.096582625772502e-08.\n",
      "learning rate: 1.10e-08, weight decay: 5.48e-10\n",
      "Epoch 150/150\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 9.3031e-04 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.6371 - val_acc: 0.9099 - val_top_5_acc: 0.9616 - val_top_10_acc: 0.9719 - lr: 1.0966e-08\n"
     ]
    }
   ],
   "source": [
    "# Clear all models in GPU\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Get new fresh model\n",
    "model = get_model()\n",
    "\n",
    "# Sanity Check\n",
    "model.summary()\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Actual Training\n",
    "history = model.fit(\n",
    "        train.batch(config['TRAIN_BATCH_SIZE']),\n",
    "        epochs=config[\"N_EPOCHS\"],\n",
    "        validation_data=validation.batch(config[\"BATCH_SIZE_VAL\"]),\n",
    "        callbacks=[\n",
    "            lr_callback,\n",
    "            WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "            tensorboard_callback\n",
    "          ],\n",
    "        verbose = VERBOSE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57044d51",
   "metadata": {
    "papermill": {
     "duration": 0.204275,
     "end_time": "2023-03-27T14:38:44.950811",
     "exception": false,
     "start_time": "2023-03-27T14:38:44.746536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Model Weights\n",
    "version = 2\n",
    "model.save_weights(f'tf_models/v{version}_model.h5')\n",
    "\n",
    "s3_client.upload_file(Filename=f'tf_models/v{version}_model.h5',\n",
    "                  Bucket=AWS_S3_BUCKET_2,\n",
    "                  Key=f'tf_models/v{version}_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bba959c-57d7-4713-ad74-874445d85f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_weights('tf_models/v2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516b9302-f002-426c-9e48-c46602128c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 03:13:38.552300: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n",
      "2023-04-17 03:13:42.025664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [94477]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/37 [>.............................] - ETA: 2s - loss: 1.1681 - acc: 0.8574 - top_5_acc: 0.9199 - top_10_acc: 0.9395  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 03:13:43.950460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 8s 65ms/step - loss: 1.0748 - acc: 0.8523 - top_5_acc: 0.9350 - top_10_acc: 0.9527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.074845314025879, 0.8522595167160034, 0.9350195527076721, 0.9526934027671814]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test.batch(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d14b4130-dc12-48dd-a7e1-d7115c7aa684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)\n",
    "train = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "486c508a-d03a-4eee-a4a8-09ac30d535d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:50:43.903623: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6519668816 exceeds 10% of free system memory.\n",
      "2023-04-16 23:50:47.360960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [94477]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 7s 66ms/step - loss: 1.0806 - acc: 0.8476 - top_5_acc: 0.9333 - top_10_acc: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0806025266647339, 0.847602903842926, 0.9333263039588928, 0.9506826400756836]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test.batch(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33e4aec0",
   "metadata": {
    "papermill": {
     "duration": 0.071523,
     "end_time": "2023-03-27T14:38:45.085266",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.013743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:51:58.658396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [94477,38,454]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 7s - 7s/epoch - 182ms/step\n"
     ]
    }
   ],
   "source": [
    "if USE_VAL:\n",
    "    # Validation Predictions\n",
    "    # y_val_pred = model.predict({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, verbose=2).argmax(axis=1)\n",
    "    y_val_pred = model.predict(test.batch(256), verbose=2).argmax(axis=1)\n",
    "    # Label\n",
    "    labels = [ORD2SIGN.get(i).replace(' ', '_') for i in range(config[\"NUM_CLASSES\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb6244",
   "metadata": {
    "papermill": {
     "duration": 0.061014,
     "end_time": "2023-03-27T14:38:45.207893",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.146879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Landmark Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8fa652a3",
   "metadata": {
    "papermill": {
     "duration": 0.077022,
     "end_time": "2023-03-27T14:38:45.348287",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.271265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.4831787e-06 4.2217339e-06 4.0389109e-06 ... 3.8456005e-06\n",
      "  3.9571082e-06 3.5290893e-06]\n",
      " [3.8667940e-06 3.7853288e-06 3.9586826e-06 ... 3.6997953e-06\n",
      "  3.9790425e-06 3.5286801e-06]\n",
      " [3.5608664e-06 3.5726960e-06 3.7164696e-06 ... 3.7078044e-06\n",
      "  3.5248988e-06 3.8749135e-06]\n",
      " ...\n",
      " [3.9577944e-06 4.1331118e-06 3.6747008e-06 ... 3.8603089e-06\n",
      "  3.8545190e-06 4.0105574e-06]\n",
      " [3.6919330e-06 4.1983135e-06 4.2047991e-06 ... 4.2108645e-06\n",
      "  3.4382376e-06 4.0052541e-06]\n",
      " [3.6628444e-06 3.8444200e-06 3.8703133e-06 ... 3.9305851e-06\n",
      "  4.0081527e-06 3.7639352e-06]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Learned attention weights, initialized at uniform 25%\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w, lm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(weights, landmarks):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weight: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(w\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "# Landmark Weights\n",
    "weights = scipy.special.softmax(model.get_layer('embedding').weights[15])\n",
    "\n",
    "print(weights)\n",
    "\n",
    "landmarks = ['face_embedding', 'left_hand_embedding', 'pose_embedding', 'right_hand_embedding']\n",
    "\n",
    "# Learned attention weights, initialized at uniform 25%\n",
    "for w, lm in zip(weights, landmarks):\n",
    "    print(f'{lm} weight: {(w*100):.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a83df4",
   "metadata": {
    "papermill": {
     "duration": 0.061678,
     "end_time": "2023-03-27T14:38:45.472071",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.410393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5a638",
   "metadata": {
    "papermill": {
     "duration": 0.073852,
     "end_time": "2023-03-27T14:38:45.607733",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.533881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_classification_report():\n",
    "    # Classification report for all signs\n",
    "    classification_report = sklearn.metrics.classification_report(\n",
    "            y_val,\n",
    "            y_val_pred,\n",
    "            target_names=labels,\n",
    "            output_dict=True,\n",
    "        )\n",
    "    # Round Data for better readability\n",
    "    classification_report = pd.DataFrame(classification_report).T\n",
    "    classification_report = classification_report.round(2)\n",
    "    classification_report = classification_report.astype({\n",
    "            'support': np.uint16,\n",
    "        })\n",
    "    # Add signs\n",
    "    classification_report['sign'] = [e if e in SIGN2ORD else -1 for e in classification_report.index]\n",
    "    classification_report['sign_ord'] = classification_report['sign'].apply(SIGN2ORD.get).fillna(-1).astype(np.int16)\n",
    "    # Sort on F1-score\n",
    "    classification_report = pd.concat((\n",
    "        classification_report.head(config[\"NUM_CLASSES\"]).sort_values('f1-score', ascending=False),\n",
    "        classification_report.tail(3),\n",
    "    ))\n",
    "\n",
    "    pd.options.display.max_rows = 999\n",
    "    display(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acd2cd",
   "metadata": {
    "papermill": {
     "duration": 0.114632,
     "end_time": "2023-03-27T14:38:45.783594",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.668962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1337c59",
   "metadata": {
    "papermill": {
     "duration": 0.06176,
     "end_time": "2023-03-27T14:38:45.907383",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.845623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b50c7b",
   "metadata": {
    "papermill": {
     "duration": 0.078619,
     "end_time": "2023-03-27T14:38:46.047474",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.968855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history_metric(metric, f_best=np.argmax, ylim=None, yscale=None, yticks=None):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    values = history.history[metric]\n",
    "    config[\"N_EPOCHS\"] = len(values)\n",
    "    val = 'val' in ''.join(history.history.keys())\n",
    "    # Epoch Ticks\n",
    "    if config[\"N_EPOCHS\"] <= 20:\n",
    "        x = np.arange(1, config[\"N_EPOCHS\"] + 1)\n",
    "    else:\n",
    "        x = [1, 5] + [10 + 5 * idx for idx in range((config[\"N_EPOCHS\"] - 10) // 5 + 1)]\n",
    "\n",
    "    x_ticks = np.arange(1, config[\"N_EPOCHS\"]+1)\n",
    "\n",
    "    # Validation\n",
    "    if val:\n",
    "        val_values = history.history[f'val_{metric}']\n",
    "        val_argmin = f_best(val_values)\n",
    "        plt.plot(x_ticks, val_values, label=f'val')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(x_ticks, values, label=f'train')\n",
    "    argmin = f_best(values)\n",
    "    plt.scatter(argmin + 1, values[argmin], color='red', s=75, marker='o', label=f'train_best')\n",
    "    if val:\n",
    "        plt.scatter(val_argmin + 1, val_values[val_argmin], color='purple', s=75, marker='o', label=f'val_best')\n",
    "\n",
    "    plt.title(f'Model {metric}', fontsize=24, pad=10)\n",
    "    plt.ylabel(metric, fontsize=20, labelpad=10)\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    if yscale is not None:\n",
    "        plt.yscale(yscale)\n",
    "        \n",
    "    if yticks is not None:\n",
    "        plt.yticks(yticks, fontsize=16)\n",
    "\n",
    "    plt.xlabel('epoch', fontsize=20, labelpad=10)        \n",
    "    plt.tick_params(axis='x', labelsize=8)\n",
    "    plt.xticks(x, fontsize=16) # set tick step to 1 and let x axis start at 1\n",
    "    plt.yticks(fontsize=16)\n",
    "    \n",
    "    plt.legend(prop={'size': 10})\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36b11b",
   "metadata": {
    "papermill": {
     "duration": 0.457464,
     "end_time": "2023-03-27T14:38:46.565722",
     "exception": false,
     "start_time": "2023-03-27T14:38:46.108258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('loss', f_best=np.argmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14124968",
   "metadata": {
    "papermill": {
     "duration": 0.454542,
     "end_time": "2023-03-27T14:38:47.085510",
     "exception": false,
     "start_time": "2023-03-27T14:38:46.630968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac7785",
   "metadata": {
    "papermill": {
     "duration": 0.465536,
     "end_time": "2023-03-27T14:38:47.618068",
     "exception": false,
     "start_time": "2023-03-27T14:38:47.152532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('top_5_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd063e4",
   "metadata": {
    "papermill": {
     "duration": 0.454357,
     "end_time": "2023-03-27T14:38:48.149474",
     "exception": false,
     "start_time": "2023-03-27T14:38:47.695117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('top_10_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2759c7",
   "metadata": {
    "papermill": {
     "duration": 0.065813,
     "end_time": "2023-03-27T14:38:48.284324",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.218511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Submission code loosley based on [this notebook](https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline#baseline) by [Darien Schettler\n",
    "](https://www.kaggle.com/dschettler8845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e007edb3-ef8c-49d0-8c7c-29c5720c1fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, s3_client, columns=data_columns)\n",
    "    n_frames = int(len(data) / 543)\n",
    "    data = data.values.reshape(n_frames, 543, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32198c2a-d17e-4104-9fc8-a1b1c0457cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "class PreprocessLayerV2(tf.keras.layers.Layer):\n",
    "    def __init__(self, INPUT_SIZE):\n",
    "        super(PreprocessLayerV2, self).__init__()\n",
    "        self.INPUT_SIZE = INPUT_SIZE\n",
    "        # Indicies in original data. \n",
    "        self.FACE_IDXS = tf.constant([0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467], dtype=tf.int32)\n",
    "        self.POSE_IDXS = tf.constant(tf.range(489, 514, delta=1, dtype=tf.int32))\n",
    "        self.LEFT_HAND_IDXS = tf.constant(tf.range(468, 489, delta=1, dtype=tf.int32))\n",
    "        self.RIGHT_HAND_IDXS = tf.constant(tf.range(522, 543, delta=1, dtype=tf.int32))\n",
    "        \n",
    "        self.HAND_IDXS = tf.constant(tf.concat([self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "            \n",
    "        # All landmarks that are used for modeling. \n",
    "        self.LANDMARK_IDXS = tf.constant(tf.concat([self.FACE_IDXS, self.POSE_IDXS, self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "        \n",
    "        # Indicies after landmarks have been filtered. \n",
    "        self.FACE_START = tf.constant(0, dtype=tf.int32)\n",
    "        self.LEFT_HAND_START = tf.constant(len(self.FACE_IDXS), dtype=tf.int32)\n",
    "        self.POSE_START = tf.constant(self.LEFT_HAND_START + len(self.LEFT_HAND_IDXS), dtype=tf.int32)\n",
    "        self.RIGHT_HAND_START = tf.constant(self.POSE_START + len(self.POSE_IDXS), dtype=tf.int32)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'INPUT_SIZE': self.INPUT_SIZE,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def get_mean_std(self, LIPS_IDXS, data):\n",
    "                \n",
    "        xs = tf.reshape(tf.transpose(data, [2,0,1]), [2,tf.size(LIPS_IDXS)*tf.shape(data)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(data, [2,0,1]), [2,tf.size(LIPS_IDXS)*tf.shape(data)[0]])[1]\n",
    "            \n",
    "        LIPS_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        LIPS_STD_X = tf.math.reduce_std(xs)\n",
    "        LIPS_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        LIPS_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        LIPS_MEAN = tf.stack([LIPS_MEAN_X, LIPS_MEAN_Y])\n",
    "        LIPS_STD = tf.stack([LIPS_STD_X, LIPS_STD_Y])\n",
    "\n",
    "        return LIPS_MEAN, LIPS_STD\n",
    "    \n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[None, 543, 2], dtype=tf.float32),),)\n",
    "    def call(self, data):\n",
    "        \n",
    "        # Filter Out Frames With Empty Hand Data\n",
    "        frames_hands_nansum = tf.experimental.numpy.nanmean(tf.gather(data, self.HAND_IDXS, axis=1), axis=[1,2])\n",
    "        non_empty_frames_idxs = tf.where(frames_hands_nansum > 0)\n",
    "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
    "        data = tf.gather(data, non_empty_frames_idxs, axis=0)\n",
    "        \n",
    "        # Cast Indices in float32 to be compatible with Tensorflow Lite\n",
    "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32) \n",
    "        \n",
    "        N_FRAMES = tf.shape(data)[0]\n",
    "        data = tf.gather(data, self.LANDMARK_IDXS, axis=1)\n",
    "        \n",
    "        # Slice out face indicies, normalize across batch.        \n",
    "        face = tf.slice(data, [0, self.FACE_START, 0], [N_FRAMES, self.LEFT_HAND_START, 2])\n",
    "        face_mean, face_std = self.get_mean_std(self.FACE_IDXS, face)\n",
    "        face = tf.where(\n",
    "                    tf.math.equal(face, 0.0),\n",
    "                    0.0,\n",
    "                    (face - face_mean) / face_std,\n",
    "                )\n",
    "        # face = tf.keras.utils.normalize(face, axis=-1, order=2)\n",
    "        \n",
    "#         # Slice out left_hand indicies, normalize across batch.\n",
    "        left_hand = tf.slice(data, [0, self.LEFT_HAND_START, 0], [N_FRAMES, self.POSE_START-self.LEFT_HAND_START, 2])\n",
    "        # left_hand = tf.keras.utils.normalize(left_hand, axis=1, order=2)\n",
    "        # left_hand = tf.linalg.normalize(left_hand, axis=1)\n",
    "        left_hand_mean, left_hand_std = self.get_mean_std(self.LEFT_HAND_IDXS, left_hand)\n",
    "        left_hand = tf.where(\n",
    "                    tf.math.equal(left_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (left_hand - left_hand_mean) / left_hand_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out pose indicies, normalize across batch.\n",
    "        pose = tf.slice(data, [0, self.POSE_START, 0], [N_FRAMES, self.RIGHT_HAND_START-self.POSE_START, 2])\n",
    "        # pose = tf.keras.utils.normalize(pose, axis=1, order=2)\n",
    "        pose_mean, pose_std = self.get_mean_std(self.POSE_IDXS, pose)\n",
    "        pose = tf.where(\n",
    "                    tf.math.equal(pose, 0.0),\n",
    "                    0.0,\n",
    "                    (pose - pose_mean) / pose_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out right_hand indicies, normalize across batch.\n",
    "        right_hand = tf.slice(data, [0, self.RIGHT_HAND_START, 0], [N_FRAMES, tf.shape(data)[1] - self.RIGHT_HAND_START, 2])\n",
    "#         # right_hand = tf.keras.utils.normalize(right_hand, axis=1, order=2)\n",
    "        right_hand_mean, right_hand_std = self.get_mean_std(self.RIGHT_HAND_IDXS, right_hand)\n",
    "        right_hand = tf.where(\n",
    "                    tf.math.equal(right_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (right_hand - right_hand_mean) / right_hand_std,\n",
    "                )\n",
    "        \n",
    "        \n",
    "        # Concat landmarks back into same frame.\n",
    "        data = tf.concat([face, left_hand, pose, right_hand], 1)\n",
    "        \n",
    "        \n",
    "        # Video fits in self.INPUT_SIZE\n",
    "        if N_FRAMES < self.INPUT_SIZE: # Number of frames we want\n",
    "            # Attention mask for frames that contain data. \n",
    "            \n",
    "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, self.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            # non_empty_frames_idxs = tf.pad(tf.range(0, N_FRAMES, 1), [[0, self.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            data = tf.pad(data, [[0, self.INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2))\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            return data, non_empty_frames_idxs\n",
    "        # Video needs to be downsampled to INPUT_SIZE\n",
    "        else:\n",
    "            # Downsample video using nearest interpolation method. \n",
    "            data = tf.image.resize(data, size=(self.INPUT_SIZE, data.shape[1]), method='nearest')\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2)).\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            # Create attention mask with all frames. \n",
    "            non_empty_frames_idxs = tf.range(0, self.INPUT_SIZE, 1, dtype=tf.float32)\n",
    "            return data, non_empty_frames_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4fe964bf-4964-4325-a546-5ae3419aa2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_layer = PreprocessLayerV2(config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be6db790-f7fe-4c06-8ef0-728d13a052db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(38, 454), dtype=float32, numpy=\n",
       " array([[ 0.35477105,  0.77816063,  0.27789864, ..., -0.5786116 ,\n",
       "          0.76873696, -0.6725151 ],\n",
       "        [-0.27624363,  0.67679495, -0.35129297, ...,  1.3697093 ,\n",
       "          0.7903673 ,  1.5212379 ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(38,), dtype=float32, numpy=\n",
       " array([ 0., 10., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_layer(load_relevant_data_subset(\"w251-asl-data/raw-data/train_landmark_files/28656/1000106739.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2d90f75e-be10-4802-85d5-0af5725773f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "de757ec9-f1d0-4484-a2d9-d3920d356e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inputs = tf.keras.Input(shape=(config[\"N_ROWS\"], config[\"N_DIMS\"]))\n",
    "# x, non_empty_frame_idxs = preprocess_layer(inputs)\n",
    "# # outputs = training_model(x)\n",
    "# preprocess_model = tf.keras.Model(inputs=inputs, outputs=[x, non_empty_frame_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8d2d0a9",
   "metadata": {
    "papermill": {
     "duration": 1.644953,
     "end_time": "2023-03-27T14:38:49.995113",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.350160",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TFLite model for submission\n",
    "class TFLiteModel(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.preprocess_layer = preprocess_layer\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, config[\"N_ROWS\"], config[\"N_DIMS\"]], dtype=tf.float32, name='inputs')])\n",
    "    def call(self, inputs):\n",
    "        # Preprocess Data\n",
    "        x, non_empty_frame_idxs = self.preprocess_layer(inputs)\n",
    "        # Add Batch Dimension\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
    "        # Make Prediction\n",
    "        outputs = self.model({'FRAMES': x, 'NON_EMPTY_FRAME_IDXS': non_empty_frame_idxs })\n",
    "        # Squeeze Output 1x250 -> 250\n",
    "        outputs = tf.squeeze(outputs, axis=0)\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "# Define TF Lite Model\n",
    "tflite_keras_model = TFLiteModel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3071a4d9",
   "metadata": {
    "papermill": {
     "duration": 32.570402,
     "end_time": "2023-03-27T14:39:22.633212",
     "exception": false,
     "start_time": "2023-03-27T14:38:50.062810",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.TFLiteModel object at 0x7f6abe6eee30>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.TFLiteModel object at 0x7f6abe6eee30>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "2023-04-17 04:02:39.733446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:39.733558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocess_layer_v2_6/155764' with dtype int32 and shape [227]\n",
      "\t [[{{node preprocess_layer_v2_6/155764}}]]\n",
      "2023-04-17 04:02:40.167777: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.167888: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '156862' with dtype int32 and shape [227]\n",
      "\t [[{{node 156862}}]]\n",
      "2023-04-17 04:02:40.350306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'data' with dtype float and shape [?,543,2]\n",
      "\t [[{{node data}}]]\n",
      "2023-04-17 04:02:40.350411: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '157459' with dtype int32 and shape [227]\n",
      "\t [[{{node 157459}}]]\n",
      "2023-04-17 04:02:40.385494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.405155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.412982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.419063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.425125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.431222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.435742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.440086: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.446637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.452226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.481358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.500518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.508317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.514326: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.520368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.526379: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.531013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.535315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.541718: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.547305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.575429: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.596484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.604770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.610844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.616877: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.623043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.627442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.631826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.638374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.643938: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.672225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.691371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.699205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.705193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.711357: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.717277: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-17 04:02:40.721814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.726076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.732586: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.738204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.767037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 04:02:40.786077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 04:02:40.793840: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.800300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 04:02:40.807240: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.813231: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-17 04:02:40.817674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.822030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.828432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.833960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.894988: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 04:02:40.922494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 04:02:40.934190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.942457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 04:02:40.949030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.957171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-17 04:02:40.962080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.966393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.973511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.981829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:40.988207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.022752: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 04:02:41.050528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 04:02:41.062089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.070285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 04:02:41.076853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.084882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-17 04:02:41.089847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.094256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.101424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.109572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.115882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.152606: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-17 04:02:41.152711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocess_layer_v2_6/158746' with dtype int32 and shape [227]\n",
      "\t [[{{node preprocess_layer_v2_6/158746}}]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'tf_lite_model_6' (type TFLiteModel).\n\nin user code:\n\n    File \"/tmp/ipykernel_2262/4121770572.py\", line 18, in call  *\n        outputs = self.model({'FRAMES': x, 'NON_EMPTY_FRAME_IDXS': non_empty_frame_idxs })\n    File \"/opt/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Binding inputs to tf.function `embedding_layer_call_and_return_conditional_losses` failed due to `missing a required argument: 'non_empty_frame_idxs'`.Received args: (<tf.Tensor 'tf.slice/Slice:0' shape=(1, 38, 320) dtype=float32>, <tf.Tensor 'tf.slice_1/Slice:0' shape=(1, 38, 42) dtype=float32>, <tf.Tensor 'tf.slice_3/Slice:0' shape=(1, 38, 42) dtype=float32>, <tf.Tensor 'tf.slice_2/Slice:0' shape=(1, 38, 50) dtype=float32>, <tf.Tensor 'inputs_1:0' shape=(1, None) dtype=float32>) and kwargs: {'training': False} for signature: (self, face0, left_hand0, right_hand0, pose0, non_empty_frame_idxs, training=<object object at 0x7f74c4188390>).\n\n\nCall arguments received by layer 'tf_lite_model_6' (type TFLiteModel):\n  â€¢ inputs=tf.Tensor(shape=(None, 543, 2), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m keras_model_converter\u001b[38;5;241m.\u001b[39mexperimental_new_converter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Convert Model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_model_converter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Write Model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtflite_models/v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_again_model.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:962\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    961\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 962\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:940\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m    939\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m--> 940\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1378\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1375\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n\u001b[1;32m   1377\u001b[0m graph_def, input_tensors, output_tensors, frozen_func \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_freeze_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1380\u001b[0m graph_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tf_model(graph_def, input_tensors,\n\u001b[1;32m   1381\u001b[0m                                     output_tensors, frozen_func)\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2,\n\u001b[1;32m   1384\u001b[0m              \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(graph_def, input_tensors, output_tensors)\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[0;32m--> 215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1330\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._freeze_keras_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m func \u001b[38;5;241m=\u001b[39m _trace_model_call(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_model, input_signature)\n\u001b[0;32m-> 1330\u001b[0m concrete_func \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_funcs \u001b[38;5;241m=\u001b[39m [concrete_func]\n\u001b[1;32m   1333\u001b[0m frozen_func, graph_def \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1334\u001b[0m     _convert_to_constants\u001b[38;5;241m.\u001b[39mconvert_variables_to_constants_v2_as_graph(\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_funcs[\u001b[38;5;241m0\u001b[39m], lower_control_flow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1258\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1257\u001b[0m   \u001b[38;5;66;03m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1258\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1238\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1242\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/tflite_keras_util.py:190\u001b[0m, in \u001b[0;36mtrace_model_call.<locals>._wrapped_model\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    186\u001b[0m inputs \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_signature) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m keras_deps\u001b[38;5;241m.\u001b[39mget_call_context_function()()\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m    189\u001b[0m     model, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, saving\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 190\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filedtu91dtt.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[1;32m     12\u001b[0m non_empty_frame_idxs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(non_empty_frame_idxs),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFRAMES\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNON_EMPTY_FRAME_IDXS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_empty_frame_idxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msqueeze, (ag__\u001b[38;5;241m.\u001b[39mld(outputs),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'tf_lite_model_6' (type TFLiteModel).\n\nin user code:\n\n    File \"/tmp/ipykernel_2262/4121770572.py\", line 18, in call  *\n        outputs = self.model({'FRAMES': x, 'NON_EMPTY_FRAME_IDXS': non_empty_frame_idxs })\n    File \"/opt/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Binding inputs to tf.function `embedding_layer_call_and_return_conditional_losses` failed due to `missing a required argument: 'non_empty_frame_idxs'`.Received args: (<tf.Tensor 'tf.slice/Slice:0' shape=(1, 38, 320) dtype=float32>, <tf.Tensor 'tf.slice_1/Slice:0' shape=(1, 38, 42) dtype=float32>, <tf.Tensor 'tf.slice_3/Slice:0' shape=(1, 38, 42) dtype=float32>, <tf.Tensor 'tf.slice_2/Slice:0' shape=(1, 38, 50) dtype=float32>, <tf.Tensor 'inputs_1:0' shape=(1, None) dtype=float32>) and kwargs: {'training': False} for signature: (self, face0, left_hand0, right_hand0, pose0, non_empty_frame_idxs, training=<object object at 0x7f74c4188390>).\n\n\nCall arguments received by layer 'tf_lite_model_6' (type TFLiteModel):\n  â€¢ inputs=tf.Tensor(shape=(None, 543, 2), dtype=float32)"
     ]
    }
   ],
   "source": [
    "version = 2\n",
    "# Create Model Converter\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "keras_model_converter.experimental_new_converter = True\n",
    "\n",
    "# Convert Model\n",
    "tflite_model = keras_model_converter.convert()\n",
    "# Write Model\n",
    "with open(f'tflite_models/v{version}_again_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "# Zip Model\n",
    "# !zip submission.zip /kaggle/working/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848181e8-9e30-471e-bc5c-b37340640edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "demo_raw_data = load_relevant_data_subset(train['path'].values[5])\n",
    "print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n",
    "demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n",
    "print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n",
    "demo_prediction = demo_output.numpy().argmax()\n",
    "print(f'demo_prediction: {demo_prediction}, correct: {train.iloc[0][\"sign_ord\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5493473",
   "metadata": {
    "papermill": {
     "duration": 11.438209,
     "end_time": "2023-03-27T14:39:34.137659",
     "exception": false,
     "start_time": "2023-03-27T14:39:22.699450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid signature_key provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtflite_models/v2_model.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m found_signatures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(interpreter\u001b[38;5;241m.\u001b[39mget_signature_list()\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 7\u001b[0m prediction_fn \u001b[38;5;241m=\u001b[39m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_signature_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m output \u001b[38;5;241m=\u001b[39m prediction_fn(inputs\u001b[38;5;241m=\u001b[39mX[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     10\u001b[0m sign \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39margmax()\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:835\u001b[0m, in \u001b[0;36mInterpreter.get_signature_runner\u001b[0;34m(self, signature_key)\u001b[0m\n\u001b[1;32m    833\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    834\u001b[0m     signature_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_defs))\n\u001b[0;32m--> 835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignatureRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:207\u001b[0m, in \u001b[0;36mSignatureRunner.__init__\u001b[0;34m(self, interpreter, signature_key)\u001b[0m\n\u001b[1;32m    205\u001b[0m signature_defs \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39m_get_full_signature_list()\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m signature_defs:\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid signature_key provided.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_def \u001b[38;5;241m=\u001b[39m signature_defs[signature_key]\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_def[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid signature_key provided."
     ]
    }
   ],
   "source": [
    "# Verify TFLite model can be loaded and used for prediction\n",
    "# !pip install tflite-runtime\n",
    "# import tf.lite.interpreter as tflite\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\"tflite_models/v2_model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=X[0])\n",
    "sign = output['outputs'].argmax()\n",
    "\n",
    "print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')\n",
    "print(\"TRUE : \", train.sign.values[0], f'[{train.sign_ord.values[0]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a012cb7b-2e6b-42f5-aa58-533a4fa2b266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interpreter.get_signature_list()\n",
    "\n",
    "input_data = load_relevant_data_subset(\"w251-asl-data/raw-data/train_landmark_files/28656/1000106739.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53553ec7-438b-4582-92ee-a16e547876fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 11 but expected 1 for dimension 0 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m output \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_output_details()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m input_1 \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_input_details()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[1;32m      6\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mget_tensor(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:696\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    681\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 11 but expected 1 for dimension 0 of input 0."
     ]
    }
   ],
   "source": [
    "output = interpreter.get_output_details()[0]\n",
    "input_1 = interpreter.get_input_details()[0]\n",
    "\n",
    "interpreter.set_tensor(input_1['index'], input_data)\n",
    "interpreter.invoke()\n",
    "interpreter.get_tensor(output['index']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d404318-27dd-471a-8ccc-d8d20ccc666f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'inputs',\n",
       " 'index': 0,\n",
       " 'shape': array([  1, 543,   2], dtype=int32),\n",
       " 'shape_signature': array([ -1, 543,   2], dtype=int32),\n",
       " 'dtype': numpy.float32,\n",
       " 'quantization': (0.0, 0),\n",
       " 'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "  'zero_points': array([], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7fcfda74-8b6d-40ba-ab0f-7d992948536d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Identity',\n",
       " 'index': 448,\n",
       " 'shape': array([250], dtype=int32),\n",
       " 'shape_signature': array([250], dtype=int32),\n",
       " 'dtype': numpy.float32,\n",
       " 'quantization': (0.0, 0),\n",
       " 'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "  'zero_points': array([], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ddddf2-5bb5-49c6-ab6c-5d5abc0dc550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3038.388613,
   "end_time": "2023-03-27T14:39:37.370611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-27T13:48:58.981998",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03d6f570ff764870bb73ccfb8c6887af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49350bdfb80d4f00a698d195ad6cc3e3",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6114b828351443dead1df1f805e5cfd7",
       "value": "100%"
      }
     },
     "07287dd36a6b457bab873107ef3a9a74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a3cb9fa235b4d3b9fe4729d0488ab41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0b6a231f62a24aae9fa0cbc3fb92820f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0bdd95bee39a4c0fba0d526a76e11ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5809fb0e32f44de489c4ffd133aed91d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ac638cb770cd4789a3ad5944574c0685",
       "value": " 1000/1000 [00:23&lt;00:00, 37.18it/s]"
      }
     },
     "0f47d306ae4c4968ae9578b5d3f96717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c0862516d904ef7a8308a72e5ae9f91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28320ac6793c47f69b05122f608c2d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0ef2e7de83043f5a1e56b8cbfdceb42",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b6a231f62a24aae9fa0cbc3fb92820f",
       "value": 1000
      }
     },
     "37eb2c935499475c89e659645e41c052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a30e5dd2b7e4e58b5f796dc56795f9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43441f82927941c183c36d4ba42c6839": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49104b8e9766498997f1c107709166cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49350bdfb80d4f00a698d195ad6cc3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fb37e6c0a6849b0ae4fca96c98079d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50b095287b764b40bc01eecfb8e226ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "549182ad731149e196c24e0c65368459": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54d833de2b3e4368a09e8f2832ae582a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43441f82927941c183c36d4ba42c6839",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_549182ad731149e196c24e0c65368459",
       "value": " 42/42 [00:06&lt;00:00,  6.63it/s]"
      }
     },
     "5809fb0e32f44de489c4ffd133aed91d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b6ddc597476439b98e2a8572db415ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f60bd20e6054b8d9990b2b2804e19a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6114b828351443dead1df1f805e5cfd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a008f4929ca442296cb2159b02d1206": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "873e173a1a48496183ab1a8b2425b3f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89aab12028bb44f0a421c39e5407e2c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a757d761f004d7faf0e86f35c7cc2ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d56ea444a554a8d86255febcfa438ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f60bd20e6054b8d9990b2b2804e19a1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_37eb2c935499475c89e659645e41c052",
       "value": "100%"
      }
     },
     "8e1a02523adf4a51928bd01fe6a016a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1b2e1be36c74ff5802bee0472d05a8c",
        "IPY_MODEL_974821174ce548f7ab78f2eb280a36bc",
        "IPY_MODEL_54d833de2b3e4368a09e8f2832ae582a"
       ],
       "layout": "IPY_MODEL_49104b8e9766498997f1c107709166cd"
      }
     },
     "974821174ce548f7ab78f2eb280a36bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fb37e6c0a6849b0ae4fca96c98079d3",
       "max": 42,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a3cb9fa235b4d3b9fe4729d0488ab41",
       "value": 42
      }
     },
     "97ebc5f11183491097eaa468c8f8d6ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fdf9f1a806d45d8afc6aa7674799d7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d56ea444a554a8d86255febcfa438ef",
        "IPY_MODEL_bc93196873734683876ec5f8b4b4c62c",
        "IPY_MODEL_d34a43c029834695b633aa4d4d941930"
       ],
       "layout": "IPY_MODEL_873e173a1a48496183ab1a8b2425b3f1"
      }
     },
     "a1b2e1be36c74ff5802bee0472d05a8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07287dd36a6b457bab873107ef3a9a74",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_fc0e155d7357432c9976cb2ac7c68b3a",
       "value": "100%"
      }
     },
     "ac638cb770cd4789a3ad5944574c0685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b0ba62ab3b254a6897d45bb7a753f044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b5005dde82d843e7a0b50cdf2669d881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d7996506467449ad9ba51cfb1e6db002",
        "IPY_MODEL_d0ff43d2109d482884de8add17da97e7",
        "IPY_MODEL_f9647d54b313481eaa72a3093a5dbc0a"
       ],
       "layout": "IPY_MODEL_1c0862516d904ef7a8308a72e5ae9f91"
      }
     },
     "bc93196873734683876ec5f8b4b4c62c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa12da626fe2424eb7a18e996ed1fb96",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b6ddc597476439b98e2a8572db415ee",
       "value": 10
      }
     },
     "d0ef2e7de83043f5a1e56b8cbfdceb42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0ff43d2109d482884de8add17da97e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a30e5dd2b7e4e58b5f796dc56795f9d",
       "max": 40,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_97ebc5f11183491097eaa468c8f8d6ba",
       "value": 40
      }
     },
     "d34a43c029834695b633aa4d4d941930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_50b095287b764b40bc01eecfb8e226ce",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7a008f4929ca442296cb2159b02d1206",
       "value": " 10/10 [00:02&lt;00:00,  5.02it/s]"
      }
     },
     "d7996506467449ad9ba51cfb1e6db002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8ec2cab76c64079add86c4cd9e47463",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0f47d306ae4c4968ae9578b5d3f96717",
       "value": "100%"
      }
     },
     "e8ec2cab76c64079add86c4cd9e47463": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edea63966eb74395b1ccf14ba9265099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_03d6f570ff764870bb73ccfb8c6887af",
        "IPY_MODEL_28320ac6793c47f69b05122f608c2d44",
        "IPY_MODEL_0bdd95bee39a4c0fba0d526a76e11ed7"
       ],
       "layout": "IPY_MODEL_89aab12028bb44f0a421c39e5407e2c2"
      }
     },
     "f9647d54b313481eaa72a3093a5dbc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a757d761f004d7faf0e86f35c7cc2ef",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b0ba62ab3b254a6897d45bb7a753f044",
       "value": " 40/40 [00:07&lt;00:00,  4.48it/s]"
      }
     },
     "fa12da626fe2424eb7a18e996ed1fb96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc0e155d7357432c9976cb2ac7c68b3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

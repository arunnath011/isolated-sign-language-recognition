{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4508e874",
   "metadata": {
    "papermill": {
     "duration": 0.016723,
     "end_time": "2023-03-27T13:49:08.191855",
     "exception": false,
     "start_time": "2023-03-27T13:49:08.175132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hello Fellow Kagglers,\n",
    "\n",
    "This notebook demonstrates the data processing and training process in Tensorflow.\n",
    "\n",
    "I am excited about this competition, because my Master Thesis was on sign language recognition.\n",
    "\n",
    "**Data Processing**\n",
    "\n",
    "Only lips, hands and arm pose coordinates are used.\n",
    "\n",
    "A custom Tensorflow layer handles the data processing. In short, it filters all frames without coordinates for the hands and downsamples the input to 32 frames if it is too long.\n",
    "\n",
    "**Model**\n",
    "\n",
    "A transformer based model is used. The embedding layer makes an ambedding per landmark(lips/left hand/right hand/arm pose) and merges these embedding with fully connected layers. The transformer consists of just 2 blocks with a simple mean pooling and fully connected layers for classification.\n",
    "\n",
    "\n",
    "**V2**\n",
    "\n",
    "* Learnable attention weights for each landmark\n",
    "* Removed layer normalisation in embedding to prevent double layer normalisation at the end of embedding and start of transformer\n",
    "* Removed additional fully connected layer in head before classification layer\n",
    "\n",
    "**V3**\n",
    "\n",
    "* Using all data for training\n",
    "* Increased final embedding size 384 -> 512\n",
    "* Added 10% dropout in classification layer\n",
    "* Increased number of epoch 50 -> 100\n",
    "* Number of transformer heads 8 -> 4\n",
    "\n",
    "If you have any feedback or questions, please feel free to leave a comment.\n",
    "\n",
    "Expect updates in the coming weeks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf87375-3103-443d-9e2c-dacd6b4b35a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow_addons\n",
    "# !pip install -q wandb\n",
    "# !pip install -q pyarrow\n",
    "# !pip install -q fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b76172",
   "metadata": {
    "papermill": {
     "duration": 8.299082,
     "end_time": "2023-03-27T13:49:16.506249",
     "exception": false,
     "start_time": "2023-03-27T13:49:08.207167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 01:02:52.376181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 01:02:53.018902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit \n",
    "\n",
    "from layers.PreprocessLayer import PreprocessLayer\n",
    "from utils.Utils import print_shape_dtype, pd_read_s3_parquet, upload_file \n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import boto3\n",
    "import io\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6783996",
   "metadata": {
    "papermill": {
     "duration": 0.014594,
     "end_time": "2023-03-27T13:49:16.606639",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.592045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdb3a65-55b9-40d5-b6c5-28144c027589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config.json\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf792f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Weights and Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e9f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.init(project='w251-asl-fp', \n",
    "           config=config,\n",
    "          sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09a2354",
   "metadata": {
    "papermill": {
     "duration": 0.024174,
     "end_time": "2023-03-27T13:49:16.646131",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.621957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_VAL = True\n",
    "\n",
    "DIM_NAMES = ['x', 'y']\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6a97b",
   "metadata": {
    "papermill": {
     "duration": 0.023506,
     "end_time": "2023-03-27T13:50:42.146814",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.123308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df8749",
   "metadata": {
    "papermill": {
     "duration": 0.03544,
     "end_time": "2023-03-27T13:50:42.205443",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.170003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom sampler to get a batch containing N times all signs\n",
    "def get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, batch_size=config[\"BATCH_ALL_SIGNS_N\"] # TODO: Change this in config file.):\n",
    "    # Arrays to store batch in\n",
    "    X_batch = np.zeros(batch_size, config[\"INPUT_SIZE\"], N_COLS, config[\"N_DIMS\"]], dtype=np.float32)\n",
    "    y_batch = np.arange(0, config[\"NUM_CLASSES\"], step=1/n, dtype=np.float32).astype(np.int64)\n",
    "    non_empty_frame_idxs_batch = np.zeros([config[\"NUM_CLASSES\"]*n, config[\"INPUT_SIZE\"]], dtype=np.float32)\n",
    "    \n",
    "    # Dictionary mapping ordinally encoded sign to corresponding sample indices\n",
    "    CLASS2IDXS = {}\n",
    "    for i in range(config[\"NUM_CLASSES\"]):\n",
    "        CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n",
    "            \n",
    "    while True:\n",
    "        # Fill batch arrays\n",
    "        for i in range(config[\"NUM_CLASSES\"]):\n",
    "            idxs = np.random.choice(CLASS2IDXS[i], n)\n",
    "            X_batch[i*n:(i+1)*n] = X[idxs]\n",
    "            non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n",
    "        \n",
    "        yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056ca475-bca9-445b-a5b2-739e07cfcb42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867a7a48-171b-4456-81ac-01e4cd4c5049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "176b9032-eb0a-4009-ba36-6e7c45f181f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (94477, 32, 92, 2), dtype: float32\n",
      "y shape: (94477,), dtype: int32\n",
      "NON_EMPTY_FRAME_IDXS shape: (94477, 32), dtype: float32\n",
      "# NaN Values X: 0\n"
     ]
    }
   ],
   "source": [
    "# data_version = config[\"DATA_VERSION\"]\n",
    "\n",
    "data_version = 1\n",
    "\n",
    "X = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{data_version}/X.npy')\n",
    "X = np.load(io.BytesIO(X['Body'].read()))\n",
    "\n",
    "y = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{data_version}/y.npy')\n",
    "y = np.load(io.BytesIO(y['Body'].read()))\n",
    "\n",
    "NON_EMPTY_FRAME_IDXS = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{data_version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "NON_EMPTY_FRAME_IDXS = np.load(io.BytesIO(NON_EMPTY_FRAME_IDXS['Body'].read()))\n",
    "    \n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "429150ec-4fd3-472d-a447-3198e1327673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sample():\n",
    "    for x_sample, y_sample, non_empty_frame_idxs_sample in zip(X, y, NON_EMPTY_FRAME_IDXS):\n",
    "        print(y_sample)\n",
    "        yield (x_sample, non_empty_frame_idxs_sample, np.array(y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51f642d5-bef5-45d9-9e79-8a903037fe89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 22 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1], shape=(32,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[0.468952  , 0.3912204 ],\n",
       "         [0.46855748, 0.38820282],\n",
       "         [0.47007626, 0.38500535],\n",
       "         ...,\n",
       "         [0.3069573 , 0.4628472 ],\n",
       "         [1.0892951 , 1.0785141 ],\n",
       "         [0.32036763, 0.49771583]],\n",
       " \n",
       "        [[0.46609   , 0.3935866 ],\n",
       "         [0.46797937, 0.39064983],\n",
       "         [0.47196886, 0.38727656],\n",
       "         ...,\n",
       "         [0.33220327, 0.41981807],\n",
       "         [1.0696523 , 1.1133848 ],\n",
       "         [0.34646925, 0.44962284]],\n",
       " \n",
       "        [[0.4625795 , 0.3956785 ],\n",
       "         [0.46426338, 0.39191473],\n",
       "         [0.4683729 , 0.38757092],\n",
       "         ...,\n",
       "         [0.35947007, 0.4036176 ],\n",
       "         [1.0731516 , 1.1004012 ],\n",
       "         [0.37707815, 0.44033766]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ]]], dtype=float32),\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 22., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.], dtype=float32),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 22, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       dtype=int32))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(get_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e3e79f6-0267-4628-882f-e56bb5228ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 01:36:41.201337: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2225122304 exceeds 10% of free system memory.\n",
      "2023-04-10 01:36:51.895563: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.07GiB (rounded to 2225122304)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-04-10 01:36:51.895592: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-04-10 01:36:51.895602: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 10, Chunks in use: 8. 2.5KiB allocated for chunks. 2.0KiB in use in bin. 177B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895609: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 2, Chunks in use: 0. 1.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895614: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895619: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895624: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895628: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895633: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895637: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895642: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895646: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895651: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895655: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895660: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895664: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895669: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895673: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895678: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895682: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895688: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895693: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895699: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 846.18MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-10 01:36:51.895704: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 2.07GiB was 256.00MiB, Chunk State: \n",
      "2023-04-10 01:36:51.895715: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 846.18MiB | Requested Size: 32B | in_use: 0 | bin_num: 20, prev:   Size: 256B | Requested Size: 32B | in_use: 1 | bin_num: -1\n",
      "2023-04-10 01:36:51.895719: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 887291904\n",
      "2023-04-10 01:36:51.895725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000000 of size 1280 next 1\n",
      "2023-04-10 01:36:51.895729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000500 of size 256 next 2\n",
      "2023-04-10 01:36:51.895733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000600 of size 256 next 3\n",
      "2023-04-10 01:36:51.895736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000700 of size 256 next 4\n",
      "2023-04-10 01:36:51.895740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1f86000800 of size 256 next 5\n",
      "2023-04-10 01:36:51.895744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000900 of size 256 next 6\n",
      "2023-04-10 01:36:51.895747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1f86000a00 of size 512 next 8\n",
      "2023-04-10 01:36:51.895751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000c00 of size 256 next 9\n",
      "2023-04-10 01:36:51.895755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1f86000d00 of size 256 next 10\n",
      "2023-04-10 01:36:51.895758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000e00 of size 256 next 11\n",
      "2023-04-10 01:36:51.895762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86000f00 of size 256 next 12\n",
      "2023-04-10 01:36:51.895765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1f86001000 of size 512 next 14\n",
      "2023-04-10 01:36:51.895769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f1f86001200 of size 256 next 15\n",
      "2023-04-10 01:36:51.895773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f1f86001300 of size 887287040 next 18446744073709551615\n",
      "2023-04-10 01:36:51.895777: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-04-10 01:36:51.895782: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 256 totalling 2.0KiB\n",
      "2023-04-10 01:36:51.895786: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-04-10 01:36:51.895790: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 3.2KiB\n",
      "2023-04-10 01:36:51.895795: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 887291904 memory_limit_: 887291904 available bytes: 0 curr_region_allocation_bytes_: 1774583808\n",
      "2023-04-10 01:36:51.895803: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       887291904\n",
      "InUse:                            3328\n",
      "MaxInUse:                         5376\n",
      "NumAllocs:                          40\n",
      "MaxAllocSize:                     1280\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-04-10 01:36:51.895809: W tensorflow/tsl/framework/bfc_allocator.cc:497] *___________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNON_EMPTY_FRAME_IDXS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m     \u001b[49m\u001b[43moutput_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m92\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:576\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    569\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    570\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    571\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    575\u001b[0m           instructions)\n\u001b[0;32m--> 576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:970\u001b[0m, in \u001b[0;36mDatasetV2.from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# from_generator_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_generator_op\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_generator_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43moutput_signature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py:155\u001b[0m, in \u001b[0;36m_from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    153\u001b[0m   args \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_n_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    157\u001b[0m generator_state \u001b[38;5;241m=\u001b[39m dataset_ops\u001b[38;5;241m.\u001b[39mDatasetV2\u001b[38;5;241m.\u001b[39m_GeneratorState(generator)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_iterator_id_fn\u001b[39m(unused_dummy):\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1742\u001b[0m, in \u001b[0;36mconvert_n_to_tensor\u001b[0;34m(values, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_n_to_tensor\u001b[39m(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, preferred_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts `values` to a list of `Tensor` objects.\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \n\u001b[1;32m   1722\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;124;03m      value.\u001b[39;00m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1742\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minternal_convert_n_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1709\u001b[0m, in \u001b[0;36minternal_convert_n_to_tensor\u001b[0;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[1;32m   1707\u001b[0m   n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (name, i)\n\u001b[1;32m   1708\u001b[0m   ret\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m-> 1709\u001b[0m       \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m          \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m          \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m          \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m          \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1642\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1633\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1634\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1635\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1639\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1642\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1645\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:280\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    279\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 280\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    283\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:305\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    get_sample,\n",
    "     output_signature=(\n",
    "        tf.TensorSpec(shape=(32, 92, 2), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(32, ), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "071d7c6c-9c68-46a9-a217-d30c3468992c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: get_sample(X, y, NON_EMPTY_FRAME_IDXS),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(32, 92, 2), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(32, ), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ebdeed32-0a20-4c0b-9a97-58632a4813e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 22 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1], shape=(32,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[ 0 10 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1], shape=(32,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 01:32:11.318292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-10 01:32:11.340312: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "\n",
      "\n",
      "2023-04-10 01:32:11.340350: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "2023-04-10 01:32:11.344849: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "\n",
      "\n",
      "2023-04-10 01:32:11.344876: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\nTraceback (most recent call last):\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y, non_empty_frame_idxs \u001b[38;5;129;01min\u001b[39;00m train_dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y)\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    796\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 780\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\nTraceback (most recent call last):\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/tensorflow/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (32,) where an element of shape () was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for x, y, non_empty_frame_idxs in train_dataset.batch(2).take(1):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(non_empty_frame_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe6a1e",
   "metadata": {
    "papermill": {
     "duration": 0.090875,
     "end_time": "2023-03-27T13:50:42.319571",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.228696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_dataset = get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS)\n",
    "X_batch, y_batch = next(dummy_dataset)\n",
    "\n",
    "for k, v in X_batch.items():\n",
    "    print(f'{k} shape: {v.shape}, dtype: {v.dtype}')\n",
    "\n",
    "# Batch shape/dtype\n",
    "print(f'y_batch shape: {y_batch.shape}, dtype: {y_batch.dtype}')\n",
    "# Verify each batch contains each sign exactly N times\n",
    "display(pd.Series(y_batch).value_counts().to_frame('Counts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d776d9f-553a-483b-ae3e-6d819fc6f8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LIPS\n",
    "LIPS_MEAN_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "LIPS_MEAN_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "LIPS_STD_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "LIPS_STD_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, config[\"N_DIMS\"]*6))\n",
    "   \n",
    "for col, ll in enumerate(tqdm( np.transpose(X[:,:,LIPS_IDXS], [2,3,0,1]).reshape([LIPS_IDXS.size, config[\"N_DIMS\"], -1]) )):\n",
    "    for dim, l in enumerate(ll):\n",
    "        v = l[np.nonzero(l)]\n",
    "        if dim == 0: # X\n",
    "            LIPS_MEAN_X[col] = v.mean()\n",
    "            LIPS_STD_X[col] = v.std()\n",
    "        if dim == 1: # Y\n",
    "            LIPS_MEAN_Y[col] = v.mean()\n",
    "            LIPS_STD_Y[col] = v.std()\n",
    "        \n",
    "        axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "        \n",
    "for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "    ax.set_title(f'Lips {dim_name.upper()} Dimension', size=24)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.50)\n",
    "plt.show()\n",
    "\n",
    "LIPS_MEAN = np.array([LIPS_MEAN_X, LIPS_MEAN_Y]).T\n",
    "LIPS_STD = np.array([LIPS_STD_X, LIPS_STD_Y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783dbd1e-d5b0-4d00-90c5-f91389b16843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEFT HAND\n",
    "LEFT_HANDS_MEAN_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "LEFT_HANDS_MEAN_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "LEFT_HANDS_STD_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "LEFT_HANDS_STD_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "# RIGHT HAND\n",
    "RIGHT_HANDS_MEAN_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "RIGHT_HANDS_MEAN_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "RIGHT_HANDS_STD_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "RIGHT_HANDS_STD_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, config[\"N_DIMS\"]*6))\n",
    "   \n",
    "for col, ll in enumerate(tqdm( np.transpose(X[:,:,HAND_IDXS], [2,3,0,1]).reshape([HAND_IDXS.size, config[\"N_DIMS\"], -1]) )):\n",
    "    for dim, l in enumerate(ll):\n",
    "        v = l[np.nonzero(l)]\n",
    "        if dim == 0: # X\n",
    "            if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
    "                LEFT_HANDS_MEAN_X[col] = v.mean()\n",
    "                LEFT_HANDS_STD_X[col] = v.std()\n",
    "            else:\n",
    "                RIGHT_HANDS_MEAN_X[col - LEFT_HAND_IDXS.size] = v.mean()\n",
    "                RIGHT_HANDS_STD_X[col - LEFT_HAND_IDXS.size] = v.std()\n",
    "        if dim == 1: # Y\n",
    "            if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
    "                LEFT_HANDS_MEAN_Y[col] = v.mean()\n",
    "                LEFT_HANDS_STD_Y[col] = v.std()\n",
    "            else: # RIGHT HAND\n",
    "                RIGHT_HANDS_MEAN_Y[col - LEFT_HAND_IDXS.size] = v.mean()\n",
    "                RIGHT_HANDS_STD_Y[col - LEFT_HAND_IDXS.size] = v.std()\n",
    "        \n",
    "        axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "        \n",
    "for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "    ax.set_title(f'Hands {dim_name.upper()} Dimension', size=24)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.50)\n",
    "plt.show()\n",
    "\n",
    "LEFT_HANDS_MEAN = np.array([LEFT_HANDS_MEAN_X, LEFT_HANDS_MEAN_Y]).T\n",
    "LEFT_HANDS_STD = np.array([LEFT_HANDS_STD_X, LEFT_HANDS_STD_Y]).T\n",
    "RIGHT_HANDS_MEAN = np.array([RIGHT_HANDS_MEAN_X, RIGHT_HANDS_MEAN_Y]).T\n",
    "RIGHT_HANDS_STD = np.array([RIGHT_HANDS_STD_X, RIGHT_HANDS_STD_Y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa676cb1-f20c-4314-8430-c435e493d7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# POSE\n",
    "POSE_MEAN_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "POSE_MEAN_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "POSE_STD_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "POSE_STD_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, config[\"N_DIMS\"]*6))\n",
    "   \n",
    "for col, ll in enumerate(tqdm( np.transpose(X[:,:,POSE_IDXS], [2,3,0,1]).reshape([POSE_IDXS.size, config[\"N_DIMS\"], -1]) )):\n",
    "    for dim, l in enumerate(ll):\n",
    "        v = l[np.nonzero(l)]\n",
    "        if dim == 0: # X\n",
    "            POSE_MEAN_X[col] = v.mean()\n",
    "            POSE_STD_X[col] = v.std()\n",
    "        if dim == 1: # Y\n",
    "            POSE_MEAN_Y[col] = v.mean()\n",
    "            POSE_STD_Y[col] = v.std()\n",
    "        \n",
    "        axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "        \n",
    "for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "    ax.set_title(f'Pose {dim_name.upper()} Dimension', size=24)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.50)\n",
    "plt.show()\n",
    "\n",
    "POSE_MEAN = np.array([POSE_MEAN_X, POSE_MEAN_Y]).T\n",
    "POSE_STD = np.array([POSE_STD_X, POSE_STD_Y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db809f",
   "metadata": {
    "papermill": {
     "duration": 0.027558,
     "end_time": "2023-03-27T13:50:42.374837",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.347279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad349c1a",
   "metadata": {
    "papermill": {
     "duration": 0.039339,
     "end_time": "2023-03-27T13:50:42.441202",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.401863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "LIPS_UNITS = 384\n",
    "HANDS_UNITS = 384\n",
    "POSE_UNITS = 384\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = 512\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = 2\n",
    "MLP_RATIO = 2\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = 0.00\n",
    "MLP_DROPOUT_RATIO = 0.30\n",
    "CLASSIFIER_DROPOUT_RATIO = 0.10\n",
    "\n",
    "# Initiailizers\n",
    "INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "GELU = tf.keras.activations.gelu\n",
    "\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08c17b",
   "metadata": {
    "papermill": {
     "duration": 0.023745,
     "end_time": "2023-03-27T13:50:42.489414",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.465669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer\n",
    "\n",
    "Need to implement transformer from scratch as TFLite does not support the native TF implementation of MultiHeadAttention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0412b",
   "metadata": {
    "papermill": {
     "duration": 0.03906,
     "end_time": "2023-03-27T13:50:42.552962",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.513902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n",
    "# replaced softmax with softmax layer to support masked softmax\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    \n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_of_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self,x, attention_mask):\n",
    "        \n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](x)\n",
    "            K = self.wk[i](x)\n",
    "            V = self.wv[i](x)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn,axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        return multi_head_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbeb2a",
   "metadata": {
    "papermill": {
     "duration": 0.036979,
     "end_time": "2023-03-27T13:50:42.613484",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.576505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(Transformer, self).__init__(name='transformer')\n",
    "        self.num_blocks = num_blocks\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.num_blocks):\n",
    "            # First Layer Normalisation\n",
    "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(UNITS, 4))\n",
    "            # Second Layer Normalisation\n",
    "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(UNITS * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM),\n",
    "                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(UNITS, kernel_initializer=INIT_HE_UNIFORM),\n",
    "            ]))\n",
    "        \n",
    "    def call(self, x, attention_mask):\n",
    "        # Iterate input over transformer blocks\n",
    "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
    "            x1 = ln_1(x)\n",
    "            attention_output = mha(x1, attention_mask)\n",
    "            x2 = x1 + attention_output\n",
    "            x3 = ln_2(x2)\n",
    "            x3 = mlp(x3)\n",
    "            x = x3 + x2\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1f32e",
   "metadata": {
    "papermill": {
     "duration": 0.023271,
     "end_time": "2023-03-27T13:50:42.659800",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.636529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Landmark Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf48db",
   "metadata": {
    "papermill": {
     "duration": 0.034861,
     "end_time": "2023-03-27T13:50:42.718239",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.683378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandmarkEmbedding(tf.keras.Model):\n",
    "    def __init__(self, units, name):\n",
    "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Embedding for missing landmark in frame, initizlied with zeros\n",
    "        self.empty_embedding = self.add_weight(\n",
    "            name=f'{self.name}_empty_embedding',\n",
    "            shape=[self.units],\n",
    "            initializer=INIT_ZEROS,\n",
    "        )\n",
    "        # Embedding\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM, activation=GELU),\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
    "        ], name=f'{self.name}_dense')\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "                # Checks whether landmark is missing in frame\n",
    "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
    "                # If so, the empty embedding is used\n",
    "                self.empty_embedding,\n",
    "                # Otherwise the landmark data is embedded\n",
    "                self.dense(x),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92e551",
   "metadata": {
    "papermill": {
     "duration": 0.023307,
     "end_time": "2023-03-27T13:50:42.764805",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.741498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac179c",
   "metadata": {
    "papermill": {
     "duration": 0.041109,
     "end_time": "2023-03-27T13:50:42.830111",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.789002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        \n",
    "    def get_diffs(self, l):\n",
    "        S = l.shape[2]\n",
    "        other = tf.expand_dims(l, 3)\n",
    "        other = tf.repeat(other, S, axis=3)\n",
    "        other = tf.transpose(other, [0,1,3,2])\n",
    "        diffs = tf.expand_dims(l, 3) - other\n",
    "        diffs = tf.reshape(diffs, [-1, config[\"INPUT_SIZE\"], S*S])\n",
    "        return diffs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Positional Embedding, initialized with zeros\n",
    "        self.positional_embedding = tf.keras.layers.Embedding(config[\"INPUT_SIZE\"]+1, UNITS, embeddings_initializer=INIT_ZEROS)\n",
    "        # Embedding layer for Landmarks\n",
    "        self.lips_embedding = LandmarkEmbedding(LIPS_UNITS, 'lips')\n",
    "        self.left_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'left_hand')\n",
    "        self.right_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'right_hand')\n",
    "        self.pose_embedding = LandmarkEmbedding(POSE_UNITS, 'pose')\n",
    "        # Landmark Weights\n",
    "        self.landmark_weights = tf.Variable(tf.zeros([4], dtype=tf.float32), name='landmark_weights')\n",
    "        # Fully Connected Layers for combined landmarks\n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(UNITS, name='fully_connected_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM, activation=GELU),\n",
    "            tf.keras.layers.Dense(UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
    "        ], name='fc')\n",
    "\n",
    "\n",
    "    def call(self, lips0, left_hand0, right_hand0, pose0, non_empty_frame_idxs, training=False):\n",
    "        # Lips\n",
    "        lips_embedding = self.lips_embedding(lips0)\n",
    "        # Left Hand\n",
    "        left_hand_embedding = self.left_hand_embedding(left_hand0)\n",
    "        # Right Hand\n",
    "        right_hand_embedding = self.right_hand_embedding(right_hand0)\n",
    "        # Pose\n",
    "        pose_embedding = self.pose_embedding(pose0)\n",
    "        # Merge Embeddings of all landmarks with mean pooling\n",
    "        x = tf.stack((lips_embedding, left_hand_embedding, right_hand_embedding, pose_embedding), axis=3)\n",
    "        # Merge Landmarks with trainable attention weights\n",
    "        x = x * tf.nn.softmax(self.landmark_weights)\n",
    "        x = tf.reduce_sum(x, axis=3)\n",
    "        # Fully Connected Layers\n",
    "        x = self.fc(x)\n",
    "        # Add Positional Embedding\n",
    "        normalised_non_empty_frame_idxs = tf.where(\n",
    "            tf.math.equal(non_empty_frame_idxs, -1.0),\n",
    "            config[\"INPUT_SIZE\"],\n",
    "            tf.cast(\n",
    "                non_empty_frame_idxs / tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True) * config[\"INPUT_SIZE\"],\n",
    "                tf.int32,\n",
    "            ),\n",
    "        )\n",
    "        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca5c18",
   "metadata": {
    "papermill": {
     "duration": 0.043124,
     "end_time": "2023-03-27T13:50:42.896486",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.853362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([config[\"INPUT_SIZE\"], N_COLS, config[\"N_DIMS\"]], dtype=tf.float32, name='frames')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([config[\"INPUT_SIZE\"]], dtype=tf.float32, name='non_empty_frame_idxs')\n",
    "    # Padding Mask\n",
    "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=2)\n",
    "    \n",
    "    \"\"\"\n",
    "        left_hand: 468:489\n",
    "        pose: 489:522\n",
    "        right_hand: 522:543\n",
    "    \"\"\"\n",
    "    x = frames\n",
    "    x = tf.slice(x, [0,0,0,0], [-1,config[\"INPUT_SIZE\"], N_COLS, 2])\n",
    "    # LIPS\n",
    "    lips = tf.slice(x, [0,0,LIPS_START,0], [-1,config[\"INPUT_SIZE\"], 40, 2])\n",
    "    lips = tf.where(\n",
    "            tf.math.equal(lips, 0.0),\n",
    "            0.0,\n",
    "            (lips - LIPS_MEAN) / LIPS_STD,\n",
    "        )\n",
    "    lips = tf.reshape(lips, [-1, config[\"INPUT_SIZE\"], 40*2])\n",
    "    # LEFT HAND\n",
    "    left_hand = tf.slice(x, [0,0,40,0], [-1,config[\"INPUT_SIZE\"], 21, 2])\n",
    "    left_hand = tf.where(\n",
    "            tf.math.equal(left_hand, 0.0),\n",
    "            0.0,\n",
    "            (left_hand - LEFT_HANDS_MEAN) / LEFT_HANDS_STD,\n",
    "        )\n",
    "    left_hand = tf.reshape(left_hand, [-1, config[\"INPUT_SIZE\"], 21*2])\n",
    "    # RIGHT HAND\n",
    "    right_hand = tf.slice(x, [0,0,61,0], [-1,config[\"INPUT_SIZE\"], 21, 2])\n",
    "    right_hand = tf.where(\n",
    "            tf.math.equal(right_hand, 0.0),\n",
    "            0.0,\n",
    "            (right_hand - RIGHT_HANDS_MEAN) / RIGHT_HANDS_STD,\n",
    "        )\n",
    "    right_hand = tf.reshape(right_hand, [-1, config[\"INPUT_SIZE\"], 21*2])\n",
    "    # POSE\n",
    "    pose = tf.slice(x, [0,0,82,0], [-1,config[\"INPUT_SIZE\"], 10, 2])\n",
    "    pose = tf.where(\n",
    "            tf.math.equal(pose, 0.0),\n",
    "            0.0,\n",
    "            (pose - POSE_MEAN) / POSE_STD,\n",
    "        )\n",
    "    pose = tf.reshape(pose, [-1, config[\"INPUT_SIZE\"], 10*2])\n",
    "    \n",
    "    x = lips, left_hand, right_hand, pose\n",
    "        \n",
    "    print(x)\n",
    "    x = Embedding()(lips, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
    "    \n",
    "    # Encoder Transformer Blocks\n",
    "    x = Transformer(NUM_BLOCKS)(x, mask)\n",
    "    \n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classifier Dropout\n",
    "    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(config[\"NUM_CLASSES\"], activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Simple Categorical Crossentropy Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=config[\"LEARNING_RATE\"], weight_decay=config[\"WEIGHT_DECAY\"])\n",
    "    \n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3827719",
   "metadata": {
    "papermill": {
     "duration": 5.328614,
     "end_time": "2023-03-27T13:50:48.248338",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.919724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f48d4-cace-46f4-a1c4-26b197fd8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(dummy_dataset, verbose=VERBOSE, steps=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb430b06",
   "metadata": {
    "papermill": {
     "duration": 0.371176,
     "end_time": "2023-03-27T13:50:48.643574",
     "exception": false,
     "start_time": "2023-03-27T13:50:48.272398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot model summary\n",
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739d7f8",
   "metadata": {
    "papermill": {
     "duration": 0.828156,
     "end_time": "2023-03-27T13:50:49.508884",
     "exception": false,
     "start_time": "2023-03-27T13:50:48.680728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a152a4b",
   "metadata": {
    "papermill": {
     "duration": 0.038958,
     "end_time": "2023-03-27T13:50:49.587880",
     "exception": false,
     "start_time": "2023-03-27T13:50:49.548922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f93f5",
   "metadata": {
    "papermill": {
     "duration": 13.677198,
     "end_time": "2023-03-27T13:51:03.302900",
     "exception": false,
     "start_time": "2023-03-27T13:50:49.625702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 32\n",
    "y_pred = model.predict(dummy_dataset, verbose=VERBOSE, steps=N).flatten()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(f'Softmax Output Initialized Model | µ={y_pred.mean():.3f}, σ={y_pred.std():.3f}', pad=25)\n",
    "pd.Series(y_pred).plot(kind='hist', bins=128, label='Class Probability')\n",
    "plt.xlim(0, max(y_pred) * 1.1)\n",
    "plt.vlines([1 / config[\"NUM_CLASSES\"]], 0, plt.ylim()[1], color='red', label=f'Random Guessing Baseline 1/config[\"NUM_CLASSES\"]={1 / config[\"NUM_CLASSES\"]:.3f}')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9779f",
   "metadata": {
    "papermill": {
     "duration": 0.038802,
     "end_time": "2023-03-27T13:51:03.381634",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.342832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cdcb6",
   "metadata": {
    "papermill": {
     "duration": 0.049275,
     "end_time": "2023-03-27T13:51:03.469275",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.420000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=config[\"N_EPOCHS\"]):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        if WARMUP_METHOD == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6401784",
   "metadata": {
    "papermill": {
     "duration": 0.738209,
     "end_time": "2023-03-27T13:51:04.245805",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.507596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lr_schedule(lr_schedule, epochs):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot([None] + lr_schedule + [None])\n",
    "    # X Labels\n",
    "    x = np.arange(1, epochs + 1)\n",
    "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
    "    plt.xlim([1, epochs])\n",
    "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
    "    \n",
    "    # Increase y-limit for better readability\n",
    "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
    "    \n",
    "    # Title\n",
    "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
    "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
    "    \n",
    "    # Plot Learning Rates\n",
    "    for x, val in enumerate(lr_schedule):\n",
    "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
    "            if x < len(lr_schedule) - 1:\n",
    "                if lr_schedule[x - 1] < val:\n",
    "                    ha = 'right'\n",
    "                else:\n",
    "                    ha = 'left'\n",
    "            elif x == 0:\n",
    "                ha = 'right'\n",
    "            else:\n",
    "                ha = 'left'\n",
    "            plt.plot(x + 1, val, 'o', color='black');\n",
    "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
    "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
    "    \n",
    "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
    "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=config[\"N_WARMUP_EPOCHS\"], lr_max=config[\"config[\"LEARNING_RATE\"]\"], num_cycles=0.50) for step in range(config[\"N_EPOCHS\"])]\n",
    "# Plot Learning Rate Schedule\n",
    "plot_lr_schedule(LR_SCHEDULE, epochs=config[\"N_EPOCHS\"])\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e550a63",
   "metadata": {
    "papermill": {
     "duration": 0.040725,
     "end_time": "2023-03-27T13:51:04.330003",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.289278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Decay Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e82c65",
   "metadata": {
    "papermill": {
     "duration": 0.050692,
     "end_time": "2023-03-27T13:51:04.421493",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.370801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom callback to update weight decay with learning rate\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, config[\"WD_RATIO\"]=config[\"WD_RATIO\"]):\n",
    "        self.step_counter = 0\n",
    "        self.config[\"WD_RATIO\"] = config[\"WD_RATIO\"]\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.config[\"config[\"LEARNING_RATE\"]\"] * self.config[\"WD_RATIO\"]\n",
    "        print(f'learning rate: {model.optimizer.config[\"config[\"LEARNING_RATE\"]\"].numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9eca4",
   "metadata": {
    "papermill": {
     "duration": 0.040431,
     "end_time": "2023-03-27T13:51:04.501979",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.461548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d7ae0",
   "metadata": {
    "papermill": {
     "duration": 6.727547,
     "end_time": "2023-03-27T13:51:11.270673",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.543126",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "# Verify model prediction is <<<100ms\n",
    "model.predict_on_batch({ 'frames': X[:1], 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS[:1] })\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97185a5",
   "metadata": {
    "papermill": {
     "duration": 0.040685,
     "end_time": "2023-03-27T13:51:11.352812",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.312127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b84f8a7",
   "metadata": {
    "papermill": {
     "duration": 0.052825,
     "end_time": "2023-03-27T13:51:11.446680",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.393855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    # Split data based on participant id\n",
    "    splitter = GroupShuffleSplit(test_size=0.10, n_splits=2, random_state=SEED)\n",
    "\n",
    "    train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)\n",
    "    PARTICIPANT_IDS = pd.read_csv(train_file.get(\"Body\"))['participant_id']\n",
    "\n",
    "    train_idxs, val_idxs = next(splitter.split(X, y, groups=PARTICIPANT_IDS))\n",
    "\n",
    "    X_train = X[train_idxs]\n",
    "    X_val = X[val_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
    "    y_train = y[train_idxs]\n",
    "    y_val = y[val_idxs]\n",
    "    \n",
    "    # Define validation Data\n",
    "    validation_data = ({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, y_val)\n",
    "\n",
    "    print(f'Patient ID Intersection Train/Val: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs])}')\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "    print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}')\n",
    "else:\n",
    "    X_train = X\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS\n",
    "    y_train = y\n",
    "    validation_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a4aeb",
   "metadata": {
    "papermill": {
     "duration": 0.049325,
     "end_time": "2023-03-27T13:51:11.536446",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.487121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    # Verify Validation Dataset Covers All Signs\n",
    "    print(f'# Unique Signs in Validation Set: {pd.Series(y_val).nunique()}')\n",
    "    # Value Counts\n",
    "    display(pd.Series(y_val).value_counts().to_frame('Count').iloc[[1,2,3,-3,-2,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648295ac",
   "metadata": {
    "papermill": {
     "duration": 0.040318,
     "end_time": "2023-03-27T13:51:11.617714",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.577396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate Initialzied Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aea388",
   "metadata": {
    "papermill": {
     "duration": 0.050112,
     "end_time": "2023-03-27T13:51:11.708205",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.658093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "_ = model.evaluate(*validation_data, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909bf11",
   "metadata": {
    "papermill": {
     "duration": 0.040524,
     "end_time": "2023-03-27T13:51:11.789064",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.748540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83cf56",
   "metadata": {
    "papermill": {
     "duration": 2852.852405,
     "end_time": "2023-03-27T14:38:44.682355",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.829950",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clear all models in GPU\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Get new fresh model\n",
    "model = get_model()\n",
    "\n",
    "# Sanity Check\n",
    "model.summary()\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Actual Training\n",
    "history = model.fit(\n",
    "        x=get_train_batch_all_signs(X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN),\n",
    "        steps_per_epoch=len(X_train) // (config[\"NUM_CLASSES\"] * config[\"BATCH_ALL_SIGNS_N\"]),\n",
    "        epochs=config[\"N_EPOCHS\"],\n",
    "        # Only used for validation data since training data is a generator\n",
    "        config[\"BATCH_SIZE_VAL\"]=config[\"BATCH_SIZE_VAL\"],\n",
    "        validation_data=validation_data,\n",
    "        callbacks=[\n",
    "            lr_callback,\n",
    "            WeightDecayCallback(),\n",
    "            tensorboard_callback\n",
    "        ],\n",
    "        verbose = VERBOSE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57044d51",
   "metadata": {
    "papermill": {
     "duration": 0.204275,
     "end_time": "2023-03-27T14:38:44.950811",
     "exception": false,
     "start_time": "2023-03-27T14:38:44.746536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Model Weights\n",
    "# model.save_weights(f'tf_models/{version}_model.h5')\n",
    "\n",
    "s3_client.upload_file(Filename=f'tf_models/{version}_model.h5',\n",
    "                  Bucket=AWS_S3_BUCKET,\n",
    "                  Key=f'tf_models/{version}_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b4130-dc12-48dd-a7e1-d7115c7aa684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)\n",
    "train = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4aec0",
   "metadata": {
    "papermill": {
     "duration": 0.071523,
     "end_time": "2023-03-27T14:38:45.085266",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.013743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    # Validation Predictions\n",
    "    y_val_pred = model.predict({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, verbose=2).argmax(axis=1)\n",
    "    # Label\n",
    "    labels = [ORD2SIGN.get(i).replace(' ', '_') for i in range(config[\"NUM_CLASSES\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb6244",
   "metadata": {
    "papermill": {
     "duration": 0.061014,
     "end_time": "2023-03-27T14:38:45.207893",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.146879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Landmark Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa652a3",
   "metadata": {
    "papermill": {
     "duration": 0.077022,
     "end_time": "2023-03-27T14:38:45.348287",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.271265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Landmark Weights\n",
    "weights = scipy.special.softmax(model.get_layer('embedding').weights[15])\n",
    "landmarks = ['lips_embedding', 'left_hand_embedding', 'right_hand_embedding', 'pose_embedding']\n",
    "\n",
    "# Learned attention weights, initialized at uniform 25%\n",
    "for w, lm in zip(weights, landmarks):\n",
    "    print(f'{lm} weight: {(w*100):.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a83df4",
   "metadata": {
    "papermill": {
     "duration": 0.061678,
     "end_time": "2023-03-27T14:38:45.472071",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.410393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5a638",
   "metadata": {
    "papermill": {
     "duration": 0.073852,
     "end_time": "2023-03-27T14:38:45.607733",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.533881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_classification_report():\n",
    "    # Classification report for all signs\n",
    "    classification_report = sklearn.metrics.classification_report(\n",
    "            y_val,\n",
    "            y_val_pred,\n",
    "            target_names=labels,\n",
    "            output_dict=True,\n",
    "        )\n",
    "    # Round Data for better readability\n",
    "    classification_report = pd.DataFrame(classification_report).T\n",
    "    classification_report = classification_report.round(2)\n",
    "    classification_report = classification_report.astype({\n",
    "            'support': np.uint16,\n",
    "        })\n",
    "    # Add signs\n",
    "    classification_report['sign'] = [e if e in SIGN2ORD else -1 for e in classification_report.index]\n",
    "    classification_report['sign_ord'] = classification_report['sign'].apply(SIGN2ORD.get).fillna(-1).astype(np.int16)\n",
    "    # Sort on F1-score\n",
    "    classification_report = pd.concat((\n",
    "        classification_report.head(config[\"NUM_CLASSES\"]).sort_values('f1-score', ascending=False),\n",
    "        classification_report.tail(3),\n",
    "    ))\n",
    "\n",
    "    pd.options.display.max_rows = 999\n",
    "    display(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acd2cd",
   "metadata": {
    "papermill": {
     "duration": 0.114632,
     "end_time": "2023-03-27T14:38:45.783594",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.668962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1337c59",
   "metadata": {
    "papermill": {
     "duration": 0.06176,
     "end_time": "2023-03-27T14:38:45.907383",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.845623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b50c7b",
   "metadata": {
    "papermill": {
     "duration": 0.078619,
     "end_time": "2023-03-27T14:38:46.047474",
     "exception": false,
     "start_time": "2023-03-27T14:38:45.968855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history_metric(metric, f_best=np.argmax, ylim=None, yscale=None, yticks=None):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    values = history.history[metric]\n",
    "    config[\"N_EPOCHS\"] = len(values)\n",
    "    val = 'val' in ''.join(history.history.keys())\n",
    "    # Epoch Ticks\n",
    "    if config[\"N_EPOCHS\"] <= 20:\n",
    "        x = np.arange(1, config[\"N_EPOCHS\"] + 1)\n",
    "    else:\n",
    "        x = [1, 5] + [10 + 5 * idx for idx in range((config[\"N_EPOCHS\"] - 10) // 5 + 1)]\n",
    "\n",
    "    x_ticks = np.arange(1, config[\"N_EPOCHS\"]+1)\n",
    "\n",
    "    # Validation\n",
    "    if val:\n",
    "        val_values = history.history[f'val_{metric}']\n",
    "        val_argmin = f_best(val_values)\n",
    "        plt.plot(x_ticks, val_values, label=f'val')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(x_ticks, values, label=f'train')\n",
    "    argmin = f_best(values)\n",
    "    plt.scatter(argmin + 1, values[argmin], color='red', s=75, marker='o', label=f'train_best')\n",
    "    if val:\n",
    "        plt.scatter(val_argmin + 1, val_values[val_argmin], color='purple', s=75, marker='o', label=f'val_best')\n",
    "\n",
    "    plt.title(f'Model {metric}', fontsize=24, pad=10)\n",
    "    plt.ylabel(metric, fontsize=20, labelpad=10)\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    if yscale is not None:\n",
    "        plt.yscale(yscale)\n",
    "        \n",
    "    if yticks is not None:\n",
    "        plt.yticks(yticks, fontsize=16)\n",
    "\n",
    "    plt.xlabel('epoch', fontsize=20, labelpad=10)        \n",
    "    plt.tick_params(axis='x', labelsize=8)\n",
    "    plt.xticks(x, fontsize=16) # set tick step to 1 and let x axis start at 1\n",
    "    plt.yticks(fontsize=16)\n",
    "    \n",
    "    plt.legend(prop={'size': 10})\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36b11b",
   "metadata": {
    "papermill": {
     "duration": 0.457464,
     "end_time": "2023-03-27T14:38:46.565722",
     "exception": false,
     "start_time": "2023-03-27T14:38:46.108258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('loss', f_best=np.argmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14124968",
   "metadata": {
    "papermill": {
     "duration": 0.454542,
     "end_time": "2023-03-27T14:38:47.085510",
     "exception": false,
     "start_time": "2023-03-27T14:38:46.630968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac7785",
   "metadata": {
    "papermill": {
     "duration": 0.465536,
     "end_time": "2023-03-27T14:38:47.618068",
     "exception": false,
     "start_time": "2023-03-27T14:38:47.152532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('top_5_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd063e4",
   "metadata": {
    "papermill": {
     "duration": 0.454357,
     "end_time": "2023-03-27T14:38:48.149474",
     "exception": false,
     "start_time": "2023-03-27T14:38:47.695117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history_metric('top_10_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2759c7",
   "metadata": {
    "papermill": {
     "duration": 0.065813,
     "end_time": "2023-03-27T14:38:48.284324",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.218511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Submission code loosley based on [this notebook](https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline#baseline) by [Darien Schettler\n",
    "](https://www.kaggle.com/dschettler8845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007edb3-ef8c-49d0-8c7c-29c5720c1fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, s3_client, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe964bf-4964-4325-a546-5ae3419aa2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_layer = PreprocessLayer(config[\"N_ROWS\"], config[\"N_DIMS\"], HAND_IDXS0, LANDMARK_IDXS0, config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2d0a9",
   "metadata": {
    "papermill": {
     "duration": 1.644953,
     "end_time": "2023-03-27T14:38:49.995113",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.350160",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TFLite model for submission\n",
    "class TFLiteModel(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.preprocess_layer = preprocess_layer\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, config[\"N_ROWS\"], config[\"N_DIMS\"]], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        # Preprocess Data\n",
    "        x, non_empty_frame_idxs = self.preprocess_layer(inputs)\n",
    "        # Add Batch Dimension\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
    "        # Make Prediction\n",
    "        outputs = self.model({ 'frames': x, 'non_empty_frame_idxs': non_empty_frame_idxs })\n",
    "        # Squeeze Output 1x250 -> 250\n",
    "        outputs = tf.squeeze(outputs, axis=0)\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "# Define TF Lite Model\n",
    "tflite_keras_model = TFLiteModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848181e8-9e30-471e-bc5c-b37340640edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "demo_raw_data = load_relevant_data_subset(train['path'].values[5])\n",
    "print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n",
    "demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n",
    "print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n",
    "demo_prediction = demo_output.numpy().argmax()\n",
    "print(f'demo_prediction: {demo_prediction}, correct: {train.iloc[0][\"sign_ord\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071a4d9",
   "metadata": {
    "papermill": {
     "duration": 32.570402,
     "end_time": "2023-03-27T14:39:22.633212",
     "exception": false,
     "start_time": "2023-03-27T14:38:50.062810",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Model Converter\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "# Convert Model\n",
    "tflite_model = keras_model_converter.convert()\n",
    "# Write Model\n",
    "with open(f'tflite_models/{version}_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "# Zip Model\n",
    "# !zip submission.zip /kaggle/working/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5493473",
   "metadata": {
    "papermill": {
     "duration": 11.438209,
     "end_time": "2023-03-27T14:39:34.137659",
     "exception": false,
     "start_time": "2023-03-27T14:39:22.699450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify TFLite model can be loaded and used for prediction\n",
    "!pip install tflite-runtime\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(\"tflite_models/model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=demo_raw_data)\n",
    "sign = output['outputs'].argmax()\n",
    "\n",
    "print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')\n",
    "print(\"TRUE : \", train.sign.values[0], f'[{train.sign_ord.values[0]}]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3038.388613,
   "end_time": "2023-03-27T14:39:37.370611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-27T13:48:58.981998",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03d6f570ff764870bb73ccfb8c6887af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49350bdfb80d4f00a698d195ad6cc3e3",
       "placeholder": "​",
       "style": "IPY_MODEL_6114b828351443dead1df1f805e5cfd7",
       "value": "100%"
      }
     },
     "07287dd36a6b457bab873107ef3a9a74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a3cb9fa235b4d3b9fe4729d0488ab41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0b6a231f62a24aae9fa0cbc3fb92820f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0bdd95bee39a4c0fba0d526a76e11ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5809fb0e32f44de489c4ffd133aed91d",
       "placeholder": "​",
       "style": "IPY_MODEL_ac638cb770cd4789a3ad5944574c0685",
       "value": " 1000/1000 [00:23&lt;00:00, 37.18it/s]"
      }
     },
     "0f47d306ae4c4968ae9578b5d3f96717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c0862516d904ef7a8308a72e5ae9f91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28320ac6793c47f69b05122f608c2d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0ef2e7de83043f5a1e56b8cbfdceb42",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b6a231f62a24aae9fa0cbc3fb92820f",
       "value": 1000
      }
     },
     "37eb2c935499475c89e659645e41c052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a30e5dd2b7e4e58b5f796dc56795f9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43441f82927941c183c36d4ba42c6839": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49104b8e9766498997f1c107709166cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49350bdfb80d4f00a698d195ad6cc3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fb37e6c0a6849b0ae4fca96c98079d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50b095287b764b40bc01eecfb8e226ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "549182ad731149e196c24e0c65368459": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54d833de2b3e4368a09e8f2832ae582a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43441f82927941c183c36d4ba42c6839",
       "placeholder": "​",
       "style": "IPY_MODEL_549182ad731149e196c24e0c65368459",
       "value": " 42/42 [00:06&lt;00:00,  6.63it/s]"
      }
     },
     "5809fb0e32f44de489c4ffd133aed91d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b6ddc597476439b98e2a8572db415ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f60bd20e6054b8d9990b2b2804e19a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6114b828351443dead1df1f805e5cfd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a008f4929ca442296cb2159b02d1206": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "873e173a1a48496183ab1a8b2425b3f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89aab12028bb44f0a421c39e5407e2c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a757d761f004d7faf0e86f35c7cc2ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d56ea444a554a8d86255febcfa438ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f60bd20e6054b8d9990b2b2804e19a1",
       "placeholder": "​",
       "style": "IPY_MODEL_37eb2c935499475c89e659645e41c052",
       "value": "100%"
      }
     },
     "8e1a02523adf4a51928bd01fe6a016a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1b2e1be36c74ff5802bee0472d05a8c",
        "IPY_MODEL_974821174ce548f7ab78f2eb280a36bc",
        "IPY_MODEL_54d833de2b3e4368a09e8f2832ae582a"
       ],
       "layout": "IPY_MODEL_49104b8e9766498997f1c107709166cd"
      }
     },
     "974821174ce548f7ab78f2eb280a36bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fb37e6c0a6849b0ae4fca96c98079d3",
       "max": 42,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a3cb9fa235b4d3b9fe4729d0488ab41",
       "value": 42
      }
     },
     "97ebc5f11183491097eaa468c8f8d6ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fdf9f1a806d45d8afc6aa7674799d7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d56ea444a554a8d86255febcfa438ef",
        "IPY_MODEL_bc93196873734683876ec5f8b4b4c62c",
        "IPY_MODEL_d34a43c029834695b633aa4d4d941930"
       ],
       "layout": "IPY_MODEL_873e173a1a48496183ab1a8b2425b3f1"
      }
     },
     "a1b2e1be36c74ff5802bee0472d05a8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07287dd36a6b457bab873107ef3a9a74",
       "placeholder": "​",
       "style": "IPY_MODEL_fc0e155d7357432c9976cb2ac7c68b3a",
       "value": "100%"
      }
     },
     "ac638cb770cd4789a3ad5944574c0685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b0ba62ab3b254a6897d45bb7a753f044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b5005dde82d843e7a0b50cdf2669d881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d7996506467449ad9ba51cfb1e6db002",
        "IPY_MODEL_d0ff43d2109d482884de8add17da97e7",
        "IPY_MODEL_f9647d54b313481eaa72a3093a5dbc0a"
       ],
       "layout": "IPY_MODEL_1c0862516d904ef7a8308a72e5ae9f91"
      }
     },
     "bc93196873734683876ec5f8b4b4c62c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa12da626fe2424eb7a18e996ed1fb96",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b6ddc597476439b98e2a8572db415ee",
       "value": 10
      }
     },
     "d0ef2e7de83043f5a1e56b8cbfdceb42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0ff43d2109d482884de8add17da97e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a30e5dd2b7e4e58b5f796dc56795f9d",
       "max": 40,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_97ebc5f11183491097eaa468c8f8d6ba",
       "value": 40
      }
     },
     "d34a43c029834695b633aa4d4d941930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_50b095287b764b40bc01eecfb8e226ce",
       "placeholder": "​",
       "style": "IPY_MODEL_7a008f4929ca442296cb2159b02d1206",
       "value": " 10/10 [00:02&lt;00:00,  5.02it/s]"
      }
     },
     "d7996506467449ad9ba51cfb1e6db002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8ec2cab76c64079add86c4cd9e47463",
       "placeholder": "​",
       "style": "IPY_MODEL_0f47d306ae4c4968ae9578b5d3f96717",
       "value": "100%"
      }
     },
     "e8ec2cab76c64079add86c4cd9e47463": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edea63966eb74395b1ccf14ba9265099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_03d6f570ff764870bb73ccfb8c6887af",
        "IPY_MODEL_28320ac6793c47f69b05122f608c2d44",
        "IPY_MODEL_0bdd95bee39a4c0fba0d526a76e11ed7"
       ],
       "layout": "IPY_MODEL_89aab12028bb44f0a421c39e5407e2c2"
      }
     },
     "f9647d54b313481eaa72a3093a5dbc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a757d761f004d7faf0e86f35c7cc2ef",
       "placeholder": "​",
       "style": "IPY_MODEL_b0ba62ab3b254a6897d45bb7a753f044",
       "value": " 40/40 [00:07&lt;00:00,  4.48it/s]"
      }
     },
     "fa12da626fe2424eb7a18e996ed1fb96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc0e155d7357432c9976cb2ac7c68b3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

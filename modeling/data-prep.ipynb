{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da5bc16-c974-469d-900a-3466788a1f87",
   "metadata": {},
   "source": [
    "### Notes for Modification\n",
    "\n",
    "- Wake - Hands overlapping with face.\n",
    "- Goose - Multiple variations of signs to represent the same thing.\n",
    "- Nap - Hands overlapping with face/ Eyes close\n",
    "- Give - Hands are closed.\n",
    "- After - Hands overlapping\n",
    "- Mouth - Hand closed, hand over mouth.\n",
    "\n",
    "Commons Things:\n",
    "- Closed hands\n",
    "- Hands over face\n",
    "- Overlapping landmarks\n",
    "\n",
    "Solutions:\n",
    "- Include eye landmarks.\n",
    "- Backfill missing data with previous landmark data.\n",
    "- Preserve relative distances between landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a3ae15-2917-4b25-8720-7a06c9b2529b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 00:46:55.190428: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 00:46:55.810409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit \n",
    "\n",
    "from layers.PreprocessLayer import PreprocessLayer\n",
    "from utils.Utils import print_shape_dtype, pd_read_s3_parquet, upload_file \n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import boto3\n",
    "import io\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775d7831-7725-4929-8ec3-635d3fe06ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f1ed6d7-4baf-4f6e-9727-59e277149865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config.json\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac357599-d129-4fb9-bb2d-0f1bf5c8c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65527ced-f65e-4159-abc7-cca17f2bce6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d092a1-8ca7-4cce-9989-fb904cd60c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0f9e50-16f8-4391-b3b5-acbac321d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 94477\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "N_SAMPLES = len(train)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66223025-c989-49dd-b662-a487c27d9bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'{AWS_S3_BUCKET}/raw-data/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e70a14b-8be1-496c-a1ad-88aeb640d814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48531589-2a82-43d6-8e54-4adcff751c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(train.head(30))\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b319f3f4-dac7-43aa-8972-ba5bbbf7b475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "#w251-asl-data/raw-data/train_landmark_files/28656/3311214787.parquet\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35150b8-20d6-48b4-a6d3-6cab6f1357a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "# USE_TYPES = ['left_hand', 'pose', 'right_hand']\n",
    "# START_IDX = 468\n",
    "# LIPS_IDXS0 = np.array([\n",
    "#         61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "#         291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "#         78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "#         95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "#     ])\n",
    "# # Landmark indices in original data\n",
    "# LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "# RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "# POSE_IDXS0 = np.arange(502, 512)\n",
    "# LANDMARK_IDXS0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, POSE_IDXS0))\n",
    "\n",
    "LIPS_IDXS0 = [0, 11, 12, 13, 14, 15, 17, 37, 38, 39, 40, 41, 42, 61, 62, 72, 73, \n",
    "        74, 76, 77, 78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 146, \n",
    "        178, 179, 180, 181, 183, 184, 185, 191, 267, 268, 269, 270, 271, 272, \n",
    "        291, 292, 302, 303, 304, 306, 307, 308, 310, 311, 312, 314, 316, 317, \n",
    "        318, 319, 320, 321, 324, 325, 375, 402, 403, 404, 405, 407, 408, 409, 415]\n",
    "\n",
    "EYES_IDXS0 = [  6,   7,  22,  23,  24,  25,  26,  30,  31,  33,  56, 110, 112,\n",
    "       113, 122, 128, 130, 133, 144, 145, 153, 154, 155, 157, 158, 159,\n",
    "       160, 161, 163, 168, 173, 188, 189, 190, 193, 196, 197, 232, 233,\n",
    "       243, 244, 245, 246, 247, 249, 252, 253, 254, 255, 256, 259, 260,\n",
    "       263, 286, 339, 341, 351, 357, 359, 362, 373, 374, 380, 381, 382,\n",
    "       384, 385, 386, 387, 388, 390, 398, 412, 413, 414, 417, 419, 453,\n",
    "       463, 464, 465, 466, 467]\n",
    "\n",
    "POSE_IDXS0 = np.arange(489, 514)\n",
    "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "\n",
    "LANDMARK_IDXS0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, EYES_IDXS0, POSE_IDXS0))\n",
    "N_COLS = LANDMARK_IDXS0.size\n",
    "\n",
    "HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
    "\n",
    "# Landmark indices in processed data\n",
    "# LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, LIPS_IDXS0)).squeeze()\n",
    "# LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, LEFT_HAND_IDXS0)).squeeze()\n",
    "# RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, RIGHT_HAND_IDXS0)).squeeze()\n",
    "# HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, HAND_IDXS0)).squeeze()\n",
    "# POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, POSE_IDXS0)).squeeze()\n",
    "\n",
    "# print(f'# HAND_IDXS: {len(HAND_IDXS0)}, N_COLS: {N_COLS}')\n",
    "# LIPS_START = 0\n",
    "# LEFT_HAND_START = LIPS_IDXS.size\n",
    "# RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
    "# POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size\n",
    "\n",
    "# print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, RIGHT_HAND_START: {RIGHT_HAND_START}, POSE_START: {POSE_START}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c319d84-7646-4a42-b4ce-8e2e1c9d3f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_layer = PreprocessLayer(config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae5f2ac-9674-4aac-9fb3-bc623a4ce9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ee2a897-3852-4f3b-9823-88be2b3977ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = config[\"DATA_VERSION\"]\n",
    "\n",
    "# Get the full dataset\n",
    "def preprocess_dataset():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, config[\"INPUT_SIZE\"]], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "    \n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    \n",
    "    # Put to S3\n",
    "    upload_file(\"./X.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/X.npy')\n",
    "    upload_file(\"./y.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/y.npy')\n",
    "    upload_file(\"./NON_EMPTY_FRAME_IDXS.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "    \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4a87a-890c-4985-9840-d45ca9e91569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb355f6baf343a5a0655141e83eb922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/94477\n",
      "Generated 5000/94477\n",
      "Generated 10000/94477\n"
     ]
    }
   ],
   "source": [
    "X, y, NON_EMPTY_FRAME_IDXS = preprocess_dataset()\n",
    "\n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492118d3-97a3-4a2d-a2a3-1d2eb8485cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(pd.Series(y).value_counts().to_frame('Class Count').iloc[[0,1,2,3,4, -5,-4,-3,-2,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864425d-7123-42bb-b1f1-5a082e86e6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/X.npy')\n",
    "X = np.load(io.BytesIO(X['Body'].read()))\n",
    "\n",
    "y = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/y.npy')\n",
    "y = np.load(io.BytesIO(y['Body'].read()))\n",
    "\n",
    "NON_EMPTY_FRAME_IDXS = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "NON_EMPTY_FRAME_IDXS = np.load(io.BytesIO(NON_EMPTY_FRAME_IDXS['Body'].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb1fc-88f3-4ba5-be78-6d7a5b4ecb47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd_read_s3_parquet(\"raw-data/train_landmark_files/28656/1000106739.parquet\", AWS_S3_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c95b20-e4a3-44c0-bc2b-5eb011e9a7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[(data['frame']==29) & (data[\"type\"] == \"pose\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa148b6a-d52e-48c6-9403-2341ae477e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[(data['frame']==29) & (data.index.isin(POSE_IDXS0))].plot.scatter(x='x',y='y', marker='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

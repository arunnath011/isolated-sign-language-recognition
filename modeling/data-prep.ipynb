{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da5bc16-c974-469d-900a-3466788a1f87",
   "metadata": {},
   "source": [
    "### Notes for Modification\n",
    "\n",
    "- Wake - Hands overlapping with face.\n",
    "- Goose - Multiple variations of signs to represent the same thing.\n",
    "- Nap - Hands overlapping with face/ Eyes close\n",
    "- Give - Hands are closed.\n",
    "- After - Hands overlapping\n",
    "- Mouth - Hand closed, hand over mouth.\n",
    "\n",
    "Commons Things:\n",
    "- Closed hands\n",
    "- Hands over face\n",
    "- Overlapping landmarks\n",
    "\n",
    "Solutions:\n",
    "- Include eye landmarks.\n",
    "- Backfill missing data with previous landmark data.\n",
    "- Preserve relative distances between landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a3ae15-2917-4b25-8720-7a06c9b2529b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 18:30:01.732606: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 18:30:03.312750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit \n",
    "\n",
    "from layers.PreprocessLayer import PreprocessLayer\n",
    "from utils.Utils import print_shape_dtype, pd_read_s3_parquet, upload_file \n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import boto3\n",
    "import io\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775d7831-7725-4929-8ec3-635d3fe06ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1ed6d7-4baf-4f6e-9727-59e277149865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac357599-d129-4fb9-bb2d-0f1bf5c8c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65527ced-f65e-4159-abc7-cca17f2bce6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d092a1-8ca7-4cce-9989-fb904cd60c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef0f9e50-16f8-4391-b3b5-acbac321d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 94477\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "N_SAMPLES = len(train)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66223025-c989-49dd-b662-a487c27d9bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'{AWS_S3_BUCKET}/raw-data/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e70a14b-8be1-496c-a1ad-88aeb640d814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48531589-2a82-43d6-8e54-4adcff751c41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sign_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/28...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/16...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/25...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/62...</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_landmark_files/26734/1000241583.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000241583</td>\n",
       "      <td>duck</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_landmark_files/26734/1000255522.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000255522</td>\n",
       "      <td>minemy</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_landmark_files/32319/1000278229.parquet</td>\n",
       "      <td>32319</td>\n",
       "      <td>1000278229</td>\n",
       "      <td>lips</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/32...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_landmark_files/37055/100035691.parquet</td>\n",
       "      <td>37055</td>\n",
       "      <td>100035691</td>\n",
       "      <td>flower</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/37...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_landmark_files/29302/100039661.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>100039661</td>\n",
       "      <td>time</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/29...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train_landmark_files/49445/1000397667.parquet</td>\n",
       "      <td>49445</td>\n",
       "      <td>1000397667</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/49...</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train_landmark_files/36257/1000536928.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>1000536928</td>\n",
       "      <td>apple</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/36...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train_landmark_files/22343/1000638205.parquet</td>\n",
       "      <td>22343</td>\n",
       "      <td>1000638205</td>\n",
       "      <td>puzzle</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/22...</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train_landmark_files/26734/1000661926.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000661926</td>\n",
       "      <td>mitten</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train_landmark_files/27610/1000697904.parquet</td>\n",
       "      <td>27610</td>\n",
       "      <td>1000697904</td>\n",
       "      <td>there</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/27...</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train_landmark_files/28656/1000862366.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000862366</td>\n",
       "      <td>dry</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/28...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train_landmark_files/61333/1000909322.parquet</td>\n",
       "      <td>61333</td>\n",
       "      <td>1000909322</td>\n",
       "      <td>shirt</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/61...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train_landmark_files/27610/1000956928.parquet</td>\n",
       "      <td>27610</td>\n",
       "      <td>1000956928</td>\n",
       "      <td>owl</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/27...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_landmark_files/26734/1001145816.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1001145816</td>\n",
       "      <td>yellow</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train_landmark_files/28656/1001158776.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1001158776</td>\n",
       "      <td>time</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/28...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>train_landmark_files/22343/1001223069.parquet</td>\n",
       "      <td>22343</td>\n",
       "      <td>1001223069</td>\n",
       "      <td>not</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/22...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>train_landmark_files/32319/1001258102.parquet</td>\n",
       "      <td>32319</td>\n",
       "      <td>1001258102</td>\n",
       "      <td>zipper</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/32...</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>train_landmark_files/26734/1001284511.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1001284511</td>\n",
       "      <td>clean</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>train_landmark_files/53618/1001363076.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>1001363076</td>\n",
       "      <td>closet</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/53...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>train_landmark_files/34503/100137027.parquet</td>\n",
       "      <td>34503</td>\n",
       "      <td>100137027</td>\n",
       "      <td>quiet</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/34...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>train_landmark_files/18796/1001373962.parquet</td>\n",
       "      <td>18796</td>\n",
       "      <td>1001373962</td>\n",
       "      <td>have</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/18...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>train_landmark_files/53618/1001379621.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>1001379621</td>\n",
       "      <td>brother</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/53...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>train_landmark_files/4718/1001385785.parquet</td>\n",
       "      <td>4718</td>\n",
       "      <td>1001385785</td>\n",
       "      <td>clown</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/47...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>train_landmark_files/55372/1001471195.parquet</td>\n",
       "      <td>55372</td>\n",
       "      <td>1001471195</td>\n",
       "      <td>cheek</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/55...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>train_landmark_files/53618/1001490690.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>1001490690</td>\n",
       "      <td>cute</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/53...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             path  participant_id  \\\n",
       "0   train_landmark_files/26734/1000035562.parquet           26734   \n",
       "1   train_landmark_files/28656/1000106739.parquet           28656   \n",
       "2    train_landmark_files/16069/100015657.parquet           16069   \n",
       "3   train_landmark_files/25571/1000210073.parquet           25571   \n",
       "4   train_landmark_files/62590/1000240708.parquet           62590   \n",
       "5   train_landmark_files/26734/1000241583.parquet           26734   \n",
       "6   train_landmark_files/26734/1000255522.parquet           26734   \n",
       "7   train_landmark_files/32319/1000278229.parquet           32319   \n",
       "8    train_landmark_files/37055/100035691.parquet           37055   \n",
       "9    train_landmark_files/29302/100039661.parquet           29302   \n",
       "10  train_landmark_files/49445/1000397667.parquet           49445   \n",
       "11  train_landmark_files/36257/1000536928.parquet           36257   \n",
       "12  train_landmark_files/22343/1000638205.parquet           22343   \n",
       "13  train_landmark_files/26734/1000661926.parquet           26734   \n",
       "14  train_landmark_files/27610/1000697904.parquet           27610   \n",
       "15  train_landmark_files/28656/1000862366.parquet           28656   \n",
       "16  train_landmark_files/61333/1000909322.parquet           61333   \n",
       "17  train_landmark_files/27610/1000956928.parquet           27610   \n",
       "18  train_landmark_files/26734/1001145816.parquet           26734   \n",
       "19  train_landmark_files/28656/1001158776.parquet           28656   \n",
       "20  train_landmark_files/22343/1001223069.parquet           22343   \n",
       "21  train_landmark_files/32319/1001258102.parquet           32319   \n",
       "22  train_landmark_files/26734/1001284511.parquet           26734   \n",
       "23  train_landmark_files/53618/1001363076.parquet           53618   \n",
       "24   train_landmark_files/34503/100137027.parquet           34503   \n",
       "25  train_landmark_files/18796/1001373962.parquet           18796   \n",
       "26  train_landmark_files/53618/1001379621.parquet           53618   \n",
       "27   train_landmark_files/4718/1001385785.parquet            4718   \n",
       "28  train_landmark_files/55372/1001471195.parquet           55372   \n",
       "29  train_landmark_files/53618/1001490690.parquet           53618   \n",
       "\n",
       "    sequence_id     sign                                          file_path  \\\n",
       "0    1000035562     blow  w251-asl-data/raw-data/train_landmark_files/26...   \n",
       "1    1000106739     wait  w251-asl-data/raw-data/train_landmark_files/28...   \n",
       "2     100015657    cloud  w251-asl-data/raw-data/train_landmark_files/16...   \n",
       "3    1000210073     bird  w251-asl-data/raw-data/train_landmark_files/25...   \n",
       "4    1000240708     owie  w251-asl-data/raw-data/train_landmark_files/62...   \n",
       "5    1000241583     duck  w251-asl-data/raw-data/train_landmark_files/26...   \n",
       "6    1000255522   minemy  w251-asl-data/raw-data/train_landmark_files/26...   \n",
       "7    1000278229     lips  w251-asl-data/raw-data/train_landmark_files/32...   \n",
       "8     100035691   flower  w251-asl-data/raw-data/train_landmark_files/37...   \n",
       "9     100039661     time  w251-asl-data/raw-data/train_landmark_files/29...   \n",
       "10   1000397667   vacuum  w251-asl-data/raw-data/train_landmark_files/49...   \n",
       "11   1000536928    apple  w251-asl-data/raw-data/train_landmark_files/36...   \n",
       "12   1000638205   puzzle  w251-asl-data/raw-data/train_landmark_files/22...   \n",
       "13   1000661926   mitten  w251-asl-data/raw-data/train_landmark_files/26...   \n",
       "14   1000697904    there  w251-asl-data/raw-data/train_landmark_files/27...   \n",
       "15   1000862366      dry  w251-asl-data/raw-data/train_landmark_files/28...   \n",
       "16   1000909322    shirt  w251-asl-data/raw-data/train_landmark_files/61...   \n",
       "17   1000956928      owl  w251-asl-data/raw-data/train_landmark_files/27...   \n",
       "18   1001145816   yellow  w251-asl-data/raw-data/train_landmark_files/26...   \n",
       "19   1001158776     time  w251-asl-data/raw-data/train_landmark_files/28...   \n",
       "20   1001223069      not  w251-asl-data/raw-data/train_landmark_files/22...   \n",
       "21   1001258102   zipper  w251-asl-data/raw-data/train_landmark_files/32...   \n",
       "22   1001284511    clean  w251-asl-data/raw-data/train_landmark_files/26...   \n",
       "23   1001363076   closet  w251-asl-data/raw-data/train_landmark_files/53...   \n",
       "24    100137027    quiet  w251-asl-data/raw-data/train_landmark_files/34...   \n",
       "25   1001373962     have  w251-asl-data/raw-data/train_landmark_files/18...   \n",
       "26   1001379621  brother  w251-asl-data/raw-data/train_landmark_files/53...   \n",
       "27   1001385785    clown  w251-asl-data/raw-data/train_landmark_files/47...   \n",
       "28   1001471195    cheek  w251-asl-data/raw-data/train_landmark_files/55...   \n",
       "29   1001490690     cute  w251-asl-data/raw-data/train_landmark_files/53...   \n",
       "\n",
       "    sign_ord  \n",
       "0         25  \n",
       "1        232  \n",
       "2         48  \n",
       "3         23  \n",
       "4        164  \n",
       "5         67  \n",
       "6        143  \n",
       "7        134  \n",
       "8         86  \n",
       "9        220  \n",
       "10       231  \n",
       "11         8  \n",
       "12       180  \n",
       "13       144  \n",
       "14       216  \n",
       "15        65  \n",
       "16       195  \n",
       "17       165  \n",
       "18       243  \n",
       "19       220  \n",
       "20       156  \n",
       "21       249  \n",
       "22        45  \n",
       "23        47  \n",
       "24       181  \n",
       "25       108  \n",
       "26        30  \n",
       "27        49  \n",
       "28        41  \n",
       "29        54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94477 entries, 0 to 94476\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            94477 non-null  object\n",
      " 1   participant_id  94477 non-null  int64 \n",
      " 2   sequence_id     94477 non-null  int64 \n",
      " 3   sign            94477 non-null  object\n",
      " 4   file_path       94477 non-null  object\n",
      " 5   sign_ord        94477 non-null  int16 \n",
      "dtypes: int16(1), int64(2), object(3)\n",
      "memory usage: 3.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head(30))\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b319f3f4-dac7-43aa-8972-ba5bbbf7b475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "#w251-asl-data/raw-data/train_landmark_files/28656/3311214787.parquet\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35150b8-20d6-48b4-a6d3-6cab6f1357a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "# USE_TYPES = ['left_hand', 'pose', 'right_hand']\n",
    "# START_IDX = 468\n",
    "# LIPS_IDXS0 = np.array([\n",
    "#         61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "#         291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "#         78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "#         95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "#     ])\n",
    "# # Landmark indices in original data\n",
    "# LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "# RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "# POSE_IDXS0 = np.arange(502, 512)\n",
    "# LANDMARK_IDXS0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, POSE_IDXS0))\n",
    "\n",
    "LIPS_IDXS0 = [0, 11, 12, 13, 14, 15, 17, 37, 38, 39, 40, 41, 42, 61, 62, 72, 73, \n",
    "        74, 76, 77, 78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 146, \n",
    "        178, 179, 180, 181, 183, 184, 185, 191, 267, 268, 269, 270, 271, 272, \n",
    "        291, 292, 302, 303, 304, 306, 307, 308, 310, 311, 312, 314, 316, 317, \n",
    "        318, 319, 320, 321, 324, 325, 375, 402, 403, 404, 405, 407, 408, 409, 415]\n",
    "\n",
    "EYES_IDXS0 = [  6,   7,  22,  23,  24,  25,  26,  30,  31,  33,  56, 110, 112,\n",
    "       113, 122, 128, 130, 133, 144, 145, 153, 154, 155, 157, 158, 159,\n",
    "       160, 161, 163, 168, 173, 188, 189, 190, 193, 196, 197, 232, 233,\n",
    "       243, 244, 245, 246, 247, 249, 252, 253, 254, 255, 256, 259, 260,\n",
    "       263, 286, 339, 341, 351, 357, 359, 362, 373, 374, 380, 381, 382,\n",
    "       384, 385, 386, 387, 388, 390, 398, 412, 413, 414, 417, 419, 453,\n",
    "       463, 464, 465, 466, 467]\n",
    "\n",
    "POSE_IDXS0 = np.arange(489, 514)\n",
    "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "\n",
    "LANDMARK_IDXS0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, EYES_IDXS0, POSE_IDXS0))\n",
    "N_COLS = LANDMARK_IDXS0.size\n",
    "\n",
    "HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
    "\n",
    "# Landmark indices in processed data\n",
    "# LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, LIPS_IDXS0)).squeeze()\n",
    "# LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, LEFT_HAND_IDXS0)).squeeze()\n",
    "# RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, RIGHT_HAND_IDXS0)).squeeze()\n",
    "# HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, HAND_IDXS0)).squeeze()\n",
    "# POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, POSE_IDXS0)).squeeze()\n",
    "\n",
    "# print(f'# HAND_IDXS: {len(HAND_IDXS0)}, N_COLS: {N_COLS}')\n",
    "# LIPS_START = 0\n",
    "# LEFT_HAND_START = LIPS_IDXS.size\n",
    "# RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
    "# POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size\n",
    "\n",
    "# print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, RIGHT_HAND_START: {RIGHT_HAND_START}, POSE_START: {POSE_START}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c319d84-7646-4a42-b4ce-8e2e1c9d3f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_layer = PreprocessLayer(config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae5f2ac-9674-4aac-9fb3-bc623a4ce9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ee2a897-3852-4f3b-9823-88be2b3977ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = config[\"DATA_VERSION\"]\n",
    "\n",
    "# Get the full dataset\n",
    "def preprocess_dataset():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, config[\"INPUT_SIZE\"]], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "    \n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    \n",
    "    # Put to S3\n",
    "    upload_file(\"./X.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/X.npy')\n",
    "    upload_file(\"./y.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/y.npy')\n",
    "    upload_file(\"./NON_EMPTY_FRAME_IDXS.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "    \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb4a87a-890c-4985-9840-d45ca9e91569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1aaf18f62d4081b30d60216270693a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/94477\n",
      "Generated 5000/94477\n",
      "Generated 10000/94477\n",
      "Generated 15000/94477\n",
      "Generated 20000/94477\n",
      "Generated 25000/94477\n",
      "Generated 30000/94477\n",
      "Generated 35000/94477\n",
      "Generated 40000/94477\n",
      "Generated 45000/94477\n",
      "Generated 50000/94477\n",
      "Generated 55000/94477\n",
      "Generated 60000/94477\n",
      "Generated 70000/94477\n",
      "Generated 75000/94477\n",
      "Generated 80000/94477\n",
      "Generated 85000/94477\n",
      "Generated 90000/94477\n",
      "X shape: (94477, 96, 454), dtype: float32\n",
      "y shape: (94477,), dtype: int32\n",
      "NON_EMPTY_FRAME_IDXS shape: (94477, 96), dtype: float32\n",
      "# NaN Values X: 0\n"
     ]
    }
   ],
   "source": [
    "X, y, NON_EMPTY_FRAME_IDXS = preprocess_dataset()\n",
    "\n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492118d3-97a3-4a2d-a2a3-1d2eb8485cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(pd.Series(y).value_counts().to_frame('Class Count').iloc[[0,1,2,3,4, -5,-4,-3,-2,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864425d-7123-42bb-b1f1-5a082e86e6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/X.npy')\n",
    "X = np.load(io.BytesIO(X['Body'].read()))\n",
    "\n",
    "y = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/y.npy')\n",
    "y = np.load(io.BytesIO(y['Body'].read()))\n",
    "\n",
    "NON_EMPTY_FRAME_IDXS = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "NON_EMPTY_FRAME_IDXS = np.load(io.BytesIO(NON_EMPTY_FRAME_IDXS['Body'].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb1fc-88f3-4ba5-be78-6d7a5b4ecb47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd_read_s3_parquet(\"raw-data/train_landmark_files/28656/1000106739.parquet\", AWS_S3_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c95b20-e4a3-44c0-bc2b-5eb011e9a7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[(data['frame']==29) & (data[\"type\"] == \"pose\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa148b6a-d52e-48c6-9403-2341ae477e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[(data['frame']==29) & (data.index.isin(POSE_IDXS0))].plot.scatter(x='x',y='y', marker='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

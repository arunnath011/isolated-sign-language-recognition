{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da5bc16-c974-469d-900a-3466788a1f87",
   "metadata": {},
   "source": [
    "### Notes for Modification\n",
    "\n",
    "- Wake - Hands overlapping with face.\n",
    "- Goose - Multiple variations of signs to represent the same thing.\n",
    "- Nap - Hands overlapping with face/ Eyes close\n",
    "- Give - Hands are closed.\n",
    "- After - Hands overlapping\n",
    "- Mouth - Hand closed, hand over mouth.\n",
    "\n",
    "Commons Things:\n",
    "- Closed hands\n",
    "- Hands over face\n",
    "- Overlapping landmarks\n",
    "\n",
    "Solutions:\n",
    "- Include eye landmarks.\n",
    "- Backfill missing data with previous landmark data.\n",
    "- Preserve relative distances between landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a3ae15-2917-4b25-8720-7a06c9b2529b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 20:02:11.800819: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-14 20:02:13.346470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit \n",
    "\n",
    "from layers.PreprocessLayer import PreprocessLayer\n",
    "from utils.Utils import print_shape_dtype, pd_read_s3_parquet, upload_file \n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import boto3\n",
    "import io\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d7831-7725-4929-8ec3-635d3fe06ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1ed6d7-4baf-4f6e-9727-59e277149865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac357599-d129-4fb9-bb2d-0f1bf5c8c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65527ced-f65e-4159-abc7-cca17f2bce6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d092a1-8ca7-4cce-9989-fb904cd60c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef0f9e50-16f8-4391-b3b5-acbac321d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 94477\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "N_SAMPLES = len(train)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66223025-c989-49dd-b662-a487c27d9bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'{AWS_S3_BUCKET}/raw-data/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e70a14b-8be1-496c-a1ad-88aeb640d814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48531589-2a82-43d6-8e54-4adcff751c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(train.head(30))\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b319f3f4-dac7-43aa-8972-ba5bbbf7b475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "#w251-asl-data/raw-data/train_landmark_files/28656/3311214787.parquet\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c319d84-7646-4a42-b4ce-8e2e1c9d3f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 20:02:24.584683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:24.969414: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:24.971881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:24.974953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:24.976936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:24.978759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:26.831560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:26.832561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:26.833318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-14 20:02:26.834029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20561 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "preprocess_layer = PreprocessLayer(config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aae5f2ac-9674-4aac-9fb3-bc623a4ce9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee2a897-3852-4f3b-9823-88be2b3977ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = config[\"DATA_VERSION\"]\n",
    "\n",
    "# Get the full dataset\n",
    "def preprocess_dataset():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, config[\"INPUT_SIZE\"]], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "    \n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    \n",
    "    # Put to S3\n",
    "    upload_file(\"./X.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/X.npy')\n",
    "    upload_file(\"./y.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/y.npy')\n",
    "    upload_file(\"./NON_EMPTY_FRAME_IDXS.npy\", AWS_S3_BUCKET, f'processed-data/v{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "    \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb4a87a-890c-4985-9840-d45ca9e91569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414634a4c94846639e089d89d35ac017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/94477\n",
      "Generated 5000/94477\n",
      "Generated 10000/94477\n",
      "Generated 15000/94477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 35000/94477\n",
      "Generated 40000/94477\n",
      "Generated 45000/94477\n",
      "Generated 50000/94477\n",
      "Generated 55000/94477\n",
      "Generated 60000/94477\n",
      "Generated 65000/94477\n",
      "Generated 70000/94477\n",
      "Generated 75000/94477\n",
      "Generated 80000/94477\n",
      "Generated 85000/94477\n",
      "Generated 90000/94477\n",
      "X shape: (94477, 38, 454), dtype: float32\n",
      "y shape: (94477,), dtype: int32\n",
      "NON_EMPTY_FRAME_IDXS shape: (94477, 38), dtype: float32\n",
      "# NaN Values X: 0\n"
     ]
    }
   ],
   "source": [
    "X, y, NON_EMPTY_FRAME_IDXS = preprocess_dataset()\n",
    "\n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492118d3-97a3-4a2d-a2a3-1d2eb8485cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(pd.Series(y).value_counts().to_frame('Class Count').iloc[[0,1,2,3,4, -5,-4,-3,-2,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864425d-7123-42bb-b1f1-5a082e86e6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/X.npy')\n",
    "X = np.load(io.BytesIO(X['Body'].read()))\n",
    "\n",
    "y = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/y.npy')\n",
    "y = np.load(io.BytesIO(y['Body'].read()))\n",
    "\n",
    "NON_EMPTY_FRAME_IDXS = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/v{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "NON_EMPTY_FRAME_IDXS = np.load(io.BytesIO(NON_EMPTY_FRAME_IDXS['Body'].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb1fc-88f3-4ba5-be78-6d7a5b4ecb47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd_read_s3_parquet(\"raw-data/train_landmark_files/28656/1000106739.parquet\", AWS_S3_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c95b20-e4a3-44c0-bc2b-5eb011e9a7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[(data['frame']==29) & (data[\"type\"] == \"pose\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa148b6a-d52e-48c6-9403-2341ae477e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[(data['frame']==29) & (data.index.isin(POSE_IDXS0))].plot.scatter(x='x',y='y', marker='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

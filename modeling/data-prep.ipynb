{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a3ae15-2917-4b25-8720-7a06c9b2529b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 03:03:18.593512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 03:03:19.213064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit \n",
    "\n",
    "from layers.PreprocessLayer import PreprocessLayer\n",
    "from utils.Utils import print_shape_dtype, pd_read_s3_parquet, upload_file \n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import boto3\n",
    "import io\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1ed6d7-4baf-4f6e-9727-59e277149865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If True, processing data from scratch\n",
    "# If False, loads preprocessed data\n",
    "PREPROCESS_DATA = False\n",
    "TRAIN_MODEL = True\n",
    "# False: use 10% of participants as validation set\n",
    "# True: use all data for training -> gives better LB result\n",
    "USE_VAL = True\n",
    "\n",
    "N_ROWS = 543\n",
    "N_DIMS = 2\n",
    "DIM_NAMES = ['x', 'y']\n",
    "SEED = 42\n",
    "NUM_CLASaSES = 250\n",
    "\n",
    "# Number of frames \n",
    "INPUT_SIZE = 32\n",
    "\n",
    "BATCH_ALL_SIGNS_N = 4\n",
    "BATCH_SIZE = 256 # Batch size during validation.\n",
    "N_EPOCHS = 100\n",
    "N_WARMUP_EPOCHS = 0\n",
    "WD_RATIO = 0.05\n",
    "MASK_VAL = 4237\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac357599-d129-4fb9-bb2d-0f1bf5c8c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65527ced-f65e-4159-abc7-cca17f2bce6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d092a1-8ca7-4cce-9989-fb904cd60c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef0f9e50-16f8-4391-b3b5-acbac321d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 5000\n"
     ]
    }
   ],
   "source": [
    "# Read Training Data\n",
    "if not PREPROCESS_DATA:\n",
    "    train = pd.read_csv(train_file.get(\"Body\")).sample(int(5e3), random_state=SEED)\n",
    "else:\n",
    "    train = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "N_SAMPLES = len(train)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66223025-c989-49dd-b662-a487c27d9bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'{AWS_S3_BUCKET}/raw-data/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e70a14b-8be1-496c-a1ad-88aeb640d814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48531589-2a82-43d6-8e54-4adcff751c41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sign_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56533</th>\n",
       "      <td>train_landmark_files/28656/3311214787.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>3311214787</td>\n",
       "      <td>sticky</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/28...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63119</th>\n",
       "      <td>train_landmark_files/53618/3588192588.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>3588192588</td>\n",
       "      <td>before</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/53...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>train_landmark_files/4718/1363575346.parquet</td>\n",
       "      <td>4718</td>\n",
       "      <td>1363575346</td>\n",
       "      <td>pretty</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/47...</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93310</th>\n",
       "      <td>train_landmark_files/37779/951199059.parquet</td>\n",
       "      <td>37779</td>\n",
       "      <td>951199059</td>\n",
       "      <td>hen</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/37...</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44842</th>\n",
       "      <td>train_landmark_files/36257/283190141.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>283190141</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/36...</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20993</th>\n",
       "      <td>train_landmark_files/61333/186594661.parquet</td>\n",
       "      <td>61333</td>\n",
       "      <td>186594661</td>\n",
       "      <td>up</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/61...</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89267</th>\n",
       "      <td>train_landmark_files/53618/782770724.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>782770724</td>\n",
       "      <td>blow</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/53...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48370</th>\n",
       "      <td>train_landmark_files/16069/2977903115.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>2977903115</td>\n",
       "      <td>weus</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/16...</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41330</th>\n",
       "      <td>train_landmark_files/2044/269101282.parquet</td>\n",
       "      <td>2044</td>\n",
       "      <td>269101282</td>\n",
       "      <td>read</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/20...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53090</th>\n",
       "      <td>train_landmark_files/28656/3171133897.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>3171133897</td>\n",
       "      <td>say</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/28...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34809</th>\n",
       "      <td>train_landmark_files/49445/2425523049.parquet</td>\n",
       "      <td>49445</td>\n",
       "      <td>2425523049</td>\n",
       "      <td>zebra</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/49...</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63078</th>\n",
       "      <td>train_landmark_files/18796/3586377265.parquet</td>\n",
       "      <td>18796</td>\n",
       "      <td>3586377265</td>\n",
       "      <td>sad</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/18...</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94163</th>\n",
       "      <td>train_landmark_files/34503/98693993.parquet</td>\n",
       "      <td>34503</td>\n",
       "      <td>98693993</td>\n",
       "      <td>drawer</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/34...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>train_landmark_files/2044/1051321002.parquet</td>\n",
       "      <td>2044</td>\n",
       "      <td>1051321002</td>\n",
       "      <td>animal</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/20...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71053</th>\n",
       "      <td>train_landmark_files/4718/3910863104.parquet</td>\n",
       "      <td>4718</td>\n",
       "      <td>3910863104</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/47...</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>train_landmark_files/2044/1250922352.parquet</td>\n",
       "      <td>2044</td>\n",
       "      <td>1250922352</td>\n",
       "      <td>pen</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/20...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88327</th>\n",
       "      <td>train_landmark_files/62590/744022975.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>744022975</td>\n",
       "      <td>donkey</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/62...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44991</th>\n",
       "      <td>train_landmark_files/2044/2837571064.parquet</td>\n",
       "      <td>2044</td>\n",
       "      <td>2837571064</td>\n",
       "      <td>cheek</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/20...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71239</th>\n",
       "      <td>train_landmark_files/32319/3918793625.parquet</td>\n",
       "      <td>32319</td>\n",
       "      <td>3918793625</td>\n",
       "      <td>cowboy</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/32...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80516</th>\n",
       "      <td>train_landmark_files/34503/429577301.parquet</td>\n",
       "      <td>34503</td>\n",
       "      <td>429577301</td>\n",
       "      <td>scissors</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/34...</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84011</th>\n",
       "      <td>train_landmark_files/53618/56956873.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>56956873</td>\n",
       "      <td>quiet</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/53...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54050</th>\n",
       "      <td>train_landmark_files/2044/3211327389.parquet</td>\n",
       "      <td>2044</td>\n",
       "      <td>3211327389</td>\n",
       "      <td>drink</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/20...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76071</th>\n",
       "      <td>train_landmark_files/27610/4114691251.parquet</td>\n",
       "      <td>27610</td>\n",
       "      <td>4114691251</td>\n",
       "      <td>girl</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/27...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93002</th>\n",
       "      <td>train_landmark_files/55372/93822631.parquet</td>\n",
       "      <td>55372</td>\n",
       "      <td>93822631</td>\n",
       "      <td>sleepy</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/55...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>train_landmark_files/49445/1033363053.parquet</td>\n",
       "      <td>49445</td>\n",
       "      <td>1033363053</td>\n",
       "      <td>zipper</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/49...</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64266</th>\n",
       "      <td>train_landmark_files/49445/363452260.parquet</td>\n",
       "      <td>49445</td>\n",
       "      <td>363452260</td>\n",
       "      <td>pig</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/49...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87112</th>\n",
       "      <td>train_landmark_files/2044/693617786.parquet</td>\n",
       "      <td>2044</td>\n",
       "      <td>693617786</td>\n",
       "      <td>bad</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/20...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35093</th>\n",
       "      <td>train_landmark_files/26734/2435587578.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>2435587578</td>\n",
       "      <td>arm</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>train_landmark_files/26734/1226679715.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1226679715</td>\n",
       "      <td>down</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76135</th>\n",
       "      <td>train_landmark_files/30680/411700859.parquet</td>\n",
       "      <td>30680</td>\n",
       "      <td>411700859</td>\n",
       "      <td>if</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/30...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "56533  train_landmark_files/28656/3311214787.parquet           28656   \n",
       "63119  train_landmark_files/53618/3588192588.parquet           53618   \n",
       "8760    train_landmark_files/4718/1363575346.parquet            4718   \n",
       "93310   train_landmark_files/37779/951199059.parquet           37779   \n",
       "44842   train_landmark_files/36257/283190141.parquet           36257   \n",
       "20993   train_landmark_files/61333/186594661.parquet           61333   \n",
       "89267   train_landmark_files/53618/782770724.parquet           53618   \n",
       "48370  train_landmark_files/16069/2977903115.parquet           16069   \n",
       "41330    train_landmark_files/2044/269101282.parquet            2044   \n",
       "53090  train_landmark_files/28656/3171133897.parquet           28656   \n",
       "34809  train_landmark_files/49445/2425523049.parquet           49445   \n",
       "63078  train_landmark_files/18796/3586377265.parquet           18796   \n",
       "94163    train_landmark_files/34503/98693993.parquet           34503   \n",
       "1246    train_landmark_files/2044/1051321002.parquet            2044   \n",
       "71053   train_landmark_files/4718/3910863104.parquet            4718   \n",
       "6071    train_landmark_files/2044/1250922352.parquet            2044   \n",
       "88327   train_landmark_files/62590/744022975.parquet           62590   \n",
       "44991   train_landmark_files/2044/2837571064.parquet            2044   \n",
       "71239  train_landmark_files/32319/3918793625.parquet           32319   \n",
       "80516   train_landmark_files/34503/429577301.parquet           34503   \n",
       "84011    train_landmark_files/53618/56956873.parquet           53618   \n",
       "54050   train_landmark_files/2044/3211327389.parquet            2044   \n",
       "76071  train_landmark_files/27610/4114691251.parquet           27610   \n",
       "93002    train_landmark_files/55372/93822631.parquet           55372   \n",
       "788    train_landmark_files/49445/1033363053.parquet           49445   \n",
       "64266   train_landmark_files/49445/363452260.parquet           49445   \n",
       "87112    train_landmark_files/2044/693617786.parquet            2044   \n",
       "35093  train_landmark_files/26734/2435587578.parquet           26734   \n",
       "5473   train_landmark_files/26734/1226679715.parquet           26734   \n",
       "76135   train_landmark_files/30680/411700859.parquet           30680   \n",
       "\n",
       "       sequence_id      sign  \\\n",
       "56533   3311214787    sticky   \n",
       "63119   3588192588    before   \n",
       "8760    1363575346    pretty   \n",
       "93310    951199059       hen   \n",
       "44842    283190141  tomorrow   \n",
       "20993    186594661        up   \n",
       "89267    782770724      blow   \n",
       "48370   2977903115      weus   \n",
       "41330    269101282      read   \n",
       "53090   3171133897       say   \n",
       "34809   2425523049     zebra   \n",
       "63078   3586377265       sad   \n",
       "94163     98693993    drawer   \n",
       "1246    1051321002    animal   \n",
       "71053   3910863104  tomorrow   \n",
       "6071    1250922352       pen   \n",
       "88327    744022975    donkey   \n",
       "44991   2837571064     cheek   \n",
       "71239   3918793625    cowboy   \n",
       "80516    429577301  scissors   \n",
       "84011     56956873     quiet   \n",
       "54050   3211327389     drink   \n",
       "76071   4114691251      girl   \n",
       "93002     93822631    sleepy   \n",
       "788     1033363053    zipper   \n",
       "64266    363452260       pig   \n",
       "87112    693617786       bad   \n",
       "35093   2435587578       arm   \n",
       "5473    1226679715      down   \n",
       "76135    411700859        if   \n",
       "\n",
       "                                               file_path  sign_ord  \n",
       "56533  w251-asl-data/raw-data/train_landmark_files/28...       206  \n",
       "63119  w251-asl-data/raw-data/train_landmark_files/53...        20  \n",
       "8760   w251-asl-data/raw-data/train_landmark_files/47...       178  \n",
       "93310  w251-asl-data/raw-data/train_landmark_files/37...       114  \n",
       "44842  w251-asl-data/raw-data/train_landmark_files/36...       221  \n",
       "20993  w251-asl-data/raw-data/train_landmark_files/61...       230  \n",
       "89267  w251-asl-data/raw-data/train_landmark_files/53...        25  \n",
       "48370  w251-asl-data/raw-data/train_landmark_files/16...       236  \n",
       "41330  w251-asl-data/raw-data/train_landmark_files/20...       184  \n",
       "53090  w251-asl-data/raw-data/train_landmark_files/28...       191  \n",
       "34809  w251-asl-data/raw-data/train_landmark_files/49...       248  \n",
       "63078  w251-asl-data/raw-data/train_landmark_files/18...       189  \n",
       "94163  w251-asl-data/raw-data/train_landmark_files/34...        62  \n",
       "1246   w251-asl-data/raw-data/train_landmark_files/20...         5  \n",
       "71053  w251-asl-data/raw-data/train_landmark_files/47...       221  \n",
       "6071   w251-asl-data/raw-data/train_landmark_files/20...       167  \n",
       "88327  w251-asl-data/raw-data/train_landmark_files/62...        60  \n",
       "44991  w251-asl-data/raw-data/train_landmark_files/20...        41  \n",
       "71239  w251-asl-data/raw-data/train_landmark_files/32...        51  \n",
       "80516  w251-asl-data/raw-data/train_landmark_files/34...       192  \n",
       "84011  w251-asl-data/raw-data/train_landmark_files/53...       181  \n",
       "54050  w251-asl-data/raw-data/train_landmark_files/20...        63  \n",
       "76071  w251-asl-data/raw-data/train_landmark_files/27...        94  \n",
       "93002  w251-asl-data/raw-data/train_landmark_files/55...       200  \n",
       "788    w251-asl-data/raw-data/train_landmark_files/49...       249  \n",
       "64266  w251-asl-data/raw-data/train_landmark_files/49...       171  \n",
       "87112  w251-asl-data/raw-data/train_landmark_files/20...        13  \n",
       "35093  w251-asl-data/raw-data/train_landmark_files/26...         9  \n",
       "5473   w251-asl-data/raw-data/train_landmark_files/26...        61  \n",
       "76135  w251-asl-data/raw-data/train_landmark_files/30...       123  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 56533 to 19516\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            5000 non-null   object\n",
      " 1   participant_id  5000 non-null   int64 \n",
      " 2   sequence_id     5000 non-null   int64 \n",
      " 3   sign            5000 non-null   object\n",
      " 4   file_path       5000 non-null   object\n",
      " 5   sign_ord        5000 non-null   int16 \n",
      "dtypes: int16(1), int64(2), object(3)\n",
      "memory usage: 244.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head(30))\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b319f3f4-dac7-43aa-8972-ba5bbbf7b475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "#w251-asl-data/raw-data/train_landmark_files/28656/3311214787.parquet\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35150b8-20d6-48b4-a6d3-6cab6f1357a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HAND_IDXS: 42, N_COLS: 92\n"
     ]
    }
   ],
   "source": [
    "USE_TYPES = ['left_hand', 'pose', 'right_hand']\n",
    "START_IDX = 468\n",
    "LIPS_IDXS0 = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "# Landmark indices in original data\n",
    "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "POSE_IDXS0 = np.arange(502, 512)\n",
    "LANDMARK_IDXS0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, POSE_IDXS0))\n",
    "HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
    "N_COLS = LANDMARK_IDXS0.size\n",
    "# Landmark indices in processed data\n",
    "LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, LIPS_IDXS0)).squeeze()\n",
    "LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, LEFT_HAND_IDXS0)).squeeze()\n",
    "RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, RIGHT_HAND_IDXS0)).squeeze()\n",
    "HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, HAND_IDXS0)).squeeze()\n",
    "POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, POSE_IDXS0)).squeeze()\n",
    "\n",
    "print(f'# HAND_IDXS: {len(HAND_IDXS)}, N_COLS: {N_COLS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd859631-8867-48f8-8e79-73b9d907ae7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPS_START: 0, LEFT_HAND_START: 40, RIGHT_HAND_START: 61, POSE_START: 82\n"
     ]
    }
   ],
   "source": [
    "LIPS_START = 0\n",
    "LEFT_HAND_START = LIPS_IDXS.size\n",
    "RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
    "POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size\n",
    "\n",
    "print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, RIGHT_HAND_START: {RIGHT_HAND_START}, POSE_START: {POSE_START}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c319d84-7646-4a42-b4ce-8e2e1c9d3f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_layer = PreprocessLayer(N_ROWS, N_DIMS, HAND_IDXS0, LANDMARK_IDXS0, INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aae5f2ac-9674-4aac-9fb3-bc623a4ce9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee2a897-3852-4f3b-9823-88be2b3977ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "\n",
    "# Get the full dataset\n",
    "def get_x_y():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "    \n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    \n",
    "    # Put to S3\n",
    "    upload_file(\"./X.npy\", AWS_S3_BUCKET, f'processed-data/{version}/X.npy')\n",
    "    upload_file(\"./y.npy\", AWS_S3_BUCKET, f'processed-data/{version}/y.npy')\n",
    "    upload_file(\"./NON_EMPTY_FRAME_IDXS.npy\", AWS_S3_BUCKET, f'processed-data/{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "    \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceb4a87a-890c-4985-9840-d45ca9e91569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (94477, 32, 92, 2), dtype: float32\n",
      "y shape: (94477,), dtype: int32\n",
      "NON_EMPTY_FRAME_IDXS shape: (94477, 32), dtype: float32\n",
      "# NaN Values X: 0\n"
     ]
    }
   ],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    X, y, NON_EMPTY_FRAME_IDXS = get_x_y()\n",
    "else:\n",
    "    X = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/{version}/X.npy')\n",
    "    X = np.load(io.BytesIO(X['Body'].read()))\n",
    "    \n",
    "    y = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/{version}/y.npy')\n",
    "    y = np.load(io.BytesIO(y['Body'].read()))\n",
    "    \n",
    "    NON_EMPTY_FRAME_IDXS = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=f'processed-data/{version}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "    NON_EMPTY_FRAME_IDXS = np.load(io.BytesIO(NON_EMPTY_FRAME_IDXS['Body'].read()))\n",
    "    \n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "492118d3-97a3-4a2d-a2a3-1d2eb8485cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class Count\n",
       "135          415\n",
       "136          414\n",
       "194          411\n",
       "60           410\n",
       "148          408\n",
       "56           312\n",
       "170          312\n",
       "21           310\n",
       "231          307\n",
       "249          299"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.Series(y).value_counts().to_frame('Class Count').iloc[[0,1,2,3,4, -5,-4,-3,-2,-1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

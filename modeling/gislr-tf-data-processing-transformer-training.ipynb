{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eecc96b",
   "metadata": {
    "papermill": {
     "duration": 0.018147,
     "end_time": "2023-04-04T19:58:22.456290",
     "exception": false,
     "start_time": "2023-04-04T19:58:22.438143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hello Fellow Kagglers,\n",
    "\n",
    "This notebook demonstrates the data processing and training process in Tensorflow.\n",
    "\n",
    "I am excited about this competition, because my Master Thesis was on sign language recognition.\n",
    "\n",
    "**Data Processing**\n",
    "\n",
    "Only lips, hands and arm pose coordinates are used.\n",
    "\n",
    "A custom Tensorflow layer handles the data processing. In short, it filters all frames without coordinates for the hands and downsamples the input to 32 frames if it is too long.\n",
    "\n",
    "**Model**\n",
    "\n",
    "A transformer based model is used. The embedding layer makes an ambedding per landmark(lips/left hand/right hand/arm pose) and merges these embedding with fully connected layers. The transformer consists of just 2 blocks with a simple mean pooling and fully connected layers for classification.\n",
    "\n",
    "\n",
    "**V2**\n",
    "\n",
    "* Learnable attention weights for each landmark\n",
    "* Removed layer normalisation in embedding to prevent double layer normalisation at the end of embedding and start of transformer\n",
    "* Removed additional fully connected layer in head before classification layer\n",
    "\n",
    "**V3**\n",
    "\n",
    "* Using all data for training\n",
    "* Increased final embedding size 384 -> 512\n",
    "* Added 10% dropout in classification layer\n",
    "* Increased number of epoch 50 -> 100\n",
    "* Number of transformer heads 8 -> 4\n",
    "\n",
    "**V5**\n",
    "\n",
    "* Corrected `USE_VAL` comments thanks to comment from [Jackson You](https://www.kaggle.com/jacksonyou)\n",
    "* Corrected bug in preprocessing layer thanks to comment from [bilzard](https://www.kaggle.com/tatamikenn)\n",
    "* Increased `INPUT_SIZE` 32 -> 64 and added label smoothing based on this [notebook](https://www.kaggle.com/code/hengck23/lb-0-73-single-fold-transformer-architecture) by [hengck23](https://www.kaggle.com/hengck23)\n",
    "* Removed layer normalisation in transformer blocks. Model is very shallow. Conventional transformers have 10s of blocks, GPT-3 for example 96 and ViT-Huge 32, in contrast to this tiny transformer of just 2 blocks. The layer normalisation does not seem to be needed in such shallow networks.\n",
    "* Biggest difference, normalisation to a single hand. When normalised to left handed, less than 1 percent of the right handed frames was filled. The model consists of only the lips, left hand and left arm pose.\n",
    "\n",
    "V5 will most likely be the last update to keep this competition competitive.\n",
    "\n",
    "Good luck to all of you in the last month of this exciting competition!\n",
    "\n",
    "If you have any feedback or questions, please feel free to leave a comment.\n",
    "\n",
    "Expect updates in the coming weeks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3f49e2",
   "metadata": {
    "papermill": {
     "duration": 8.350689,
     "end_time": "2023-04-04T19:58:30.824967",
     "exception": false,
     "start_time": "2023-04-04T19:58:22.474278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 17:16:02.495065: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 17:16:03.147123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow V2.12.0\n",
      "Keras V2.12.0\n",
      "Python V3.10.10 (main, Mar 24 2023, 16:01:42) [GCC 7.3.1 20180712 (Red Hat 7.3.1-15)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit \n",
    "from utils.Utils import pd_read_s3_parquet\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import boto3\n",
    "\n",
    "print(f'Tensorflow V{tf.__version__}')\n",
    "print(f'Keras V{tf.keras.__version__}')\n",
    "print(f'Python V{sys.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89553e",
   "metadata": {
    "papermill": {
     "duration": 0.02654,
     "end_time": "2023-04-04T19:58:30.877883",
     "exception": false,
     "start_time": "2023-04-04T19:58:30.851343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Plot Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901b607d",
   "metadata": {
    "papermill": {
     "duration": 0.040529,
     "end_time": "2023-04-04T19:58:30.944471",
     "exception": false,
     "start_time": "2023-04-04T19:58:30.903942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MatplotLib Global Settings\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['axes.titlesize'] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa494d",
   "metadata": {
    "papermill": {
     "duration": 0.026058,
     "end_time": "2023-04-04T19:58:30.996237",
     "exception": false,
     "start_time": "2023-04-04T19:58:30.970179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762bad5b",
   "metadata": {
    "papermill": {
     "duration": 0.038947,
     "end_time": "2023-04-04T19:58:31.063826",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.024879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If True, processing data from scratch\n",
    "# If False, loads preprocessed data\n",
    "PREPROCESS_DATA = True\n",
    "TRAIN_MODEL = True\n",
    "# True: use 10% of participants as validation set\n",
    "# False: use all data for training -> gives better LB result\n",
    "USE_VAL = False\n",
    "\n",
    "N_ROWS = 543\n",
    "N_DIMS = 2\n",
    "DIM_NAMES = ['x', 'y', 'z']\n",
    "SEED = 42\n",
    "NUM_CLASSES = 250\n",
    "VERBOSE = 2\n",
    "\n",
    "INPUT_SIZE = 38\n",
    "\n",
    "BATCH_ALL_SIGNS_N = 4\n",
    "BATCH_SIZE = 256\n",
    "N_EPOCHS = 100\n",
    "LR_MAX = 1e-3\n",
    "N_WARMUP_EPOCHS = 0\n",
    "WD_RATIO = 0.05\n",
    "MASK_VAL = 4237"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d018d",
   "metadata": {
    "papermill": {
     "duration": 0.025524,
     "end_time": "2023-04-04T19:58:31.114942",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.089418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c4f9d7",
   "metadata": {
    "papermill": {
     "duration": 0.03575,
     "end_time": "2023-04-04T19:58:31.176034",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.140284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prints Shape and Dtype For List Of Variables\n",
    "def print_shape_dtype(l, names):\n",
    "    for e, n in zip(l, names):\n",
    "        print(f'{n} shape: {e.shape}, dtype: {e.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144b07f",
   "metadata": {
    "papermill": {
     "duration": 0.025582,
     "end_time": "2023-04-04T19:58:31.226617",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.201035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7131dfd-b746-4df6-8f82-bb8a3142e94f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 94477\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")\n",
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\"\n",
    "train_file = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=TRAIN_CSV_FILE)\n",
    "train = pd.read_csv(train_file.get(\"Body\"))\n",
    "\n",
    "\n",
    "N_SAMPLES = len(train)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d90aa1",
   "metadata": {
    "papermill": {
     "duration": 0.016353,
     "end_time": "2023-04-04T19:58:31.510616",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.494263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Add File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134954ea",
   "metadata": {
    "papermill": {
     "duration": 0.032462,
     "end_time": "2023-04-04T19:58:31.559654",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.527192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'{AWS_S3_BUCKET}/raw-data/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc6453",
   "metadata": {
    "papermill": {
     "duration": 0.016537,
     "end_time": "2023-04-04T19:58:31.592802",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.576265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ordinally Encode Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f49136",
   "metadata": {
    "papermill": {
     "duration": 0.040708,
     "end_time": "2023-04-04T19:58:31.650777",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.610069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503b02a4",
   "metadata": {
    "papermill": {
     "duration": 0.054582,
     "end_time": "2023-04-04T19:58:31.723379",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.668797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sign_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/26...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/28...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/16...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/25...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>w251-asl-data/raw-data/train_landmark_files/62...</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign                                          file_path  sign_ord  \n",
       "0   blow  w251-asl-data/raw-data/train_landmark_files/26...        25  \n",
       "1   wait  w251-asl-data/raw-data/train_landmark_files/28...       232  \n",
       "2  cloud  w251-asl-data/raw-data/train_landmark_files/16...        48  \n",
       "3   bird  w251-asl-data/raw-data/train_landmark_files/25...        23  \n",
       "4   owie  w251-asl-data/raw-data/train_landmark_files/62...       164  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94477 entries, 0 to 94476\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            94477 non-null  object\n",
      " 1   participant_id  94477 non-null  int64 \n",
      " 2   sequence_id     94477 non-null  int64 \n",
      " 3   sign            94477 non-null  object\n",
      " 4   file_path       94477 non-null  object\n",
      " 5   sign_ord        94477 non-null  int16 \n",
      "dtypes: int16(1), int64(2), object(3)\n",
      "memory usage: 3.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head(5))\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056cedf",
   "metadata": {
    "papermill": {
     "duration": 0.017343,
     "end_time": "2023-04-04T19:58:31.758550",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.741207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Video Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2017f0ce",
   "metadata": {
    "papermill": {
     "duration": 22.721605,
     "end_time": "2023-04-04T19:58:54.497903",
     "exception": false,
     "start_time": "2023-04-04T19:58:31.776298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N = int(10e3)\n",
    "# N_UNIQUE_FRAMES = np.zeros(N, dtype=np.uint16)\n",
    "# N_MISSING_FRAMES = np.zeros(N, dtype=np.uint16)\n",
    "# MAX_FRAME = np.zeros(N, dtype=np.uint16)\n",
    "\n",
    "# PERCENTILES = [0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99, 0.999]\n",
    "\n",
    "# for idx, file_path in enumerate(tqdm(train['file_path'].sample(N, random_state=SEED))):\n",
    "#     df = pd.read_parquet(file_path)\n",
    "#     N_UNIQUE_FRAMES[idx] = df['frame'].nunique()\n",
    "#     N_MISSING_FRAMES[idx] = (df['frame'].max() - df['frame'].min()) - df['frame'].nunique() + 1\n",
    "#     MAX_FRAME[idx] = df['frame'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6ecd36",
   "metadata": {
    "papermill": {
     "duration": 0.58055,
     "end_time": "2023-04-04T19:58:55.096436",
     "exception": false,
     "start_time": "2023-04-04T19:58:54.515886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Number of unique frames in each video\n",
    "# display(pd.Series(N_UNIQUE_FRAMES).describe(percentiles=PERCENTILES).to_frame('N_UNIQUE_FRAMES'))\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# plt.title('Number of Unique Frames', size=24)\n",
    "# pd.Series(N_UNIQUE_FRAMES).plot(kind='hist', bins=128)\n",
    "# plt.grid()\n",
    "# xlim = math.ceil(plt.xlim()[1])\n",
    "# plt.xlim(0, xlim)\n",
    "# plt.xticks(np.arange(0, xlim+25, 25))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6d5e52",
   "metadata": {
    "papermill": {
     "duration": 0.463688,
     "end_time": "2023-04-04T19:58:55.579287",
     "exception": false,
     "start_time": "2023-04-04T19:58:55.115599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Number of missing frames, consecutive frames with missing intermediate frame, i.e. 1,2,4,5 -> 3 is missing\n",
    "# display(pd.Series(N_MISSING_FRAMES).describe(percentiles=PERCENTILES).to_frame('N_MISSING_FRAMES'))\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# plt.title('Number of Missing Frames', size=24)\n",
    "# pd.Series(N_MISSING_FRAMES).plot(kind='hist', bins=128)\n",
    "# plt.grid()\n",
    "# plt.xlim(0, math.ceil(plt.xlim()[1]))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0345c30b",
   "metadata": {
    "papermill": {
     "duration": 0.458184,
     "end_time": "2023-04-04T19:58:56.057811",
     "exception": false,
     "start_time": "2023-04-04T19:58:55.599627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Maximum frame number\n",
    "# display(pd.Series(MAX_FRAME).describe(percentiles=PERCENTILES).to_frame('MAX_FRAME'))\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# plt.title('Maximum Frames Index', size=24)\n",
    "# pd.Series(MAX_FRAME).plot(kind='hist', bins=128)\n",
    "# plt.grid()\n",
    "# plt.xlim(0, math.ceil(plt.xlim()[1]))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087c2ea",
   "metadata": {
    "papermill": {
     "duration": 0.019627,
     "end_time": "2023-04-04T19:58:56.097315",
     "exception": false,
     "start_time": "2023-04-04T19:58:56.077688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Landmark Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab1b34f",
   "metadata": {
    "papermill": {
     "duration": 0.035155,
     "end_time": "2023-04-04T19:58:56.152680",
     "exception": false,
     "start_time": "2023-04-04T19:58:56.117525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE_TYPES = ['left_hand', 'pose', 'right_hand']\n",
    "# START_IDX = 468\n",
    "# LIPS_IDXS0 = np.array([\n",
    "#         61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "#         291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "#         78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "#         95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "#     ])\n",
    "# # Landmark indices in original data\n",
    "# LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "# RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "# LEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\n",
    "# RIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n",
    "# LANDMARK_IDXS_LEFT_DOMINANT0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, LEFT_POSE_IDXS0))\n",
    "# LANDMARK_IDXS_RIGHT_DOMINANT0 = np.concatenate((LIPS_IDXS0, RIGHT_HAND_IDXS0, RIGHT_POSE_IDXS0))\n",
    "# HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
    "# N_COLS = LANDMARK_IDXS_LEFT_DOMINANT0.size\n",
    "# # Landmark indices in processed data\n",
    "# LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LIPS_IDXS0)).squeeze()\n",
    "# LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_HAND_IDXS0)).squeeze()\n",
    "# RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, RIGHT_HAND_IDXS0)).squeeze()\n",
    "# HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, HAND_IDXS0)).squeeze()\n",
    "# POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_POSE_IDXS0)).squeeze()\n",
    "\n",
    "# print(f'# HAND_IDXS: {len(HAND_IDXS)}, N_COLS: {N_COLS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4e68a1-9415-492d-9ee5-0affd5fed77b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_COLS: 227\n"
     ]
    }
   ],
   "source": [
    "LIPS_IDXS0 = np.array([0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467])\n",
    "# Landmark indices in original data\n",
    "LEFT_HAND_IDXS0 = np.arange(468, 489)\n",
    "POSE_IDXS0 = np.arange(489, 514)\n",
    "\n",
    "RIGHT_HAND_IDXS0 = np.arange(522, 543)\n",
    "\n",
    "HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
    "LANDMARK_IDXS = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, POSE_IDXS0), axis=0)\n",
    "N_COLS = LANDMARK_IDXS.size\n",
    "# Landmark indices in processed data\n",
    "LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS, LIPS_IDXS0)).squeeze()\n",
    "LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS, LEFT_HAND_IDXS0)).squeeze()\n",
    "RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS, RIGHT_HAND_IDXS0)).squeeze()\n",
    "HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS, HAND_IDXS0)).squeeze()\n",
    "POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS, POSE_IDXS0)).squeeze()\n",
    "\n",
    "print(f'N_COLS: {N_COLS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa3926d",
   "metadata": {
    "papermill": {
     "duration": 0.029328,
     "end_time": "2023-04-04T19:58:56.201254",
     "exception": false,
     "start_time": "2023-04-04T19:58:56.171926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPS_START: 0, LEFT_HAND_START: 160, POSE_START: 181, RIGHT_HAND_START: 206\n"
     ]
    }
   ],
   "source": [
    "LIPS_START = 0\n",
    "LEFT_HAND_START = LIPS_IDXS.size\n",
    "POSE_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
    "RIGHT_HAND_START = POSE_START + POSE_IDXS.size\n",
    "\n",
    "print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, POSE_START: {POSE_START}, RIGHT_HAND_START: {RIGHT_HAND_START}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018c456",
   "metadata": {
    "papermill": {
     "duration": 0.019305,
     "end_time": "2023-04-04T19:58:56.240237",
     "exception": false,
     "start_time": "2023-04-04T19:58:56.220932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Process Data Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0051d551",
   "metadata": {
    "papermill": {
     "duration": 0.028194,
     "end_time": "2023-04-04T19:58:56.287722",
     "exception": false,
     "start_time": "2023-04-04T19:58:56.259528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08fe8f68",
   "metadata": {
    "papermill": {
     "duration": 2.709448,
     "end_time": "2023-04-04T19:58:59.016402",
     "exception": false,
     "start_time": "2023-04-04T19:58:56.306954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Tensorflow layer to process data in TFLite\n",
    "#     Data needs to be processed in the model itself, so we can not use Python\n",
    "# \"\"\" \n",
    "# class PreprocessLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(PreprocessLayer, self).__init__()\n",
    "#         normalisation_correction = tf.constant([\n",
    "#                     # Add 0.50 to left hand (original right hand) and substract 0.50 of right hand (original left hand)\n",
    "#                     [0] * len(LIPS_IDXS) + [0.50] * len(LEFT_HAND_IDXS) + [0.50] * len(POSE_IDXS),\n",
    "#                     # Y coordinates stay intact\n",
    "#                     [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n",
    "#                     # Z coordinates stay intact\n",
    "#                     [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n",
    "#                 ],\n",
    "#                 dtype=tf.float32,\n",
    "#             )\n",
    "#         self.normalisation_correction = tf.transpose(normalisation_correction, [1,0])\n",
    "        \n",
    "#     def pad_edge(self, t, repeats, side):\n",
    "#         if side == 'LEFT':\n",
    "#             return tf.concat((tf.repeat(t[:1], repeats=repeats, axis=0), t), axis=0)\n",
    "#         elif side == 'RIGHT':\n",
    "#             return tf.concat((t, tf.repeat(t[-1:], repeats=repeats, axis=0)), axis=0)\n",
    "        \n",
    "# #         N_FRAMES = tf.shape(data)[0]\n",
    "# #         data = tf.gather(data, self.LANDMARK_IDXS, axis=2)\n",
    "        \n",
    "# #         # Slice out face indicies, normalize across batch.        \n",
    "# #         face = tf.slice(data, [0, self.FACE_START, 0], [N_FRAMES, self.LEFT_HAND_START, 2])\n",
    "        \n",
    "# #         # Slice out left_hand indicies, normalize across batch.\n",
    "# #         left_hand = tf.slice(data, [0, self.LEFT_HAND_START, 0], [N_FRAMES, self.POSE_START-self.LEFT_HAND_START, 2])\n",
    "        \n",
    "# #         # Slice out pose indicies, normalize across batch.\n",
    "# #         pose = tf.slice(data, [0, self.POSE_START, 0], [N_FRAMES, self.RIGHT_HAND_START-self.POSE_START, 2])\n",
    "        \n",
    "# #         # Slice out right_hand indicies, normalize across batch.\n",
    "# #         right_hand = tf.slice(data, [0, self.RIGHT_HAND_START, 0], [N_FRAMES, tf.shape(data)[2] - self.RIGHT_HAND_START, 2])\n",
    "        \n",
    "# #         # Concat landmarks back into same frame.\n",
    "# #         data = tf.concat([face, left_hand, pose, right_hand], 1)\n",
    "        \n",
    "# #         # Video fits in self.INPUT_SIZE\n",
    "# #         if N_FRAMES < self.INPUT_SIZE: # Number of frames we want\n",
    "# #             # Attention mask for frames that contain data. \n",
    "# #             non_empty_frames_idxs = tf.pad(tf.range(0, N_FRAMES, 1), [[0, self.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "# #             data = tf.pad(data, [[0, self.INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "# #             # Fill NaN Values With 0\n",
    "# #             data = tf.where(tf.math.is_nan(data), 0, data)\n",
    "# #             # Reshape into (Number of desired frames, (Number of landmarks * 2))\n",
    "# #             data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "# #             return data, non_empty_frames_idxs\n",
    "# #         # Video needs to be downsampled to INPUT_SIZE\n",
    "# #         else:\n",
    "# #             # Downsample video using nearest interpolation method. \n",
    "# #             data = tf.image.resize(data, size=(self.INPUT_SIZE, data.shape[1]), method='nearest')\n",
    "# #             # Fill NaN Values With 0\n",
    "# #             data = tf.where(tf.math.is_nan(data), 0, data)\n",
    "# #             # Reshape into (Number of desired frames, (Number of landmarks * 2)).\n",
    "# #             data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "# #             # Create attention mask with all frames. \n",
    "# #             non_empty_frames_idxs = tf.range(0, self.INPUT_SIZE, 1)\n",
    "# #             return data, non_empty_frames_idxs\n",
    "    \n",
    "#     @tf.function(\n",
    "#         input_signature=(tf.TensorSpec(shape=[None,N_ROWS,N_DIMS], dtype=tf.float32),),\n",
    "#     )\n",
    "#     def call(self, data0):\n",
    "#         # Number of Frames in Video\n",
    "#         N_FRAMES0 = tf.shape(data0)[0]\n",
    "        \n",
    "#         # Find dominant hand by comparing summed absolute coordinates\n",
    "#         left_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1))\n",
    "#         right_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1))\n",
    "#         left_dominant = left_hand_sum >= right_hand_sum\n",
    "        \n",
    "#         # Count non NaN Hand values in each frame for the dominant hand\n",
    "#         if left_dominant:\n",
    "#             frames_hands_non_nan_sum = tf.math.reduce_sum(\n",
    "#                     tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1),\n",
    "#                     axis=[1, 2],\n",
    "#                 )\n",
    "#         else:\n",
    "#             frames_hands_non_nan_sum = tf.math.reduce_sum(\n",
    "#                     tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1),\n",
    "#                     axis=[1, 2],\n",
    "#                 )\n",
    "        \n",
    "#         # Find frames indices with coordinates of dominant hand\n",
    "#         non_empty_frames_idxs = tf.where(frames_hands_non_nan_sum > 0)\n",
    "#         non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
    "#         # Filter frames\n",
    "#         data = tf.gather(data0, non_empty_frames_idxs, axis=0)\n",
    "        \n",
    "#         # Cast Indices in float32 to be compatible with Tensorflow Lite\n",
    "#         non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32)\n",
    "#         # Normalize to start with 0\n",
    "#         non_empty_frames_idxs -= tf.reduce_min(non_empty_frames_idxs)\n",
    "        \n",
    "#         # Number of Frames in Filtered Video\n",
    "#         N_FRAMES = tf.shape(data)[0]\n",
    "        \n",
    "#         # Gather Relevant Landmark Columns\n",
    "#         if left_dominant:\n",
    "#             data = tf.gather(data, LANDMARK_IDXS_LEFT_DOMINANT0, axis=1)\n",
    "#         else:\n",
    "#             data = tf.gather(data, LANDMARK_IDXS_RIGHT_DOMINANT0, axis=1)\n",
    "#             data = (\n",
    "#                     self.normalisation_correction + (\n",
    "#                         (data - self.normalisation_correction) * tf.where(self.normalisation_correction != 0, -1.0, 1.0))\n",
    "#                 )\n",
    "        \n",
    "#         # Video fits in INPUT_SIZE\n",
    "#         if N_FRAMES < INPUT_SIZE:\n",
    "#             # Pad With -1 to indicate padding\n",
    "#             non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "#             # Pad Data With Zeros\n",
    "#             data = tf.pad(data, [[0, INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "#             # Fill NaN Values With 0\n",
    "#             data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "#             return data, non_empty_frames_idxs\n",
    "#         # Video needs to be downsampled to INPUT_SIZE\n",
    "#         else:\n",
    "#             # Repeat\n",
    "#             if N_FRAMES < INPUT_SIZE**2:\n",
    "#                 repeats = tf.math.floordiv(INPUT_SIZE * INPUT_SIZE, N_FRAMES0)\n",
    "#                 data = tf.repeat(data, repeats=repeats, axis=0)\n",
    "#                 non_empty_frames_idxs = tf.repeat(non_empty_frames_idxs, repeats=repeats, axis=0)\n",
    "\n",
    "#             # Pad To Multiple Of Input Size\n",
    "#             pool_size = tf.math.floordiv(len(data), INPUT_SIZE)\n",
    "#             if tf.math.mod(len(data), INPUT_SIZE) > 0:\n",
    "#                 pool_size += 1\n",
    "\n",
    "#             if pool_size == 1:\n",
    "#                 pad_size = (pool_size * INPUT_SIZE) - len(data)\n",
    "#             else:\n",
    "#                 pad_size = (pool_size * INPUT_SIZE) % len(data)\n",
    "\n",
    "#             # Pad Start/End with Start/End value\n",
    "#             pad_left = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n",
    "#             pad_right = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n",
    "#             if tf.math.mod(pad_size, 2) > 0:\n",
    "#                 pad_right += 1\n",
    "\n",
    "#             # Pad By Concatenating Left/Right Edge Values\n",
    "#             data = self.pad_edge(data, pad_left, 'LEFT')\n",
    "#             data = self.pad_edge(data, pad_right, 'RIGHT')\n",
    "\n",
    "#             # Pad Non Empty Frame Indices\n",
    "#             non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_left, 'LEFT')\n",
    "#             non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_right, 'RIGHT')\n",
    "\n",
    "#             # Reshape to Mean Pool\n",
    "#             data = tf.reshape(data, [INPUT_SIZE, -1, N_COLS, N_DIMS])\n",
    "#             non_empty_frames_idxs = tf.reshape(non_empty_frames_idxs, [INPUT_SIZE, -1])\n",
    "\n",
    "#             # Mean Pool\n",
    "#             data = tf.experimental.numpy.nanmean(data, axis=1)\n",
    "#             non_empty_frames_idxs = tf.experimental.numpy.nanmean(non_empty_frames_idxs, axis=1)\n",
    "\n",
    "#             # Fill NaN Values With 0\n",
    "#             data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            \n",
    "#             return data, non_empty_frames_idxs\n",
    "    \n",
    "# preprocess_layer = PreprocessLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f56799-cc19-4537-a033-c40ecc3a2dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Tensorflow layer to process data in TFLite\n",
    "    Data needs to be processed in the model itself, so we can not use Python\n",
    "\"\"\" \n",
    "class PreprocessLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PreprocessLayer, self).__init__()\n",
    "\n",
    "    # @tf.function(\n",
    "    #     input_signature=(tf.TensorSpec(shape=[None,N_ROWS,3], dtype=tf.float32),),\n",
    "    # )\n",
    "    def call(self, data0):\n",
    "        \n",
    "        # Number of Frames in Filtered Video\n",
    "        N_FRAMES = tf.shape(data0)[0]\n",
    "        \n",
    "        # Gather Relevant Landmark Columns\n",
    "        data = tf.gather(data0, LANDMARK_IDXS, axis=1)\n",
    "    \n",
    "        # Video fits in INPUT_SIZE\n",
    "        if N_FRAMES < INPUT_SIZE:\n",
    "            # Pad With -1 to indicate padding\n",
    "            non_empty_frames_idxs = tf.pad(tf.range(0, N_FRAMES, 1), [[0, INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            # Pad Data With Zeros\n",
    "            data = tf.pad(data, [[0, INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            return data, non_empty_frames_idxs\n",
    "        # Video needs to be downsampled to INPUT_SIZE\n",
    "        else:\n",
    "            data = tf.image.resize(data, size=(INPUT_SIZE, data.shape[1]), method='nearest')\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0, data)\n",
    "            # Create attention mask with all frames. \n",
    "            non_empty_frames_idxs = tf.range(0, INPUT_SIZE, 1)\n",
    "            return data, non_empty_frames_idxs\n",
    "    \n",
    "preprocess_layer = PreprocessLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3949c17",
   "metadata": {
    "papermill": {
     "duration": 0.019569,
     "end_time": "2023-04-04T19:58:59.056215",
     "exception": false,
     "start_time": "2023-04-04T19:58:59.036646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Interpolate NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df34ad24",
   "metadata": {
    "papermill": {
     "duration": 0.028933,
     "end_time": "2023-04-04T19:58:59.104677",
     "exception": false,
     "start_time": "2023-04-04T19:58:59.075744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83812d7f",
   "metadata": {
    "papermill": {
     "duration": 0.019211,
     "end_time": "2023-04-04T19:58:59.143664",
     "exception": false,
     "start_time": "2023-04-04T19:58:59.124453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "828a5533",
   "metadata": {
    "papermill": {
     "duration": 0.03485,
     "end_time": "2023-04-04T19:58:59.197716",
     "exception": false,
     "start_time": "2023-04-04T19:58:59.162866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the full dataset\n",
    "def preprocess_data():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "\n",
    "    # Fill X/y\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        # Log message every 5000 samples\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        # Sanity check, data should not contain NaN values\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "\n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    \n",
    "    # Save Validation\n",
    "    splitter = GroupShuffleSplit(test_size=0.10, n_splits=2, random_state=SEED)\n",
    "    PARTICIPANT_IDS = train['participant_id'].values\n",
    "    train_idxs, val_idxs = next(splitter.split(X, y, groups=PARTICIPANT_IDS))\n",
    "\n",
    "    # Save Train\n",
    "    X_train = X[train_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
    "    y_train = y[train_idxs]\n",
    "    np.save('X_train.npy', X_train)\n",
    "    np.save('y_train.npy', y_train)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n",
    "    # Save Validation\n",
    "    X_val = X[val_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
    "    y_val = y[val_idxs]\n",
    "    np.save('X_val.npy', X_val)\n",
    "    np.save('y_val.npy', y_val)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n",
    "    # Split Statistics\n",
    "    print(f'Patient ID Intersection Train/Val: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs])}')\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "    print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef358f",
   "metadata": {
    "papermill": {
     "duration": 27.790382,
     "end_time": "2023-04-04T19:59:27.007971",
     "exception": false,
     "start_time": "2023-04-04T19:58:59.217589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd599f6894646708184a26c0e5ba251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/94477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 17:16:05.540266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:05.561282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:05.563160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:05.566812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:05.568633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:05.570428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:06.094537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:06.095517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:06.096278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 17:16:06.096993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20561 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Preprocess All Data From Scratch\n",
    "if PREPROCESS_DATA:\n",
    "    preprocess_data()\n",
    "ROOT_DIR = '.'\n",
    "    \n",
    "# Load Data\n",
    "if USE_VAL:\n",
    "    # Load Train\n",
    "    X_train = np.load(f'{ROOT_DIR}/X_train.npy')\n",
    "    y_train = np.load(f'{ROOT_DIR}/y_train.npy')\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS_TRAIN.npy')\n",
    "    # Load Val\n",
    "    X_val = np.load(f'{ROOT_DIR}/X_val.npy')\n",
    "    y_val = np.load(f'{ROOT_DIR}/y_val.npy')\n",
    "    NON_EMPTY_FRAME_IDXS_VAL = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS_VAL.npy')\n",
    "    # Define validation Data\n",
    "    validation_data = ({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, y_val)\n",
    "else:\n",
    "    X_train = np.load(f'{ROOT_DIR}/X.npy')\n",
    "    y_train = np.load(f'{ROOT_DIR}/y.npy')\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "    validation_data = None\n",
    "\n",
    "# Train \n",
    "print_shape_dtype([X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN], ['X_train', 'y_train', 'NON_EMPTY_FRAME_IDXS_TRAIN'])\n",
    "# Val\n",
    "if USE_VAL:\n",
    "    print_shape_dtype([X_val, y_val, NON_EMPTY_FRAME_IDXS_VAL], ['X_val', 'y_val', 'NON_EMPTY_FRAME_IDXS_VAL'])\n",
    "# Sanity Check\n",
    "print(f'# NaN Values X_train: {np.isnan(X_train).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744c255",
   "metadata": {
    "papermill": {
     "duration": 0.041339,
     "end_time": "2023-04-04T19:59:27.070504",
     "exception": false,
     "start_time": "2023-04-04T19:59:27.029165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class Count\n",
    "display(pd.Series(y_train).value_counts().to_frame('Class Count').iloc[[0,1,2,3,4, -5,-4,-3,-2,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad08a5",
   "metadata": {
    "papermill": {
     "duration": 0.022277,
     "end_time": "2023-04-04T19:59:27.115439",
     "exception": false,
     "start_time": "2023-04-04T19:59:27.093162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Number Of Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4ebc0",
   "metadata": {
    "papermill": {
     "duration": 13.241164,
     "end_time": "2023-04-04T19:59:40.377776",
     "exception": false,
     "start_time": "2023-04-04T19:59:27.136612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Vast majority of samples fits has less than 32 non empty frames\n",
    "# N_EMPTY_FRAMES = (NON_EMPTY_FRAME_IDXS_TRAIN != -1).sum(axis=1) \n",
    "# N_EMPTY_FRAMES_WATERFALL = []\n",
    "# for n in tqdm(range(1,INPUT_SIZE+1)):\n",
    "#     N_EMPTY_FRAMES_WATERFALL.append(sum(N_EMPTY_FRAMES >= n) / len(NON_EMPTY_FRAME_IDXS_TRAIN) * 100)\n",
    "\n",
    "# plt.figure(figsize=(18,10))\n",
    "# plt.title('Waterfall Plot For Number Of Non Empty Frames')\n",
    "# pd.Series(N_EMPTY_FRAMES_WATERFALL).plot(kind='bar')\n",
    "# plt.grid(axis='y')\n",
    "# plt.xticks(np.arange(INPUT_SIZE), np.arange(1, INPUT_SIZE+1))\n",
    "# plt.xlabel('Number of Non Empty Frames', size=16)\n",
    "# plt.yticks(np.arange(0, 100+10, 10))\n",
    "# plt.ylim(0, 100)\n",
    "# plt.ylabel('Percentage of Samples With At Least N Non Empty Frames', size=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23b302",
   "metadata": {
    "papermill": {
     "duration": 0.020535,
     "end_time": "2023-04-04T19:59:40.419979",
     "exception": false,
     "start_time": "2023-04-04T19:59:40.399444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Percentage of Frames Filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fdb5e",
   "metadata": {
    "papermill": {
     "duration": 0.037864,
     "end_time": "2023-04-04T19:59:40.478875",
     "exception": false,
     "start_time": "2023-04-04T19:59:40.441011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Percentage of frames filled, this is the maximum fill percentage of each landmark\n",
    "# P_DATA_FILLED = (NON_EMPTY_FRAME_IDXS_TRAIN != -1).sum() / NON_EMPTY_FRAME_IDXS_TRAIN.size * 100\n",
    "# print(f'P_DATA_FILLED: {P_DATA_FILLED:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d6deb",
   "metadata": {
    "papermill": {
     "duration": 0.020623,
     "end_time": "2023-04-04T19:59:40.520131",
     "exception": false,
     "start_time": "2023-04-04T19:59:40.499508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Statistics - Lips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71fb6bd",
   "metadata": {
    "papermill": {
     "duration": 16.810231,
     "end_time": "2023-04-04T19:59:57.351001",
     "exception": false,
     "start_time": "2023-04-04T19:59:40.540770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Percentage of Lips Measurements\n",
    "# P_LEFT_LIPS_MEASUREMENTS = (X_train[:,:,LIPS_IDXS] != 0).sum() / X_train[:,:,LIPS_IDXS].size / P_DATA_FILLED * 1e4\n",
    "# print(f'P_LEFT_LIPS_MEASUREMENTS: {P_LEFT_LIPS_MEASUREMENTS:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d343c",
   "metadata": {
    "papermill": {
     "duration": 19.108485,
     "end_time": "2023-04-04T20:00:16.481153",
     "exception": false,
     "start_time": "2023-04-04T19:59:57.372668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lips_mean_std():\n",
    "    # LIPS\n",
    "    LIPS_MEAN_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "    LIPS_MEAN_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "    LIPS_STD_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "    LIPS_STD_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "\n",
    "#     fig, axes = plt.subplots(3, 1, figsize=(15, N_DIMS*6))\n",
    "\n",
    "#     for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,LIPS_IDXS], [2,3,0,1]).reshape([LIPS_IDXS.size, N_DIMS, -1]) )):\n",
    "#         for dim, l in enumerate(ll):\n",
    "#             v = l[np.nonzero(l)]\n",
    "#             if dim == 0: # X\n",
    "#                 LIPS_MEAN_X[col] = v.mean()\n",
    "#                 LIPS_STD_X[col] = v.std()\n",
    "#             if dim == 1: # Y\n",
    "#                 LIPS_MEAN_Y[col] = v.mean()\n",
    "#                 LIPS_STD_Y[col] = v.std()\n",
    "\n",
    "#             axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "\n",
    "#     for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "#         ax.set_title(f'Lips {dim_name.upper()} Dimension', size=24)\n",
    "#         ax.tick_params(axis='x', labelsize=8)\n",
    "#         ax.grid(axis='y')\n",
    "\n",
    "#     plt.subplots_adjust(hspace=0.50)\n",
    "#     plt.show()\n",
    "\n",
    "    LIPS_MEAN = np.array([LIPS_MEAN_X, LIPS_MEAN_Y]).T\n",
    "    LIPS_STD = np.array([LIPS_STD_X, LIPS_STD_Y]).T\n",
    "    \n",
    "    return LIPS_MEAN, LIPS_STD\n",
    "\n",
    "LIPS_MEAN, LIPS_STD = get_lips_mean_std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e7405",
   "metadata": {
    "papermill": {
     "duration": 0.022081,
     "end_time": "2023-04-04T20:00:16.526064",
     "exception": false,
     "start_time": "2023-04-04T20:00:16.503983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Statistics - Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bedea6",
   "metadata": {
    "papermill": {
     "duration": 9.109154,
     "end_time": "2023-04-04T20:00:25.657679",
     "exception": false,
     "start_time": "2023-04-04T20:00:16.548525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Verify Normalised to Left Hand Dominant\n",
    "# P_LEFT_HAND_MEASUREMENTS = (X_train[:,:,LEFT_HAND_IDXS] != 0).sum() / X_train[:,:,LEFT_HAND_IDXS].size / P_DATA_FILLED * 1e4\n",
    "# # P_RIGHT_HAND_MEASUREMENTS = (X_train[:,:,RIGHT_HAND_IDXS] != 0).sum() / X_train[:,:,RIGHT_HAND_IDXS].size / P_DATA_FILLED * 1e4\n",
    "# print(f'P_LEFT_HAND_MEASUREMENTS: {P_LEFT_HAND_MEASUREMENTS:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d979cb",
   "metadata": {
    "papermill": {
     "duration": 10.838381,
     "end_time": "2023-04-04T20:00:36.518919",
     "exception": false,
     "start_time": "2023-04-04T20:00:25.680538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_left_right_hand_mean_std():\n",
    "    # LEFT HAND\n",
    "    LEFT_HANDS_MEAN_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "    LEFT_HANDS_MEAN_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "    LEFT_HANDS_STD_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "    LEFT_HANDS_STD_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "\n",
    "#     fig, axes = plt.subplots(3, 1, figsize=(15, N_DIMS*6))\n",
    "\n",
    "#     for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,LEFT_HAND_IDXS], [2,3,0,1]).reshape([LEFT_HAND_IDXS.size, N_DIMS, -1]) )):\n",
    "#         for dim, l in enumerate(ll):\n",
    "#             v = l[np.nonzero(l)]\n",
    "#             if dim == 0: # X\n",
    "#                 LEFT_HANDS_MEAN_X[col] = v.mean()\n",
    "#                 LEFT_HANDS_STD_X[col] = v.std()\n",
    "#             if dim == 1: # Y\n",
    "#                 LEFT_HANDS_MEAN_Y[col] = v.mean()\n",
    "#                 LEFT_HANDS_STD_Y[col] = v.std()\n",
    "#             # Plot\n",
    "#             axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "\n",
    "#     for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "#         ax.set_title(f'Hands {dim_name.upper()} Dimension', size=24)\n",
    "#         ax.tick_params(axis='x', labelsize=8)\n",
    "#         ax.grid(axis='y')\n",
    "\n",
    "#     plt.subplots_adjust(hspace=0.50)\n",
    "#     plt.show()\n",
    "\n",
    "    LEFT_HANDS_MEAN = np.array([LEFT_HANDS_MEAN_X, LEFT_HANDS_MEAN_Y]).T\n",
    "    LEFT_HANDS_STD = np.array([LEFT_HANDS_STD_X, LEFT_HANDS_STD_Y]).T\n",
    "    \n",
    "    return LEFT_HANDS_MEAN, LEFT_HANDS_STD\n",
    "\n",
    "LEFT_HANDS_MEAN, LEFT_HANDS_STD = get_left_right_hand_mean_std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfcf15",
   "metadata": {
    "papermill": {
     "duration": 0.036152,
     "end_time": "2023-04-04T20:00:36.593642",
     "exception": false,
     "start_time": "2023-04-04T20:00:36.557490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Statistics - Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87180a4",
   "metadata": {
    "papermill": {
     "duration": 2.039628,
     "end_time": "2023-04-04T20:00:38.669731",
     "exception": false,
     "start_time": "2023-04-04T20:00:36.630103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Percentage of Lips Measurements\n",
    "# P_POSE_MEASUREMENTS = (X_train[:,:,POSE_IDXS] != 0).sum() / X_train[:,:,POSE_IDXS].size / P_DATA_FILLED * 1e4\n",
    "# print(f'P_POSE_MEASUREMENTS: {P_POSE_MEASUREMENTS:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a9d8f",
   "metadata": {
    "papermill": {
     "duration": 2.786989,
     "end_time": "2023-04-04T20:00:41.481342",
     "exception": false,
     "start_time": "2023-04-04T20:00:38.694353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pose_mean_std():\n",
    "    # POSE\n",
    "    POSE_MEAN_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "    POSE_MEAN_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "    POSE_STD_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "    POSE_STD_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "\n",
    "#     fig, axes = plt.subplots(3, 1, figsize=(15, N_DIMS*6))\n",
    "\n",
    "#     for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,POSE_IDXS], [2,3,0,1]).reshape([POSE_IDXS.size, N_DIMS, -1]) )):\n",
    "#         for dim, l in enumerate(ll):\n",
    "#             v = l[np.nonzero(l)]\n",
    "#             if dim == 0: # X\n",
    "#                 POSE_MEAN_X[col] = v.mean()\n",
    "#                 POSE_STD_X[col] = v.std()\n",
    "#             if dim == 1: # Y\n",
    "#                 POSE_MEAN_Y[col] = v.mean()\n",
    "#                 POSE_STD_Y[col] = v.std()\n",
    "\n",
    "#             axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n",
    "\n",
    "#     for ax, dim_name in zip(axes, DIM_NAMES):\n",
    "#         ax.set_title(f'Pose {dim_name.upper()} Dimension', size=24)\n",
    "#         ax.tick_params(axis='x', labelsize=8)\n",
    "#         ax.grid(axis='y')\n",
    "\n",
    "#     plt.subplots_adjust(hspace=0.50)\n",
    "#     plt.show()\n",
    "\n",
    "    POSE_MEAN = np.array([POSE_MEAN_X, POSE_MEAN_Y]).T\n",
    "    POSE_STD = np.array([POSE_STD_X, POSE_STD_Y]).T\n",
    "    \n",
    "    return POSE_MEAN, POSE_STD\n",
    "\n",
    "POSE_MEAN, POSE_STD = get_pose_mean_std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ab563",
   "metadata": {
    "papermill": {
     "duration": 0.024752,
     "end_time": "2023-04-04T20:00:41.532362",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.507610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f597f94",
   "metadata": {
    "papermill": {
     "duration": 0.040175,
     "end_time": "2023-04-04T20:00:41.598627",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.558452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Custom sampler to get a batch containing N times all signs\n",
    "# def get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, n=BATCH_ALL_SIGNS_N):\n",
    "#     # Arrays to store batch in\n",
    "#     X_batch = np.zeros([NUM_CLASSES*n, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "#     y_batch = np.arange(0, NUM_CLASSES, step=1/n, dtype=np.float32).astype(np.int64)\n",
    "#     non_empty_frame_idxs_batch = np.zeros([NUM_CLASSES*n, INPUT_SIZE], dtype=np.float32)\n",
    "    \n",
    "#     # Dictionary mapping ordinally encoded sign to corresponding sample indices\n",
    "#     CLASS2IDXS = {}\n",
    "#     for i in range(NUM_CLASSES):\n",
    "#         CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n",
    "            \n",
    "#     while True:\n",
    "#         # Fill batch arrays\n",
    "#         for i in range(NUM_CLASSES):\n",
    "#             idxs = np.random.choice(CLASS2IDXS[i], n)\n",
    "#             X_batch[i*n:(i+1)*n] = X[idxs]\n",
    "#             non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n",
    "        \n",
    "#         yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681779ed-0800-4b01-afd7-0d3dc56de86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom sampler to get a batch containing N times all signs\n",
    "def get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, n=BATCH_ALL_SIGNS_N):\n",
    "    # Arrays to store batch in\n",
    "    X_batch = np.zeros([NUM_CLASSES*n, INPUT_SIZE, N_COLS * N_DIMS], dtype=np.float32)\n",
    "    y_batch = np.arange(0, NUM_CLASSES, step=1/n, dtype=np.float32).astype(np.int64)\n",
    "    non_empty_frame_idxs_batch = np.zeros([NUM_CLASSES*n, INPUT_SIZE], dtype=np.float32)\n",
    "    \n",
    "    # Dictionary mapping ordinally encoded sign to corresponding sample indices\n",
    "    CLASS2IDXS = {}\n",
    "    for i in range(NUM_CLASSES):\n",
    "        CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n",
    "            \n",
    "    while True:\n",
    "        # Fill batch arrays\n",
    "        for i in range(NUM_CLASSES):\n",
    "            idxs = np.random.choice(CLASS2IDXS[i], n)\n",
    "            X_batch[i*n:(i+1)*n] = X[idxs]\n",
    "            non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n",
    "        \n",
    "        yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbdbb25",
   "metadata": {
    "papermill": {
     "duration": 0.10295,
     "end_time": "2023-04-04T20:00:41.726022",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.623072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_dataset = get_train_batch_all_signs(X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN)\n",
    "X_batch, y_batch = next(dummy_dataset)\n",
    "\n",
    "for k, v in X_batch.items():\n",
    "    print(f'{k} shape: {v.shape}, dtype: {v.dtype}')\n",
    "\n",
    "# Batch shape/dtype\n",
    "print(f'y_batch shape: {y_batch.shape}, dtype: {y_batch.dtype}')\n",
    "# Verify each batch contains each sign exactly N times\n",
    "display(pd.Series(y_batch).value_counts().to_frame('Counts'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350e88a",
   "metadata": {
    "papermill": {
     "duration": 0.025059,
     "end_time": "2023-04-04T20:00:41.776940",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.751881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04785cfe",
   "metadata": {
    "papermill": {
     "duration": 0.038772,
     "end_time": "2023-04-04T20:00:41.841012",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.802240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "LIPS_UNITS = 384\n",
    "HANDS_UNITS = 384\n",
    "POSE_UNITS = 384\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = 512\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = 2\n",
    "MLP_RATIO = 2\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = 0.00\n",
    "MLP_DROPOUT_RATIO = 0.30\n",
    "CLASSIFIER_DROPOUT_RATIO = 0.10\n",
    "\n",
    "# Initiailizers\n",
    "INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "GELU = tf.keras.activations.gelu\n",
    "\n",
    "print(f'UNITS: {UNITS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62465dd",
   "metadata": {
    "papermill": {
     "duration": 0.031717,
     "end_time": "2023-04-04T20:00:41.897888",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.866171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer\n",
    "\n",
    "Need to implement transformer from scratch as TFLite does not support the native TF implementation of MultiHeadAttention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ecaff",
   "metadata": {
    "papermill": {
     "duration": 0.040255,
     "end_time": "2023-04-04T20:00:41.963367",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.923112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n",
    "# replaced softmax with softmax layer to support masked softmax\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    \n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_of_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self,x, attention_mask):\n",
    "        \n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](x)\n",
    "            K = self.wk[i](x)\n",
    "            V = self.wv[i](x)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn,axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        return multi_head_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b165d",
   "metadata": {
    "papermill": {
     "duration": 0.037269,
     "end_time": "2023-04-04T20:00:42.026052",
     "exception": false,
     "start_time": "2023-04-04T20:00:41.988783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(Transformer, self).__init__(name='transformer')\n",
    "        self.num_blocks = num_blocks\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.num_blocks):\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(UNITS, 8))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(UNITS * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM),\n",
    "                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(UNITS, kernel_initializer=INIT_HE_UNIFORM),\n",
    "            ]))\n",
    "        \n",
    "    def call(self, x, attention_mask):\n",
    "        # Iterate input over transformer blocks\n",
    "        for mha, mlp in zip(self.mhas, self.mlps):\n",
    "            x = x + mha(x, attention_mask)\n",
    "            x = x + mlp(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb7bff",
   "metadata": {
    "papermill": {
     "duration": 0.025478,
     "end_time": "2023-04-04T20:00:42.076750",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.051272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Landmark Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1b6d0",
   "metadata": {
    "papermill": {
     "duration": 0.037205,
     "end_time": "2023-04-04T20:00:42.139191",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.101986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandmarkEmbedding(tf.keras.Model):\n",
    "    def __init__(self, units, name):\n",
    "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Embedding for missing landmark in frame, initizlied with zeros\n",
    "        self.empty_embedding = self.add_weight(\n",
    "            name=f'{self.name}_empty_embedding',\n",
    "            shape=[self.units],\n",
    "            initializer=INIT_ZEROS,\n",
    "        )\n",
    "        # Embedding\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM),\n",
    "            tf.keras.layers.Activation(GELU),\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
    "        ], name=f'{self.name}_dense')\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "                # Checks whether landmark is missing in frame\n",
    "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
    "                # If so, the empty embedding is used\n",
    "                self.empty_embedding,\n",
    "                # Otherwise the landmark data is embedded\n",
    "                self.dense(x),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf69040",
   "metadata": {
    "papermill": {
     "duration": 0.025192,
     "end_time": "2023-04-04T20:00:42.189482",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.164290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21602749",
   "metadata": {
    "papermill": {
     "duration": 0.042481,
     "end_time": "2023-04-04T20:00:42.257778",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.215297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        \n",
    "    def get_diffs(self, l):\n",
    "        S = l.shape[2]\n",
    "        other = tf.expand_dims(l, 3)\n",
    "        other = tf.repeat(other, S, axis=3)\n",
    "        other = tf.transpose(other, [0,1,3,2])\n",
    "        diffs = tf.expand_dims(l, 3) - other\n",
    "        diffs = tf.reshape(diffs, [-1, INPUT_SIZE, S*S])\n",
    "        return diffs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Positional Embedding, initialized with zeros\n",
    "        self.positional_embedding = tf.keras.layers.Embedding(INPUT_SIZE+1, UNITS, embeddings_initializer=INIT_ZEROS)\n",
    "        # Embedding layer for Landmarks\n",
    "        self.lips_embedding = LandmarkEmbedding(LIPS_UNITS, 'lips')\n",
    "        self.left_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'left_hand')\n",
    "        self.pose_embedding = LandmarkEmbedding(POSE_UNITS, 'pose')\n",
    "        # Landmark Weights\n",
    "        self.landmark_weights = tf.Variable(tf.zeros([3], dtype=tf.float32), name='landmark_weights')\n",
    "        # Fully Connected Layers for combined landmarks\n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(UNITS, name='fully_connected_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM),\n",
    "            tf.keras.layers.Activation(GELU),\n",
    "            tf.keras.layers.Dense(UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
    "        ], name='fc')\n",
    "\n",
    "\n",
    "    def call(self, lips0, left_hand0, pose0, non_empty_frame_idxs, training=False):\n",
    "        # Lips\n",
    "        lips_embedding = self.lips_embedding(lips0)\n",
    "        # Left Hand\n",
    "        left_hand_embedding = self.left_hand_embedding(left_hand0)\n",
    "        # Pose\n",
    "        pose_embedding = self.pose_embedding(pose0)\n",
    "        # Merge Embeddings of all landmarks with mean pooling\n",
    "        x = tf.stack((\n",
    "            lips_embedding, left_hand_embedding, pose_embedding,\n",
    "        ), axis=3)\n",
    "        x = x * tf.nn.softmax(self.landmark_weights)\n",
    "        x = tf.reduce_sum(x, axis=3)\n",
    "        # Fully Connected Layers\n",
    "        x = self.fc(x)\n",
    "        # Add Positional Embedding\n",
    "        max_frame_idxs = tf.clip_by_value(\n",
    "                tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True),\n",
    "                1,\n",
    "                np.PINF,\n",
    "            )\n",
    "        normalised_non_empty_frame_idxs = tf.where(\n",
    "            tf.math.equal(non_empty_frame_idxs, -1.0),\n",
    "            INPUT_SIZE,\n",
    "            tf.cast(\n",
    "                non_empty_frame_idxs / max_frame_idxs * INPUT_SIZE,\n",
    "                tf.int32,\n",
    "            ),\n",
    "        )\n",
    "        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4799d",
   "metadata": {
    "papermill": {
     "duration": 0.025033,
     "end_time": "2023-04-04T20:00:42.307883",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.282850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12750ba",
   "metadata": {
    "papermill": {
     "duration": 0.036353,
     "end_time": "2023-04-04T20:00:42.369314",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.332961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Not used, adds random X/y translation to input on samples level\n",
    "class Augmentation(tf.keras.layers.Layer):\n",
    "    def __init__(self, noise_std):\n",
    "        super(Augmentation, self).__init__()\n",
    "        self.noise_std = noise_std\n",
    "    \n",
    "    def add_noise(self, t):\n",
    "        B = tf.shape(t)[0]\n",
    "        return tf.where(\n",
    "            t == 0.0,\n",
    "            0.0,\n",
    "            t + tf.random.normal([B,1,1,tf.shape(t)[3]], 0, self.noise_std),\n",
    "        )\n",
    "    \n",
    "    def call(self, lips0, left_hand0, pose0, training=False):\n",
    "        if training:\n",
    "            # Lips\n",
    "            lips0 = self.add_noise(lips0)\n",
    "            # Left Hand\n",
    "            left_hand0 = self.add_noise(left_hand0)\n",
    "            # Pose\n",
    "            pose0 = self.add_noise(pose0)\n",
    "        \n",
    "        return lips0, left_hand0, pose0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a138817",
   "metadata": {
    "papermill": {
     "duration": 0.025151,
     "end_time": "2023-04-04T20:00:42.419365",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.394214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sparse Categorical Crossentropy With Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f5992",
   "metadata": {
    "papermill": {
     "duration": 0.034697,
     "end_time": "2023-04-04T20:00:42.479115",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.444418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source:: https://stackoverflow.com/questions/60689185/label-smoothing-for-sparse-categorical-crossentropy\n",
    "def scce_with_ls(y_true, y_pred):\n",
    "    # One Hot Encode Sparsely Encoded Target Sign\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_true = tf.one_hot(y_true, NUM_CLASSES, axis=1)\n",
    "    y_true = tf.squeeze(y_true, axis=2)\n",
    "    # Categorical Crossentropy with native label smoothing support\n",
    "    return tf.keras.losses.categorical_crossentropy(y_true, y_pred, label_smoothing=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afcaee2",
   "metadata": {
    "papermill": {
     "duration": 0.02498,
     "end_time": "2023-04-04T20:00:42.529114",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.504134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a157f",
   "metadata": {
    "papermill": {
     "duration": 0.045221,
     "end_time": "2023-04-04T20:00:42.599226",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.554005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_model():\n",
    "#     # Inputs\n",
    "#     frames = tf.keras.layers.Input([INPUT_SIZE, N_COLS, N_DIMS], dtype=tf.float32, name='frames')\n",
    "#     non_empty_frame_idxs = tf.keras.layers.Input([INPUT_SIZE], dtype=tf.float32, name='non_empty_frame_idxs')\n",
    "#     # Padding Mask\n",
    "#     mask0 = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "#     mask0 = tf.expand_dims(mask0, axis=2)\n",
    "#     # Random Frame Masking\n",
    "#     mask = tf.where(\n",
    "#         (tf.random.uniform(tf.shape(mask0)) > 0.25) & tf.math.not_equal(mask0, 0.0),\n",
    "#         1.0,\n",
    "#         0.0,\n",
    "#     )\n",
    "#     # Correct Samples Which are all masked now...\n",
    "#     mask = tf.where(\n",
    "#         tf.math.equal(tf.reduce_sum(mask, axis=[1,2], keepdims=True), 0.0),\n",
    "#         mask0,\n",
    "#         mask,\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     \"\"\"\n",
    "#         left_hand: 468:489\n",
    "#         pose: 489:522\n",
    "#         right_hand: 522:543\n",
    "#     \"\"\"\n",
    "#     x = frames\n",
    "#     x = tf.slice(x, [0,0,0,0], [-1,INPUT_SIZE, N_COLS, 2])\n",
    "#     # LIPS\n",
    "#     lips = tf.slice(x, [0,0,LIPS_START,0], [-1,INPUT_SIZE, 40, 2])\n",
    "#     lips = tf.where(\n",
    "#             tf.math.equal(lips, 0.0),\n",
    "#             0.0,\n",
    "#             (lips - LIPS_MEAN) / LIPS_STD,\n",
    "#         )\n",
    "#     # LEFT HAND\n",
    "#     left_hand = tf.slice(x, [0,0,40,0], [-1,INPUT_SIZE, 21, 2])\n",
    "#     left_hand = tf.where(\n",
    "#             tf.math.equal(left_hand, 0.0),\n",
    "#             0.0,\n",
    "#             (left_hand - LEFT_HANDS_MEAN) / LEFT_HANDS_STD,\n",
    "#         )\n",
    "#     # POSE\n",
    "#     pose = tf.slice(x, [0,0,61,0], [-1,INPUT_SIZE, 5, 2])\n",
    "#     pose = tf.where(\n",
    "#             tf.math.equal(pose, 0.0),\n",
    "#             0.0,\n",
    "#             (pose - POSE_MEAN) / POSE_STD,\n",
    "#         )\n",
    "    \n",
    "#     # Flatten\n",
    "#     lips = tf.reshape(lips, [-1, INPUT_SIZE, 40*2])\n",
    "#     left_hand = tf.reshape(left_hand, [-1, INPUT_SIZE, 21*2])\n",
    "#     pose = tf.reshape(pose, [-1, INPUT_SIZE, 5*2])\n",
    "        \n",
    "#     # Embedding\n",
    "#     x = Embedding()(lips, left_hand, pose, non_empty_frame_idxs)\n",
    "    \n",
    "#     # Encoder Transformer Blocks\n",
    "#     x = Transformer(NUM_BLOCKS)(x, mask)\n",
    "    \n",
    "#     # Pooling\n",
    "#     x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "#     # Classifier Dropout\n",
    "#     x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "#     # Classification Layer\n",
    "#     x = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "#     outputs = x\n",
    "    \n",
    "#     # Create Tensorflow Model\n",
    "#     model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "#     # Sparse Categorical Cross Entropy With Label Smoothing\n",
    "#     loss = scce_with_ls\n",
    "    \n",
    "#     # Adam Optimizer with weight decay\n",
    "#     optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5, clipnorm=1.0)\n",
    "    \n",
    "#     # TopK Metrics\n",
    "#     metrics = [\n",
    "#         tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "#         tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "#         tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "#     ]\n",
    "    \n",
    "#     model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27156593-5c1a-407e-b96b-1fd56e6940db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # 38, 454,\n",
    "    # INPUT_SIZE, N_COLS, N_DIMS\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([INPUT_SIZE, N_COLS * N_DIMS], dtype=tf.float32, name='frames')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([INPUT_SIZE], dtype=tf.float32, name='non_empty_frame_idxs')\n",
    "    # Padding Mask\n",
    "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=2)\n",
    "    \n",
    "    \"\"\"\n",
    "        left_hand: 468:489\n",
    "        pose: 489:522\n",
    "        right_hand: 522:543\n",
    "    \"\"\"\n",
    "    x = frames\n",
    "    \n",
    "    x = tf.slice(x, [0,0,0], [-1,INPUT_SIZE, N_COLS * 2])\n",
    "    # LIPS\n",
    "    lips = tf.slice(frames, [0, 0, LIPS_START], [-1, INPUT_SIZE, LIPS_IDXS.size * 2])\n",
    "    lips = tf.where(\n",
    "            tf.math.equal(lips, 0.0),\n",
    "            0.0,\n",
    "            (lips - LIPS_MEAN) / LIPS_STD,\n",
    "        )\n",
    "    # LEFT HAND\n",
    "    left_hand = tf.slice(frames, [0, 0, LEFT_HAND_START * 2], [-1, INPUT_SIZE, LEFT_HAND_IDXS.size * 2])\n",
    "    left_hand = tf.where(\n",
    "            tf.math.equal(left_hand, 0.0),\n",
    "            0.0,\n",
    "            (left_hand - LEFT_HANDS_MEAN) / LEFT_HANDS_STD,\n",
    "        )\n",
    "    # RIGHT HAND\n",
    "    right_hand = tf.slice(frames, [0, 0, RIGHT_HAND_START * 2], [-1, INPUT_SIZE, RIGHT_HAND_IDXS.size * 2])\n",
    "    right_hand = tf.where(\n",
    "            tf.math.equal(right_hand, 0.0),\n",
    "            0.0,\n",
    "            (right_hand - RIGHT_HANDS_MEAN) / RIGHT_HANDS_STD,\n",
    "        )\n",
    "    # POSE\n",
    "    pose = tf.slice(frames, [0, 0, POSE_START * 2], [-1, INPUT_SIZE, POSE_IDXS.size * 2])\n",
    "    pose = tf.where(\n",
    "            tf.math.equal(pose, 0.0),\n",
    "            0.0,\n",
    "            (pose - POSE_MEAN) / POSE_STD,\n",
    "        )\n",
    "    \n",
    "    x = lips, left_hand, right_hand, pose\n",
    "        \n",
    "    x = Embedding()(lips, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
    "    \n",
    "    # Encoder Transformer Blocks\n",
    "    x = Transformer(NUM_BLOCKS)(x, mask)\n",
    "    \n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classifier Dropout\n",
    "    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Simple Categorical Crossentropy Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5, clipnorm=1.0)\n",
    "    \n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad51e9e",
   "metadata": {
    "papermill": {
     "duration": 2.061227,
     "end_time": "2023-04-04T20:00:44.685608",
     "exception": false,
     "start_time": "2023-04-04T20:00:42.624381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc214c",
   "metadata": {
    "papermill": {
     "duration": 0.391521,
     "end_time": "2023-04-04T20:00:45.103309",
     "exception": false,
     "start_time": "2023-04-04T20:00:44.711788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot model summary\n",
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09b5d1",
   "metadata": {
    "papermill": {
     "duration": 1.257698,
     "end_time": "2023-04-04T20:00:46.412443",
     "exception": false,
     "start_time": "2023-04-04T20:00:45.154745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fa558",
   "metadata": {
    "papermill": {
     "duration": 0.041812,
     "end_time": "2023-04-04T20:00:46.497777",
     "exception": false,
     "start_time": "2023-04-04T20:00:46.455965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# No NaN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b57bc",
   "metadata": {
    "papermill": {
     "duration": 3.489254,
     "end_time": "2023-04-04T20:00:50.027621",
     "exception": false,
     "start_time": "2023-04-04T20:00:46.538367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not PREPROCESS_DATA and TRAIN_MODEL:\n",
    "    y_pred = model.predict_on_batch(X_batch).flatten()\n",
    "\n",
    "    print(f'# NaN Values In Prediction: {np.isnan(y_pred).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14215d69",
   "metadata": {
    "papermill": {
     "duration": 0.044122,
     "end_time": "2023-04-04T20:00:50.113772",
     "exception": false,
     "start_time": "2023-04-04T20:00:50.069650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c787e",
   "metadata": {
    "papermill": {
     "duration": 0.584733,
     "end_time": "2023-04-04T20:00:50.739650",
     "exception": false,
     "start_time": "2023-04-04T20:00:50.154917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not PREPROCESS_DATA and TRAIN_MODEL:\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.title(f'Softmax Output Initialized Model | µ={y_pred.mean():.3f}, σ={y_pred.std():.3f}', pad=25)\n",
    "    pd.Series(y_pred).plot(kind='hist', bins=128, label='Class Probability')\n",
    "    plt.xlim(0, max(y_pred) * 1.1)\n",
    "    plt.vlines([1 / NUM_CLASSES], 0, plt.ylim()[1], color='red', label=f'Random Guessing Baseline 1/NUM_CLASSES={1 / NUM_CLASSES:.3f}')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580925e",
   "metadata": {
    "papermill": {
     "duration": 0.041884,
     "end_time": "2023-04-04T20:00:50.823747",
     "exception": false,
     "start_time": "2023-04-04T20:00:50.781863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ac7d5",
   "metadata": {
    "papermill": {
     "duration": 0.054396,
     "end_time": "2023-04-04T20:00:50.919670",
     "exception": false,
     "start_time": "2023-04-04T20:00:50.865274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        if WARMUP_METHOD == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7bebe",
   "metadata": {
    "papermill": {
     "duration": 0.751586,
     "end_time": "2023-04-04T20:00:51.712347",
     "exception": false,
     "start_time": "2023-04-04T20:00:50.960761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lr_schedule(lr_schedule, epochs):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot([None] + lr_schedule + [None])\n",
    "    # X Labels\n",
    "    x = np.arange(1, epochs + 1)\n",
    "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
    "    plt.xlim([1, epochs])\n",
    "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
    "    \n",
    "    # Increase y-limit for better readability\n",
    "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
    "    \n",
    "    # Title\n",
    "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
    "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
    "    \n",
    "    # Plot Learning Rates\n",
    "    for x, val in enumerate(lr_schedule):\n",
    "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
    "            if x < len(lr_schedule) - 1:\n",
    "                if lr_schedule[x - 1] < val:\n",
    "                    ha = 'right'\n",
    "                else:\n",
    "                    ha = 'left'\n",
    "            elif x == 0:\n",
    "                ha = 'right'\n",
    "            else:\n",
    "                ha = 'left'\n",
    "            plt.plot(x + 1, val, 'o', color='black');\n",
    "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
    "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
    "    \n",
    "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
    "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n",
    "# Plot Learning Rate Schedule\n",
    "plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0aba6f",
   "metadata": {
    "papermill": {
     "duration": 0.046237,
     "end_time": "2023-04-04T20:00:51.804197",
     "exception": false,
     "start_time": "2023-04-04T20:00:51.757960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Decay Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f10e1",
   "metadata": {
    "papermill": {
     "duration": 0.053303,
     "end_time": "2023-04-04T20:00:51.900248",
     "exception": false,
     "start_time": "2023-04-04T20:00:51.846945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom callback to update weight decay with learning rate\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, wd_ratio=WD_RATIO):\n",
    "        self.step_counter = 0\n",
    "        self.wd_ratio = wd_ratio\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
    "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440a7c2",
   "metadata": {
    "papermill": {
     "duration": 0.042772,
     "end_time": "2023-04-04T20:00:51.986505",
     "exception": false,
     "start_time": "2023-04-04T20:00:51.943733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f13ab",
   "metadata": {
    "papermill": {
     "duration": 12.184084,
     "end_time": "2023-04-04T20:01:04.213748",
     "exception": false,
     "start_time": "2023-04-04T20:00:52.029664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "if TRAIN_MODEL:\n",
    "    # Verify model prediction is <<<100ms\n",
    "    model.predict_on_batch({ 'frames': X_train[:1], 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_TRAIN[:1] })\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5669cbf",
   "metadata": {
    "papermill": {
     "duration": 0.050333,
     "end_time": "2023-04-04T20:01:04.316960",
     "exception": false,
     "start_time": "2023-04-04T20:01:04.266627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb31e39",
   "metadata": {
    "papermill": {
     "duration": 0.052411,
     "end_time": "2023-04-04T20:01:04.414097",
     "exception": false,
     "start_time": "2023-04-04T20:01:04.361686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    # Verify Validation Dataset Covers All Signs\n",
    "    print(f'# Unique Signs in Validation Set: {pd.Series(y_val).nunique()}')\n",
    "    # Value Counts\n",
    "    display(pd.Series(y_val).value_counts().to_frame('Count').iloc[[1,2,3,-3,-2,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fb45a",
   "metadata": {
    "papermill": {
     "duration": 0.043286,
     "end_time": "2023-04-04T20:01:04.500365",
     "exception": false,
     "start_time": "2023-04-04T20:01:04.457079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate Initialized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a338966",
   "metadata": {
    "papermill": {
     "duration": 0.050905,
     "end_time": "2023-04-04T20:01:04.594278",
     "exception": false,
     "start_time": "2023-04-04T20:01:04.543373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "if TRAIN_MODEL and USE_VAL:\n",
    "    _ = model.evaluate(*validation_data, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707b2fa",
   "metadata": {
    "papermill": {
     "duration": 0.042473,
     "end_time": "2023-04-04T20:01:04.679588",
     "exception": false,
     "start_time": "2023-04-04T20:01:04.637115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6eb322",
   "metadata": {
    "papermill": {
     "duration": 5136.224818,
     "end_time": "2023-04-04T21:26:40.947162",
     "exception": false,
     "start_time": "2023-04-04T20:01:04.722344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    # Clear all models in GPU\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Get new fresh model\n",
    "    model = get_model()\n",
    "    \n",
    "    # Sanity Check\n",
    "    model.summary()\n",
    "\n",
    "    # Actual Training\n",
    "    history = model.fit(\n",
    "            x=get_train_batch_all_signs(X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN),\n",
    "            steps_per_epoch=len(X_train) // (NUM_CLASSES * BATCH_ALL_SIGNS_N),\n",
    "            epochs=N_EPOCHS,\n",
    "            # Only used for validation data since training data is a generator\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=validation_data,\n",
    "            callbacks=[\n",
    "                lr_callback,\n",
    "                WeightDecayCallback(),\n",
    "            ],\n",
    "            verbose = VERBOSE,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2367e3",
   "metadata": {
    "papermill": {
     "duration": 0.256919,
     "end_time": "2023-04-04T21:26:41.270995",
     "exception": false,
     "start_time": "2023-04-04T21:26:41.014076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Model Weights\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fb9d2",
   "metadata": {
    "papermill": {
     "duration": 0.078227,
     "end_time": "2023-04-04T21:26:41.415620",
     "exception": false,
     "start_time": "2023-04-04T21:26:41.337393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    # Validation Predictions\n",
    "    y_val_pred = model.predict({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, verbose=2).argmax(axis=1)\n",
    "    # Label\n",
    "    labels = [ORD2SIGN.get(i).replace(' ', '_') for i in range(NUM_CLASSES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96f9e9",
   "metadata": {
    "papermill": {
     "duration": 0.065587,
     "end_time": "2023-04-04T21:26:41.546702",
     "exception": false,
     "start_time": "2023-04-04T21:26:41.481115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Landmark Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3324c0",
   "metadata": {
    "papermill": {
     "duration": 0.10684,
     "end_time": "2023-04-04T21:26:41.721056",
     "exception": false,
     "start_time": "2023-04-04T21:26:41.614216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Landmark Weights\n",
    "for w in model.get_layer('embedding').weights:\n",
    "    if 'landmark_weights' in w.name:\n",
    "        weights = scipy.special.softmax(w)\n",
    "\n",
    "landmarks = ['lips_embedding', 'left_hand_embedding', 'pose_embedding']\n",
    "\n",
    "for w, lm in zip(weights, landmarks):\n",
    "    print(f'{lm} weight: {(w*100):.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e32c39",
   "metadata": {
    "papermill": {
     "duration": 0.068274,
     "end_time": "2023-04-04T21:26:41.855273",
     "exception": false,
     "start_time": "2023-04-04T21:26:41.786999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c57a16",
   "metadata": {
    "papermill": {
     "duration": 0.083212,
     "end_time": "2023-04-04T21:26:42.005948",
     "exception": false,
     "start_time": "2023-04-04T21:26:41.922736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_classification_report():\n",
    "    # Classification report for all signs\n",
    "    classification_report = sklearn.metrics.classification_report(\n",
    "            y_val,\n",
    "            y_val_pred,\n",
    "            target_names=labels,\n",
    "            output_dict=True,\n",
    "        )\n",
    "    # Round Data for better readability\n",
    "    classification_report = pd.DataFrame(classification_report).T\n",
    "    classification_report = classification_report.round(2)\n",
    "    classification_report = classification_report.astype({\n",
    "            'support': np.uint16,\n",
    "        })\n",
    "    # Add signs\n",
    "    classification_report['sign'] = [e if e in SIGN2ORD else -1 for e in classification_report.index]\n",
    "    classification_report['sign_ord'] = classification_report['sign'].apply(SIGN2ORD.get).fillna(-1).astype(np.int16)\n",
    "    # Sort on F1-score\n",
    "    classification_report = pd.concat((\n",
    "        classification_report.head(NUM_CLASSES).sort_values('f1-score', ascending=False),\n",
    "        classification_report.tail(3),\n",
    "    ))\n",
    "\n",
    "    pd.options.display.max_rows = 999\n",
    "    display(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0b01a",
   "metadata": {
    "papermill": {
     "duration": 0.075501,
     "end_time": "2023-04-04T21:26:42.187445",
     "exception": false,
     "start_time": "2023-04-04T21:26:42.111944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f63cd",
   "metadata": {
    "papermill": {
     "duration": 0.065383,
     "end_time": "2023-04-04T21:26:42.318679",
     "exception": false,
     "start_time": "2023-04-04T21:26:42.253296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b4c26",
   "metadata": {
    "papermill": {
     "duration": 0.082741,
     "end_time": "2023-04-04T21:26:42.468623",
     "exception": false,
     "start_time": "2023-04-04T21:26:42.385882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history_metric(metric, f_best=np.argmax, ylim=None, yscale=None, yticks=None):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    values = history.history[metric]\n",
    "    N_EPOCHS = len(values)\n",
    "    val = 'val' in ''.join(history.history.keys())\n",
    "    # Epoch Ticks\n",
    "    if N_EPOCHS <= 20:\n",
    "        x = np.arange(1, N_EPOCHS + 1)\n",
    "    else:\n",
    "        x = [1, 5] + [10 + 5 * idx for idx in range((N_EPOCHS - 10) // 5 + 1)]\n",
    "\n",
    "    x_ticks = np.arange(1, N_EPOCHS+1)\n",
    "\n",
    "    # Validation\n",
    "    if val:\n",
    "        val_values = history.history[f'val_{metric}']\n",
    "        val_argmin = f_best(val_values)\n",
    "        plt.plot(x_ticks, val_values, label=f'val')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(x_ticks, values, label=f'train')\n",
    "    argmin = f_best(values)\n",
    "    plt.scatter(argmin + 1, values[argmin], color='red', s=75, marker='o', label=f'train_best')\n",
    "    if val:\n",
    "        plt.scatter(val_argmin + 1, val_values[val_argmin], color='purple', s=75, marker='o', label=f'val_best')\n",
    "\n",
    "    plt.title(f'Model {metric}', fontsize=24, pad=10)\n",
    "    plt.ylabel(metric, fontsize=20, labelpad=10)\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    if yscale is not None:\n",
    "        plt.yscale(yscale)\n",
    "        \n",
    "    if yticks is not None:\n",
    "        plt.yticks(yticks, fontsize=16)\n",
    "\n",
    "    plt.xlabel('epoch', fontsize=20, labelpad=10)        \n",
    "    plt.tick_params(axis='x', labelsize=8)\n",
    "    plt.xticks(x, fontsize=16) # set tick step to 1 and let x axis start at 1\n",
    "    plt.yticks(fontsize=16)\n",
    "    \n",
    "    plt.legend(prop={'size': 10})\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fcda6",
   "metadata": {
    "papermill": {
     "duration": 0.458551,
     "end_time": "2023-04-04T21:26:42.992926",
     "exception": false,
     "start_time": "2023-04-04T21:26:42.534375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    plot_history_metric('loss', f_best=np.argmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4eaf01",
   "metadata": {
    "papermill": {
     "duration": 0.453593,
     "end_time": "2023-04-04T21:26:43.516256",
     "exception": false,
     "start_time": "2023-04-04T21:26:43.062663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    plot_history_metric('acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee76d2",
   "metadata": {
    "papermill": {
     "duration": 0.456719,
     "end_time": "2023-04-04T21:26:44.042121",
     "exception": false,
     "start_time": "2023-04-04T21:26:43.585402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    plot_history_metric('top_5_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af803566",
   "metadata": {
    "papermill": {
     "duration": 0.455061,
     "end_time": "2023-04-04T21:26:44.570622",
     "exception": false,
     "start_time": "2023-04-04T21:26:44.115561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    plot_history_metric('top_10_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b92fa",
   "metadata": {
    "papermill": {
     "duration": 0.068944,
     "end_time": "2023-04-04T21:26:44.720540",
     "exception": false,
     "start_time": "2023-04-04T21:26:44.651596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Submission code loosley based on [this notebook](https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline#baseline) by [Darien Schettler\n",
    "](https://www.kaggle.com/dschettler8845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf922f7",
   "metadata": {
    "papermill": {
     "duration": 2.363022,
     "end_time": "2023-04-04T21:26:47.152715",
     "exception": false,
     "start_time": "2023-04-04T21:26:44.789693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TFLite model for submission\n",
    "class TFLiteModel(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.preprocess_layer = preprocess_layer\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, N_ROWS, N_DIMS], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        # Preprocess Data\n",
    "        x, non_empty_frame_idxs = self.preprocess_layer(inputs)\n",
    "        # Add Batch Dimension\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
    "        # Make Prediction\n",
    "        outputs = self.model({ 'frames': x, 'non_empty_frame_idxs': non_empty_frame_idxs })\n",
    "        # Squeeze Output 1x250 -> 250\n",
    "        outputs = tf.squeeze(outputs, axis=0)\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "# Define TF Lite Model\n",
    "tflite_keras_model = TFLiteModel(model)\n",
    "\n",
    "# Sanity Check\n",
    "demo_raw_data = load_relevant_data_subset(train['file_path'].values[5])\n",
    "print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n",
    "demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n",
    "print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n",
    "demo_prediction = demo_output.numpy().argmax()\n",
    "print(f'demo_prediction: {demo_prediction}, correct: {train.iloc[0][\"sign_ord\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c4074",
   "metadata": {
    "papermill": {
     "duration": 40.914365,
     "end_time": "2023-04-04T21:27:28.136402",
     "exception": false,
     "start_time": "2023-04-04T21:26:47.222037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Model Converter\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "# Convert Model\n",
    "tflite_model = keras_model_converter.convert()\n",
    "# Write Model\n",
    "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "# Zip Model\n",
    "!zip submission.zip /kaggle/working/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7d98e",
   "metadata": {
    "papermill": {
     "duration": 10.810307,
     "end_time": "2023-04-04T21:27:39.067261",
     "exception": false,
     "start_time": "2023-04-04T21:27:28.256954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify TFLite model can be loaded and used for prediction\n",
    "!pip install tflite-runtime\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(\"/kaggle/working/model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=demo_raw_data)\n",
    "sign = output['outputs'].argmax()\n",
    "\n",
    "print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')\n",
    "print(\"TRUE : \", train.sign.values[0], f'[{train.sign_ord.values[0]}]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5368.840469,
   "end_time": "2023-04-04T21:27:42.124817",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-04T19:58:13.284348",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "081199ad839b443fab1183d0e8fe6889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ff866a5adf64b17adaf1a4b61e22f1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cbd6691085ec4afdad0ee0291c9a51c2",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_731307049ef14eddb229465fd860c192",
       "value": 1000
      }
     },
     "2158130593a24b85b0e5e98b084b922e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c2992f04f48a4e88ac9e6f6a3ccd0265",
       "max": 64,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7818bae5c7f040c283551ea4fd4c8c6c",
       "value": 64
      }
     },
     "29383e1f7a3e4a66bcf94f0b1425765e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d2864763f8b4dd9a87ed995f2f8eb02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2e2e17311ba74778b3b1ffbe32711074": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "33c6a8d3d86149d9b49c7987ecba954f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35c03e93d5b741caabd7cea5b6eaf03c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_29383e1f7a3e4a66bcf94f0b1425765e",
       "placeholder": "​",
       "style": "IPY_MODEL_9d3f5f3626df453f8409ca52860284f8",
       "value": " 5/5 [00:01&lt;00:00,  3.40it/s]"
      }
     },
     "3cd8df49be7e42eb8c66890d684bf12a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3eb18d1192834535a28caff69e9df0ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "42520414e18a49088fc62f3f060025fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bf207ac24e8b4f14acbce77affe1b863",
       "placeholder": "​",
       "style": "IPY_MODEL_a7a2738387544930be82f50cae549250",
       "value": "100%"
      }
     },
     "433529fe3c334a0ca3287929b8f3ed03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc2f520172f544fe81aa29439f7aac4e",
       "max": 40,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ace5802e4d4045bab6968a87a4c29309",
       "value": 40
      }
     },
     "52b3a6479cfc4bfa957d3b0a53160ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8fdd24718b2b4ef5a593212294987721",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83bf24eb706c4aeca58146720c3a5276",
       "value": 5
      }
     },
     "5458125a9ac84e6f97a9c22eb99af538": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5854101cdb30493e9d3b417fa46bc481": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ec4f8351787f4e0f9b2cd9842e6bb04c",
       "placeholder": "​",
       "style": "IPY_MODEL_3eb18d1192834535a28caff69e9df0ec",
       "value": "100%"
      }
     },
     "59a1a4c0f0e5469592d3b1f5cfa19dfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59af1e1d8e4345a995fdbac316429743": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a2c410c02854a1bbea50b61e7b42e02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebe9dd71b7d24aa49845554b0a82e06e",
       "placeholder": "​",
       "style": "IPY_MODEL_eb0a38c392074d008df7d725a2320143",
       "value": "100%"
      }
     },
     "5b1ace1db41e483e86a5610cacab14f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5a2c410c02854a1bbea50b61e7b42e02",
        "IPY_MODEL_0ff866a5adf64b17adaf1a4b61e22f1c",
        "IPY_MODEL_69193533fe634e459a4078017ed87a2e"
       ],
       "layout": "IPY_MODEL_59a1a4c0f0e5469592d3b1f5cfa19dfd"
      }
     },
     "63f9545aff3b4d64b66c19038b3f749a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5854101cdb30493e9d3b417fa46bc481",
        "IPY_MODEL_433529fe3c334a0ca3287929b8f3ed03",
        "IPY_MODEL_ef03db7a6a4e4c98ba693c66c30d8c31"
       ],
       "layout": "IPY_MODEL_c92fe7b2491843f2b20d771955f144dc"
      }
     },
     "69193533fe634e459a4078017ed87a2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f53c81681a64480bac390de276948dc4",
       "placeholder": "​",
       "style": "IPY_MODEL_724871f7d7074c12a14b05144cdc7445",
       "value": " 1000/1000 [00:22&lt;00:00, 44.82it/s]"
      }
     },
     "6b3ec5debdf94d95bf3ff99ecb932555": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_33c6a8d3d86149d9b49c7987ecba954f",
       "placeholder": "​",
       "style": "IPY_MODEL_5458125a9ac84e6f97a9c22eb99af538",
       "value": "100%"
      }
     },
     "6cbf0afbb7c644a79e11f2d06a4966ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "724871f7d7074c12a14b05144cdc7445": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "731307049ef14eddb229465fd860c192": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7818bae5c7f040c283551ea4fd4c8c6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "78a822b098334dbfb43fe9a432e4769e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f3afa526b0343bb83bb6051d52e270e",
       "placeholder": "​",
       "style": "IPY_MODEL_e11359e5cb034cf683bfa757d5e54b06",
       "value": "100%"
      }
     },
     "7f3afa526b0343bb83bb6051d52e270e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83bf24eb706c4aeca58146720c3a5276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8fdd24718b2b4ef5a593212294987721": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93c32ff502a7411c8e003e3cc805b3c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b3ec5debdf94d95bf3ff99ecb932555",
        "IPY_MODEL_2158130593a24b85b0e5e98b084b922e",
        "IPY_MODEL_cb40300f1b184d058c0c2ae2992a1383"
       ],
       "layout": "IPY_MODEL_59af1e1d8e4345a995fdbac316429743"
      }
     },
     "9b4d4bc12550400ca993cfed3b533ac0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f67d34d2a5b8495485c1aeed00c8418f",
       "max": 21,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fb58db1143a44f1da7cc5064ca6eceb5",
       "value": 21
      }
     },
     "9d3f5f3626df453f8409ca52860284f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a16a553681f74f64989d25238faf72e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_78a822b098334dbfb43fe9a432e4769e",
        "IPY_MODEL_52b3a6479cfc4bfa957d3b0a53160ed7",
        "IPY_MODEL_35c03e93d5b741caabd7cea5b6eaf03c"
       ],
       "layout": "IPY_MODEL_3cd8df49be7e42eb8c66890d684bf12a"
      }
     },
     "a317b1e0a7dc46debc9ceff622989055": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a7a2738387544930be82f50cae549250": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ace5802e4d4045bab6968a87a4c29309": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b0b7203a9da5450baa99708bdb2f7fa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6cbf0afbb7c644a79e11f2d06a4966ce",
       "placeholder": "​",
       "style": "IPY_MODEL_2e2e17311ba74778b3b1ffbe32711074",
       "value": " 21/21 [00:06&lt;00:00,  3.42it/s]"
      }
     },
     "bf207ac24e8b4f14acbce77affe1b863": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0f7edf62bda49abb70aaca9b7f6cd01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2992f04f48a4e88ac9e6f6a3ccd0265": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c81bf1409dde4c148cf5b3fe01cba914": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c92fe7b2491843f2b20d771955f144dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb40300f1b184d058c0c2ae2992a1383": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c0f7edf62bda49abb70aaca9b7f6cd01",
       "placeholder": "​",
       "style": "IPY_MODEL_a317b1e0a7dc46debc9ceff622989055",
       "value": " 64/64 [00:12&lt;00:00,  5.07it/s]"
      }
     },
     "cbd6691085ec4afdad0ee0291c9a51c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc2f520172f544fe81aa29439f7aac4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d07689ecd2d34d63a198d190f2ec32c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_42520414e18a49088fc62f3f060025fb",
        "IPY_MODEL_9b4d4bc12550400ca993cfed3b533ac0",
        "IPY_MODEL_b0b7203a9da5450baa99708bdb2f7fa0"
       ],
       "layout": "IPY_MODEL_c81bf1409dde4c148cf5b3fe01cba914"
      }
     },
     "e11359e5cb034cf683bfa757d5e54b06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eb0a38c392074d008df7d725a2320143": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ebe9dd71b7d24aa49845554b0a82e06e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec4f8351787f4e0f9b2cd9842e6bb04c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef03db7a6a4e4c98ba693c66c30d8c31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_081199ad839b443fab1183d0e8fe6889",
       "placeholder": "​",
       "style": "IPY_MODEL_2d2864763f8b4dd9a87ed995f2f8eb02",
       "value": " 40/40 [00:11&lt;00:00,  3.86it/s]"
      }
     },
     "f53c81681a64480bac390de276948dc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f67d34d2a5b8495485c1aeed00c8418f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb58db1143a44f1da7cc5064ca6eceb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

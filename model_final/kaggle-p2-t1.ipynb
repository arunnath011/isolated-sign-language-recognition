{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363732af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow_addons\n",
    "!pip install -q pyarrow\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66841318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 00:41:09.850012: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 00:41:10.477076: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import io\n",
    "import json\n",
    "\n",
    "import wandb\n",
    "\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd110003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeanna-emery\u001b[0m (\u001b[33mw251-asl-fp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Setup Weights and Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1306e",
   "metadata": {
    "papermill": {
     "duration": 0.014594,
     "end_time": "2023-03-27T13:49:16.606639",
     "exception": false,
     "start_time": "2023-03-27T13:49:16.592045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0888b5b-c39b-48bb-aa59-b19410aa21cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \n",
    "    \"TRANSFORMER\" : 'V1',\n",
    "    \"PREPROCESS\" : 'V2',\n",
    "    \"N_COLS0\": 543,\n",
    "    \"N_COLS\": 227,\n",
    "    \"N_ROWS\":543,\n",
    "    \"N_DIMS\": 2, \n",
    "    \"N_EPOCHS\": 100,\n",
    "    \"TRAIN_BATCH_SIZE\": 512, #128,\n",
    "    \"INPUT_SIZE\":38,\n",
    "    \"NUM_CLASSES\": 250,\n",
    "    \"VAL_BATCH_SIZE\": 512, #128,\n",
    "    \"WD_RATIO\":0.05,\n",
    "    \"LEARNING_RATE\": 0.0001, #0.00001,\n",
    "    \"WEIGHT_DECAY\": 0.0001, #0.00001,\n",
    "    \"N_WARMUP_EPOCHS\": 2,\n",
    "    'LAYER_NORM_EPS' : 1e-6,\n",
    "    'LANDMARK_UNITS' : 384,\n",
    "    'TOTAL_UNITS' : 512,\n",
    "    'NUM_BLOCKS' : 2,\n",
    "    'MLP_RATIO' : 2,\n",
    "    'NUM_HEADS' : 4,\n",
    "    'EMBEDDING_DROPOUT' : 0.00,\n",
    "    'MLP_DROPOUT_RATIO' : 0.10,\n",
    "    'CLASSIFIER_DROPOUT_RATIO' : 0.10\n",
    "}\n",
    "\n",
    "USE_VAL = True\n",
    "VERBOSE = True\n",
    "\n",
    "DIM_NAMES = ['x', 'y']\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = config['LAYER_NORM_EPS']\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "FACE_UNITS = config['LANDMARK_UNITS']\n",
    "HANDS_UNITS = config['LANDMARK_UNITS']\n",
    "POSE_UNITS = config['LANDMARK_UNITS']\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = config['TOTAL_UNITS']\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = config['NUM_BLOCKS']\n",
    "MLP_RATIO = config['MLP_RATIO']\n",
    "NUM_HEADS = config['NUM_HEADS']\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = config['EMBEDDING_DROPOUT']\n",
    "MLP_DROPOUT_RATIO = config['MLP_DROPOUT_RATIO']\n",
    "CLASSIFIER_DROPOUT_RATIO = config['CLASSIFIER_DROPOUT_RATIO']\n",
    "\n",
    "ROWS_PER_FRAME = config['N_ROWS']  # number of landmarks per frame\n",
    "\n",
    "# Initiailizers\n",
    "# INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "# INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "ACTIVATION = tf.keras.activations.gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15ec671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOG_DIR = './logs/fit'\n",
    "# wandb.tensorboard.patch(root_logdir= LOG_DIR)\n",
    "# wandb.init(project='w251-GISLR-Final', \n",
    "#            config=config,\n",
    "#           sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f088e7-d2e5-43e0-a697-6ab2c5c030b9",
   "metadata": {},
   "source": [
    "### Util functions for reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f840f81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "#w251-asl-data/raw-data/train_landmark_files/28656/3311214787.parquet\n",
    "\n",
    "# def load_relevant_data_subset(pq_path):\n",
    "#     data_columns = ['x', 'y']\n",
    "#     data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "#     n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "#     data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "#     return data.astype(np.float32)\n",
    "\n",
    "# Read single parquet file from S3\n",
    "def pd_read_s3_parquet(key, bucket, s3_client=None, **args):\n",
    "    if s3_client is None:\n",
    "        s3_client = boto3.client('s3')\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    return pd.read_parquet(io.BytesIO(obj['Body'].read()), **args)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y']\n",
    "    data = pd_read_s3_parquet(pq_path[14:], AWS_S3_BUCKET, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc095c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prints Shape and Dtype For List Of Variables\n",
    "def print_shape_dtype(l, names):\n",
    "    for e, n in zip(l, names):\n",
    "        print(f'{n} shape: {e.shape}, dtype: {e.dtype}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d982f07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 100\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv('../resources/train.csv')\n",
    "\n",
    "train_metadata = train_metadata.head(100)\n",
    "\n",
    "N_SAMPLES = len(train_metadata)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b8b57f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get complete file path to file\n",
    "# def get_file_path(path):\n",
    "#     return f'/kaggle/input/asl-signs/{path}'\n",
    "\n",
    "# train_metadata['file_path'] = train_metadata['path'].apply(get_file_path)\n",
    "import boto3\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    \"s3\"\n",
    ")\n",
    "\n",
    "AWS_S3_BUCKET = \"w251-asl-data\"\n",
    "TRAIN_CSV_FILE = \"raw-data/train.csv\"\n",
    "\n",
    "\n",
    "# Get complete file path to file\n",
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'{AWS_S3_BUCKET}/raw-data/{path}'\n",
    "\n",
    "train_metadata['file_path'] = train_metadata['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2926ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train_metadata['sign_ord'] = train_metadata['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train_metadata[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train_metadata[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d55e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreprocessLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, INPUT_SIZE):\n",
    "        super(PreprocessLayer, self).__init__()\n",
    "        self.INPUT_SIZE = INPUT_SIZE\n",
    "        # Indicies in original data. \n",
    "        self.FACE_IDXS = tf.constant([0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467], dtype=tf.int32)\n",
    "        self.POSE_IDXS = tf.constant(tf.range(489, 514, delta=1, dtype=tf.int32))\n",
    "        self.LEFT_HAND_IDXS = tf.constant(tf.range(468, 489, delta=1, dtype=tf.int32))\n",
    "        self.RIGHT_HAND_IDXS = tf.constant(tf.range(522, 543, delta=1, dtype=tf.int32))\n",
    "        \n",
    "        self.HAND_IDXS = tf.constant(tf.concat([self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "            \n",
    "        # All landmarks that are used for modeling. \n",
    "        self.LANDMARK_IDXS = tf.constant(tf.concat([self.FACE_IDXS, self.POSE_IDXS, self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS], 0), dtype=tf.int32)\n",
    "        \n",
    "        # Indicies after landmarks have been filtered. \n",
    "        self.FACE_START = tf.constant(0, dtype=tf.int32)\n",
    "        self.LEFT_HAND_START = tf.constant(len(self.FACE_IDXS), dtype=tf.int32)\n",
    "        self.POSE_START = tf.constant(self.LEFT_HAND_START + len(self.LEFT_HAND_IDXS), dtype=tf.int32)\n",
    "        self.RIGHT_HAND_START = tf.constant(self.POSE_START + len(self.POSE_IDXS), dtype=tf.int32)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'INPUT_SIZE': self.INPUT_SIZE,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    \n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[None, 543, 2], dtype=tf.float32),),)\n",
    "    def call(self, data):\n",
    "        \n",
    "        # Filter Out Frames With Empty Hand Data\n",
    "        frames_hands_nansum = tf.experimental.numpy.nanmean(tf.gather(data, self.HAND_IDXS, axis=1), axis=[1,2])\n",
    "        non_empty_frames_idxs = tf.where(frames_hands_nansum > 0)\n",
    "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
    "        data = tf.gather(data, non_empty_frames_idxs, axis=0)\n",
    "        \n",
    "        # Cast Indices in float32 to be compatible with Tensorflow Lite\n",
    "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32) \n",
    "        \n",
    "        N_FRAMES = tf.shape(data)[0]\n",
    "        data = tf.gather(data, self.LANDMARK_IDXS, axis=1)\n",
    "        \n",
    "        # Slice out face indicies, normalize across batch.        \n",
    "        face = tf.slice(data, [0, self.FACE_START, 0], [N_FRAMES, self.LEFT_HAND_START, 2])\n",
    "        # face_mean, face_std = self.get_mean_std(self.FACE_IDXS, face)\n",
    "        xs = tf.reshape(tf.transpose(face, [2,0,1]), [2,tf.size(self.FACE_IDXS)*tf.shape(face)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(face, [2,0,1]), [2,tf.size(self.FACE_IDXS)*tf.shape(face)[0]])[1]\n",
    "            \n",
    "        FACE_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        FACE_STD_X = tf.math.reduce_std(xs)\n",
    "        FACE_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        FACE_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        face_mean = tf.stack([FACE_MEAN_X, FACE_MEAN_Y])\n",
    "        face_std = tf.stack([FACE_STD_X, FACE_STD_Y])\n",
    "        face = tf.where(\n",
    "                    tf.math.equal(face, 0.0),\n",
    "                    0.0,\n",
    "                    (face - face_mean) / face_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out left_hand indicies, normalize across batch.\n",
    "        left_hand = tf.slice(data, [0, self.LEFT_HAND_START, 0], [N_FRAMES, self.POSE_START-self.LEFT_HAND_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(left_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(left_hand)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(left_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(left_hand)[0]])[1]\n",
    "            \n",
    "        LEFT_HAND_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        LEFT_HAND_STD_X = tf.math.reduce_std(xs)\n",
    "        LEFT_HAND_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        LEFT_HAND_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        left_hand_mean = tf.stack([LEFT_HAND_MEAN_X, LEFT_HAND_MEAN_Y])\n",
    "        left_hand_std = tf.stack([LEFT_HAND_STD_X, LEFT_HAND_STD_Y])\n",
    "        left_hand = tf.where(\n",
    "                    tf.math.equal(left_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (left_hand - left_hand_mean) / left_hand_std,\n",
    "                )\n",
    "        \n",
    "#         # Slice out pose indicies, normalize across batch.\n",
    "        pose = tf.slice(data, [0, self.POSE_START, 0], [N_FRAMES, self.RIGHT_HAND_START-self.POSE_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(pose, [2,0,1]), [2,tf.size(self.POSE_IDXS)*tf.shape(pose)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(pose, [2,0,1]), [2,tf.size(self.POSE_IDXS)*tf.shape(pose)[0]])[1]\n",
    "            \n",
    "        POSE_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        POSE_STD_X = tf.math.reduce_std(xs)\n",
    "        POSE_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        POSE_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        pose_mean = tf.stack([POSE_MEAN_X, POSE_MEAN_Y])\n",
    "        pose_std = tf.stack([POSE_STD_X, POSE_STD_Y])\n",
    "        pose = tf.where(\n",
    "                    tf.math.equal(pose, 0.0),\n",
    "                    0.0,\n",
    "                    (pose - pose_mean) / pose_std,\n",
    "                )\n",
    "        \n",
    "         # Slice out right_hand indicies, normalize across batch.\n",
    "        right_hand = tf.slice(data, [0, self.RIGHT_HAND_START, 0], [N_FRAMES, tf.shape(data)[1] - self.RIGHT_HAND_START, 2])\n",
    "        xs = tf.reshape(tf.transpose(right_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(right_hand)[0]])[0]\n",
    "        ys = tf.reshape(tf.transpose(right_hand, [2,0,1]), [2,tf.size(self.LEFT_HAND_IDXS)*tf.shape(right_hand)[0]])[1]\n",
    "            \n",
    "        RIGHT_HAND_MEAN_X = tf.math.reduce_mean(xs)\n",
    "        RIGHT_HAND_STD_X = tf.math.reduce_std(xs)\n",
    "        RIGHT_HAND_MEAN_Y = tf.math.reduce_mean(ys)\n",
    "        RIGHT_HAND_STD_Y = tf.math.reduce_std(ys)\n",
    "\n",
    "        right_hand_mean = tf.stack([RIGHT_HAND_MEAN_X, RIGHT_HAND_MEAN_Y])\n",
    "        right_hand_std = tf.stack([RIGHT_HAND_STD_X, RIGHT_HAND_STD_Y])\n",
    "        right_hand = tf.where(\n",
    "                    tf.math.equal(right_hand, 0.0),\n",
    "                    0.0,\n",
    "                    (right_hand - right_hand_mean) / right_hand_std,\n",
    "                )\n",
    "        \n",
    "        \n",
    "        # Concat landmarks back into same frame.\n",
    "        data = tf.concat([face, left_hand, pose, right_hand], 1)\n",
    "        \n",
    "        \n",
    "        # Video fits in self.INPUT_SIZE\n",
    "        if N_FRAMES < self.INPUT_SIZE: # Number of frames we want\n",
    "            # Attention mask for frames that contain data. \n",
    "            \n",
    "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, self.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            data = tf.pad(data, [[0, self.INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2))\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            return data, non_empty_frames_idxs\n",
    "        # Video needs to be downsampled to INPUT_SIZE\n",
    "        else:\n",
    "            # Downsample video using nearest interpolation method. \n",
    "            data = tf.image.resize(data, size=(self.INPUT_SIZE, data.shape[1]), method='nearest')\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            # Reshape into (Number of desired frames, (Number of landmarks * 2)).\n",
    "            data = tf.reshape(data, [self.INPUT_SIZE, tf.shape(data)[1] * 2])\n",
    "            # Create attention mask with all frames. \n",
    "            non_empty_frames_idxs = tf.range(0, self.INPUT_SIZE, 1, dtype=tf.float32)\n",
    "            return data, non_empty_frames_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35f25f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 00:41:13.865572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:13.885769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:13.887955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:13.891105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:13.893122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:13.894896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:14.408861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:14.409865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:14.410611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-20 00:41:14.411339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20561 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "preprocess_layer = PreprocessLayer(config[\"INPUT_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66850e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d43c6fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the full dataset\n",
    "def preprocess_dataset():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, config[\"INPUT_SIZE\"]], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train_metadata[['file_path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "    \n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "        \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e191aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936e2f29eb4a4bb29b38093448c5b7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/100\n",
      "X shape: (100, 38, 454), dtype: float32\n",
      "y shape: (100,), dtype: int32\n",
      "NON_EMPTY_FRAME_IDXS shape: (100, 38), dtype: float32\n",
      "# NaN Values X: 0\n"
     ]
    }
   ],
   "source": [
    "X, y, NON_EMPTY_FRAME_IDXS = preprocess_dataset()\n",
    "\n",
    "print_shape_dtype([X, y, NON_EMPTY_FRAME_IDXS], ['X', 'y', 'NON_EMPTY_FRAME_IDXS'])\n",
    "print(f'# NaN Values X: {np.isnan(X).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5d4732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FACE_IDXS = [0, 6, 7, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 30, 31, \n",
    "                     33, 37, 38, 39, 40, 41, 42, 56, 61, 62, 72, 73, 74, 76, 77, \n",
    "                     78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 110, 112, \n",
    "                     113, 122, 128, 130, 133, 144, 145, 146, 153, 154, 155, 157, 158, \n",
    "                     159, 160, 161, 163, 168, 173, 178, 179, 180, 181, 183, 184, 185, \n",
    "                     188, 189, 190, 191, 193, 196, 197, 232, 233, 243, 244, 245, 246, \n",
    "                     247, 249, 252, 253, 254, 255, 256, 259, 260, 263, 267, 268, 269, \n",
    "                     270, 271, 272, 286, 291, 292, 302, 303, 304, 306, 307, 308, 310, \n",
    "                     311, 312, 314, 316, 317, 318, 319, 320, 321, 324, 325, 339, 341, \n",
    "                     351, 357, 359, 362, 373, 374, 375, 380, 381, 382, 384, 385, 386, \n",
    "                     387, 388, 390, 398, 402, 403, 404, 405, 407, 408, 409, 412, 413, \n",
    "                     414, 415, 417, 419, 453, 463, 464, 465, 466, 467]\n",
    "POSE_IDXS = np.arange(489, 514)\n",
    "LEFT_HAND_IDXS = np.arange(468, 489)\n",
    "RIGHT_HAND_IDXS = np.arange(522, 543)\n",
    "\n",
    "# All landmarks that are used for modeling. \n",
    "LANDMARK_IDXS = np.concatenate((FACE_IDXS, POSE_IDXS, LEFT_HAND_IDXS, RIGHT_HAND_IDXS))\n",
    "\n",
    "# Indicies after landmarks have been filtered. \n",
    "FACE_START = 0\n",
    "LEFT_HAND_START = len(FACE_IDXS)\n",
    "POSE_START = LEFT_HAND_START + len(LEFT_HAND_IDXS)\n",
    "RIGHT_HAND_START = POSE_START + len(POSE_IDXS)\n",
    "\n",
    "# Length of landmarks.\n",
    "FACE_LEN = len(FACE_IDXS)\n",
    "POSE_LEN = POSE_IDXS.size\n",
    "LEFT_HAND_LEN = LEFT_HAND_IDXS.size\n",
    "RIGHT_HAND_LEN = RIGHT_HAND_IDXS.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7838ebb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandmarkEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, name, activation):\n",
    "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
    "        self.UNITS = units\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Embedding for missing landmark in frame, initizlied with zeros\n",
    "        self.empty_embedding = self.add_weight(\n",
    "            name=f'{self.name}_empty_embedding',\n",
    "            shape=[self.UNITS],\n",
    "            initializer=tf.keras.initializers.constant(0.0),\n",
    "        )\n",
    "        # Embedding\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.UNITS, name=f'{self.name}_dense_1', use_bias=False, \n",
    "                                  kernel_initializer=tf.keras.initializers.glorot_uniform, activation=self.ACTIVATION),\n",
    "            tf.keras.layers.Dense(self.UNITS, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "        ], name=f'{self.name}_dense')\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "                # Checks whether landmark is missing in frame\n",
    "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
    "                # If so, the empty embedding is used\n",
    "                self.empty_embedding,\n",
    "                # Otherwise the landmark data is embedded\n",
    "                self.dense(x),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bb44e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_size, face_units, hands_units, pose_units, units, activation):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.INPUT_SIZE = input_size\n",
    "        self.FACE_UNITS = face_units\n",
    "        self.HANDS_UNITS = hands_units\n",
    "        self.POSE_UNITS = pose_units\n",
    "        self.UNITS = units\n",
    "        self.ACTIVATION = activation\n",
    "        \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'INPUT_SIZE': self.INPUT_SIZE,\n",
    "            'FACE_UNITS': self.FACE_UNITS,\n",
    "            'HANDS_UNITS': self.HANDS_UNITS,\n",
    "            'POSE_UNITS': self.POSE_UNITS,\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Positional Embedding, initialized with zeros\n",
    "        self.positional_embedding = tf.keras.layers.Embedding(self.INPUT_SIZE+1, self.UNITS, embeddings_initializer=tf.keras.initializers.constant(0.0))\n",
    "        # Embedding layer for Landmarks\n",
    "        self.face_embedding = LandmarkEmbedding(self.FACE_UNITS, 'face', self.ACTIVATION)\n",
    "        self.left_hand_embedding = LandmarkEmbedding(self.HANDS_UNITS, 'left_hand', self.ACTIVATION)\n",
    "        self.right_hand_embedding = LandmarkEmbedding(self.HANDS_UNITS, 'right_hand', self.ACTIVATION)\n",
    "        self.pose_embedding = LandmarkEmbedding(self.POSE_UNITS, 'pose', self.ACTIVATION)\n",
    "        # Landmark Weights\n",
    "        self.landmark_weights = tf.Variable(tf.zeros([4], dtype=tf.float32), name='landmark_weights')\n",
    "        # Fully Connected Layers for combined landmarks\n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.UNITS, name='fully_connected_1', use_bias=False, \n",
    "                                  kernel_initializer=tf.keras.initializers.glorot_uniform, activation=self.ACTIVATION),\n",
    "            tf.keras.layers.Dense(self.UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "        ], name='fc')\n",
    "\n",
    "\n",
    "    def call(self, face0, left_hand0, right_hand0, pose0, non_empty_frame_idxs,training=False):\n",
    "        # Face\n",
    "        face_embedding = self.face_embedding(face0)\n",
    "        # Left Hand\n",
    "        left_hand_embedding = self.left_hand_embedding(left_hand0)\n",
    "        # Right Hand\n",
    "        right_hand_embedding = self.right_hand_embedding(right_hand0)\n",
    "        # Pose\n",
    "        pose_embedding = self.pose_embedding(pose0)\n",
    "        # Merge Embeddings of all landmarks with mean pooling\n",
    "        x = tf.stack((face_embedding, left_hand_embedding, right_hand_embedding, pose_embedding), axis=3)\n",
    "        # Merge Landmarks with trainable attention weights\n",
    "        x = x * tf.nn.softmax(self.landmark_weights)\n",
    "        x = tf.reduce_sum(x, axis=3)\n",
    "        # Fully Connected Layers\n",
    "        x = self.fc(x)\n",
    "        # Add Positional Embedding\n",
    "        normalised_non_empty_frame_idxs = tf.where(\n",
    "            tf.math.equal(non_empty_frame_idxs, -1.0),\n",
    "            self.INPUT_SIZE,\n",
    "            tf.cast(\n",
    "                non_empty_frame_idxs / tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True) * self.INPUT_SIZE,\n",
    "                tf.int32,\n",
    "            ),\n",
    "        )\n",
    "        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af24773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n",
    "# replaced softmax with softmax layer to support masked softmax\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    \n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_of_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'num_of_heads': self.num_of_heads\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self,x, attention_mask):\n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](x)\n",
    "            K = self.wk[i](x)\n",
    "            V = self.wv[i](x)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn,axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        return multi_head_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8bcc760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Transformer\n",
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_blocks, layer_norm_eps, units, mlp_ratio, mlp_dropout_ratio, activation, num_heads):\n",
    "        super(Transformer, self).__init__(name='transformer')\n",
    "        self.NUM_BLOCKS = num_blocks\n",
    "        self.LAYER_NORM_EPS = layer_norm_eps\n",
    "        self.UNITS = units\n",
    "        self.MLP_RATIO = mlp_ratio\n",
    "        self.MLP_DROPOUT_RATIO = mlp_dropout_ratio\n",
    "        self.ACTIVATION = activation\n",
    "        self.NUM_HEADS = num_heads\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'NUM_BLOCKS': self.NUM_BLOCKS,\n",
    "            'LAYER_NORM_EPS': self.LAYER_NORM_EPS,\n",
    "            'MLP_RATIO': self.MLP_RATIO,\n",
    "            'MLP_DROPOUT_RATIO': self.MLP_DROPOUT_RATIO,\n",
    "            'UNITS': self.UNITS,\n",
    "            'ACTIVATION': self.ACTIVATION,\n",
    "            'NUM_HEADS': self.NUM_HEADS\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.NUM_BLOCKS):\n",
    "            # First Layer Normalisation\n",
    "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=self.LAYER_NORM_EPS))\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(self.UNITS, self.NUM_HEADS))\n",
    "            # Second Layer Normalisation\n",
    "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=self.LAYER_NORM_EPS))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(self.UNITS * self.MLP_RATIO, activation=self.ACTIVATION, \n",
    "                                      kernel_initializer=tf.keras.initializers.glorot_uniform),\n",
    "                tf.keras.layers.Dropout(self.MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(self.UNITS, kernel_initializer=tf.keras.initializers.he_uniform),\n",
    "            ]))\n",
    "        \n",
    "    def call(self, x, attention_mask):\n",
    "        # Iterate input over transformer blocks\n",
    "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
    "            x1 = ln_1(x)\n",
    "            attention_output = mha(x1, attention_mask)\n",
    "            x2 = x1 + attention_output\n",
    "            x3 = ln_2(x2)\n",
    "            x3 = mlp(x3)\n",
    "            x = x3 + x2\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec8d504c",
   "metadata": {
    "papermill": {
     "duration": 0.043124,
     "end_time": "2023-03-27T13:50:42.896486",
     "exception": false,
     "start_time": "2023-03-27T13:50:42.853362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([config[\"INPUT_SIZE\"], config[\"N_COLS\"] * config[\"N_DIMS\"]], dtype=tf.float32, name='FRAMES')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([config[\"INPUT_SIZE\"]], dtype=tf.float32, name='NON_EMPTY_FRAME_IDXS')\n",
    "    \n",
    "    # Attention Mask\n",
    "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=2)\n",
    "    \n",
    "    # Slice out face indicies       \n",
    "    face = tf.slice(frames, [0, 0, FACE_START], [-1, config[\"INPUT_SIZE\"], FACE_LEN * 2])\n",
    "    # face = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], FACE_LEN*2])\n",
    "    \n",
    "     # Slice out left_hand indicies\n",
    "    left_hand = tf.slice(frames, [0, 0, LEFT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], LEFT_HAND_LEN * 2])\n",
    "    # left_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(LEFT_HAND_IDXS)*2])\n",
    "\n",
    "    # Slice out pose indicies\n",
    "    pose = tf.slice(frames, [0, 0, POSE_START * 2], [-1, config[\"INPUT_SIZE\"], POSE_LEN * 2])\n",
    "    # pose = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(POSE_IDXS)*2])\n",
    "\n",
    "    # Slice out right_hand indicies\n",
    "    right_hand = tf.slice(frames, [0, 0, RIGHT_HAND_START * 2], [-1, config[\"INPUT_SIZE\"], RIGHT_HAND_LEN * 2])\n",
    "    # right_hand = tf.reshape(frames, [-1, config[\"INPUT_SIZE\"], len(RIGHT_HAND_IDXS)*2])\n",
    "    \n",
    "    embedding_layer = Embedding(config[\"INPUT_SIZE\"], FACE_UNITS, HANDS_UNITS, POSE_UNITS, UNITS, ACTIVATION)\n",
    "    x = embedding_layer(face, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
    "    transformer_input_shape = x.shape\n",
    "    \n",
    "    # Encoder Transformer Blocks\n",
    "    transformer_layer = Transformer(NUM_BLOCKS, LAYER_NORM_EPS, UNITS, MLP_RATIO, \n",
    "                                    MLP_DROPOUT_RATIO, ACTIVATION, NUM_HEADS)\n",
    "    x = transformer_layer(x, mask)\n",
    "    \n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classifier Dropout\n",
    "    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(config[\"NUM_CLASSES\"], activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    \n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Simple Categorical Crossentropy Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=config[\"LEARNING_RATE\"], weight_decay=config[\"WEIGHT_DECAY\"])\n",
    "    \n",
    "    # TopK Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, run_eagerly=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c752db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = np.load('../modeling/X.npy')\n",
    "# y = np.load('../modeling/y.npy')\n",
    "# NON_EMPTY_FRAME_IDXS = np.load('../modeling/NON_EMPTY_FRAME_IDXS.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2fdb97b-7489-40f4-a69e-be79c359c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000, seed=42):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=seed)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "# Load dataset\n",
    "with tf.device('CPU'):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({\"FRAMES\": X, \"NON_EMPTY_FRAME_IDXS\": NON_EMPTY_FRAME_IDXS}, y))\n",
    "    \n",
    "train, validation, test = get_dataset_partitions_tf(dataset, X.shape[0], train_split=0.8, val_split=0.1, \n",
    "                                                test_split=0.1, shuffle=True, shuffle_size=10000, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "841f78e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Custom sampler to get a batch containing N times all signs\n",
    "# def get_train_batch(X, y, NON_EMPTY_FRAME_IDXS, batch_size=128):\n",
    "#     # Arrays to store batch in\n",
    "#     X_batch = np.zeros([batch_size, config['INPUT_SIZE'], config['N_COLS'] * config['N_DIMS']], dtype=np.float32)\n",
    "#     y_batch = np.arange(0, batch_size, step=1/batch_size, dtype=np.float32).astype(np.int64)\n",
    "#     non_empty_frame_idxs_batch = np.zeros([batch_size, config['INPUT_SIZE']], dtype=np.float32)\n",
    "    \n",
    "#     samples = X.shape[0]\n",
    "#     n_batches = samples // batch_size\n",
    "    \n",
    "#     while True:\n",
    "#         for index in range(n_batches):\n",
    "\n",
    "#             X_batch = X[(index*batch_size):((index+1)*batch_size)]\n",
    "#             y_batch = y[(index*batch_size):((index+1)*batch_size)]\n",
    "#             NON_EMPTY_FRAME_IDXS_batch = NON_EMPTY_FRAME_IDXS[(index*batch_size):((index+1)*batch_size)]\n",
    "\n",
    "#         yield { 'FRAMES': X_batch, 'NON_EMPTY_FRAME_IDXS': NON_EMPTY_FRAME_IDXS_batch }, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "494d2293-9bf9-4b42-9fc7-03eaed798c11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# NON_EMPTY_FRAME_IDXS_train, NON_EMPTY_FRAME_IDXS_val = train_test_split(NON_EMPTY_FRAME_IDXS, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779db5cb",
   "metadata": {
    "papermill": {
     "duration": 0.038802,
     "end_time": "2023-03-27T13:51:03.381634",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.342832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83ff9425",
   "metadata": {
    "papermill": {
     "duration": 0.049275,
     "end_time": "2023-03-27T13:51:03.469275",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.420000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=config[\"N_EPOCHS\"], warm_method='log'):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        if warm_method == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efbb6b24",
   "metadata": {
    "papermill": {
     "duration": 0.738209,
     "end_time": "2023-03-27T13:51:04.245805",
     "exception": false,
     "start_time": "2023-03-27T13:51:03.507596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=config[\"N_WARMUP_EPOCHS\"], \n",
    "                    lr_max=config[\"LEARNING_RATE\"], num_cycles=0.50) for step in range(config[\"N_EPOCHS\"])]\n",
    "\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f49ca",
   "metadata": {
    "papermill": {
     "duration": 0.040725,
     "end_time": "2023-03-27T13:51:04.330003",
     "exception": false,
     "start_time": "2023-03-27T13:51:04.289278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight Decay Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef2cbe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom callback to update weight decay with learning rate\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, wd_ratio=config['WD_RATIO']):\n",
    "        self.step_counter = 0\n",
    "        self.wd_ratio = wd_ratio\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
    "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac727612",
   "metadata": {
    "papermill": {
     "duration": 0.040685,
     "end_time": "2023-03-27T13:51:11.352812",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.312127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53f26154-c87a-4609-b10e-63e93175b6a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " NON_EMPTY_FRAME_IDXS (InputLay  [(None, 38)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " FRAMES (InputLayer)            [(None, 38, 454)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, 38)          0           ['NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.slice (TFOpLambda)          (None, 38, 320)      0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_1 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_3 (TFOpLambda)        (None, 38, 42)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_2 (TFOpLambda)        (None, 38, 50)       0           ['FRAMES[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 38)           0           ['tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 38, 512)      1244420     ['tf.slice[0][0]',               \n",
      "                                                                  'tf.slice_1[0][0]',             \n",
      "                                                                  'tf.slice_3[0][0]',             \n",
      "                                                                  'tf.slice_2[0][0]',             \n",
      "                                                                  'NON_EMPTY_FRAME_IDXS[0][0]']   \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 38, 1)        0           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " transformer (Transformer)      (None, 38, 512)      4205568     ['embedding[0][0]',              \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 38, 512)      0           ['transformer[0][0]',            \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 512)         0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None, 1)           0           ['tf.expand_dims[0][0]']         \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 512)          0           ['tf.math.reduce_sum[0][0]',     \n",
      "                                                                  'tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          128250      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,578,238\n",
      "Trainable params: 5,578,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "learning rate: 1.00e-06, weight decay: 5.00e-08\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 00:41:49.398842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [100]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-04-20 00:41:50.082327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 7.3601 - acc: 0.0125 - top_5_acc: 0.0500 - top_10_acc: 0.0875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 00:41:50.426450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [100]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 7.3601 - acc: 0.0125 - top_5_acc: 0.0500 - top_10_acc: 0.0875 - val_loss: 8.4486 - val_acc: 0.0000e+00 - val_top_5_acc: 0.0000e+00 - val_top_10_acc: 0.0000e+00 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 1e-05.\n",
      "learning rate: 1.00e-05, weight decay: 5.00e-07\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 7.4260 - acc: 0.0000e+00 - top_5_acc: 0.0250 - top_10_acc: 0.0375 - val_loss: 6.8016 - val_acc: 0.0000e+00 - val_top_5_acc: 0.1000 - val_top_10_acc: 0.2000 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0001.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 6.8975 - acc: 0.0250 - top_5_acc: 0.0500 - top_10_acc: 0.1000 - val_loss: 5.9199 - val_acc: 0.0000e+00 - val_top_5_acc: 0.0000e+00 - val_top_10_acc: 0.0000e+00 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 9.99743108100344e-05.\n",
      "learning rate: 1.00e-04, weight decay: 5.00e-06\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 5.8495 - acc: 0.0625 - top_5_acc: 0.1000 - top_10_acc: 0.1750 - val_loss: 5.5651 - val_acc: 0.0000e+00 - val_top_5_acc: 0.1000 - val_top_10_acc: 0.2000 - lr: 9.9974e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 9.989726963751682e-05.\n",
      "learning rate: 9.99e-05, weight decay: 4.99e-06\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 5.1158 - acc: 0.0500 - top_5_acc: 0.1625 - top_10_acc: 0.2875 - val_loss: 3.9819 - val_acc: 0.1000 - val_top_5_acc: 0.4000 - val_top_10_acc: 0.5000 - lr: 9.9897e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 9.976895564745991e-05.\n",
      "learning rate: 9.98e-05, weight decay: 4.99e-06\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 4.9151 - acc: 0.0500 - top_5_acc: 0.2375 - top_10_acc: 0.3250 - val_loss: 4.4484 - val_acc: 0.1000 - val_top_5_acc: 0.4000 - val_top_10_acc: 0.4000 - lr: 9.9769e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 9.95895006911623e-05.\n",
      "learning rate: 9.96e-05, weight decay: 4.98e-06\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 4.3519 - acc: 0.1000 - top_5_acc: 0.3125 - top_10_acc: 0.4000 - val_loss: 3.4388 - val_acc: 0.3000 - val_top_5_acc: 0.7000 - val_top_10_acc: 0.7000 - lr: 9.9590e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 9.935908917072252e-05.\n",
      "learning rate: 9.94e-05, weight decay: 4.97e-06\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 4.0285 - acc: 0.1250 - top_5_acc: 0.3500 - top_10_acc: 0.4750 - val_loss: 4.2920 - val_acc: 0.2000 - val_top_5_acc: 0.3000 - val_top_10_acc: 0.4000 - lr: 9.9359e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 9.907795784955327e-05.\n",
      "learning rate: 9.91e-05, weight decay: 4.95e-06\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 3.8868 - acc: 0.1375 - top_5_acc: 0.3750 - top_10_acc: 0.5250 - val_loss: 3.5407 - val_acc: 0.2000 - val_top_5_acc: 0.5000 - val_top_10_acc: 0.6000 - lr: 9.9078e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 9.874639560909117e-05.\n",
      "learning rate: 9.87e-05, weight decay: 4.94e-06\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 3.4388 - acc: 0.2000 - top_5_acc: 0.5000 - top_10_acc: 0.6125 - val_loss: 2.3338 - val_acc: 0.5000 - val_top_5_acc: 0.8000 - val_top_10_acc: 0.9000 - lr: 9.8746e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 9.836474315195147e-05.\n",
      "learning rate: 9.84e-05, weight decay: 4.92e-06\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 3.3364 - acc: 0.2000 - top_5_acc: 0.5750 - top_10_acc: 0.6875 - val_loss: 2.6831 - val_acc: 0.4000 - val_top_5_acc: 0.7000 - val_top_10_acc: 0.8000 - lr: 9.8365e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 9.793339265183303e-05.\n",
      "learning rate: 9.79e-05, weight decay: 4.90e-06\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 3.0240 - acc: 0.2375 - top_5_acc: 0.5625 - top_10_acc: 0.7375 - val_loss: 2.1456 - val_acc: 0.5000 - val_top_5_acc: 0.9000 - val_top_10_acc: 0.9000 - lr: 9.7933e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 9.745278735053343e-05.\n",
      "learning rate: 9.75e-05, weight decay: 4.87e-06\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 2.8381 - acc: 0.3000 - top_5_acc: 0.6375 - top_10_acc: 0.8250 - val_loss: 2.3662 - val_acc: 0.6000 - val_top_5_acc: 0.8000 - val_top_10_acc: 0.9000 - lr: 9.7453e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 9.692342110248802e-05.\n",
      "learning rate: 9.69e-05, weight decay: 4.85e-06\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 2.6713 - acc: 0.3000 - top_5_acc: 0.6375 - top_10_acc: 0.7625 - val_loss: 2.2138 - val_acc: 0.5000 - val_top_5_acc: 0.9000 - val_top_10_acc: 1.0000 - lr: 9.6923e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 9.63458378673011e-05.\n",
      "learning rate: 9.63e-05, weight decay: 4.82e-06\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 2.8631 - acc: 0.2125 - top_5_acc: 0.5875 - top_10_acc: 0.7625 - val_loss: 1.8082 - val_acc: 0.6000 - val_top_5_acc: 0.7000 - val_top_10_acc: 0.9000 - lr: 9.6346e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 9.572063115079063e-05.\n",
      "learning rate: 9.57e-05, weight decay: 4.79e-06\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 2.4524 - acc: 0.3625 - top_5_acc: 0.7125 - top_10_acc: 0.8750 - val_loss: 1.7092 - val_acc: 0.6000 - val_top_5_acc: 0.9000 - val_top_10_acc: 1.0000 - lr: 9.5721e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 9.504844339512095e-05.\n",
      "learning rate: 9.50e-05, weight decay: 4.75e-06\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 2.2286 - acc: 0.4750 - top_5_acc: 0.7750 - top_10_acc: 0.8875 - val_loss: 1.8661 - val_acc: 0.5000 - val_top_5_acc: 0.9000 - val_top_10_acc: 1.0000 - lr: 9.5048e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 9.432996531865002e-05.\n",
      "learning rate: 9.43e-05, weight decay: 4.72e-06\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 2.1094 - acc: 0.4625 - top_5_acc: 0.7750 - top_10_acc: 0.9250 - val_loss: 1.9974 - val_acc: 0.6000 - val_top_5_acc: 0.8000 - val_top_10_acc: 0.9000 - lr: 9.4330e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 9.356593520616948e-05.\n",
      "learning rate: 9.36e-05, weight decay: 4.68e-06\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 1.8236 - acc: 0.5000 - top_5_acc: 0.8625 - top_10_acc: 0.9500 - val_loss: 1.8747 - val_acc: 0.6000 - val_top_5_acc: 0.9000 - val_top_10_acc: 1.0000 - lr: 9.3566e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 9.275713815026731e-05.\n",
      "learning rate: 9.28e-05, weight decay: 4.64e-06\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 1.6107 - acc: 0.6125 - top_5_acc: 0.8875 - top_10_acc: 0.9625 - val_loss: 1.9168 - val_acc: 0.5000 - val_top_5_acc: 0.8000 - val_top_10_acc: 0.9000 - lr: 9.2757e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 9.190440524459203e-05.\n",
      "learning rate: 9.19e-05, weight decay: 4.60e-06\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 1.6629 - acc: 0.5000 - top_5_acc: 0.9000 - top_10_acc: 0.9875 - val_loss: 0.9561 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 9.1904e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 9.10086127298478e-05.\n",
      "learning rate: 9.10e-05, weight decay: 4.55e-06\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 1.4394 - acc: 0.6750 - top_5_acc: 0.9125 - top_10_acc: 0.9500 - val_loss: 1.4946 - val_acc: 0.6000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 9.1009e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 9.007068109339784e-05.\n",
      "learning rate: 9.01e-05, weight decay: 4.50e-06\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 1.2734 - acc: 0.7000 - top_5_acc: 0.9750 - top_10_acc: 1.0000 - val_loss: 0.8811 - val_acc: 0.8000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 9.0071e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 8.90915741234015e-05.\n",
      "learning rate: 8.91e-05, weight decay: 4.45e-06\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 1.1355 - acc: 0.7375 - top_5_acc: 0.9625 - top_10_acc: 0.9875 - val_loss: 1.1261 - val_acc: 0.7000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.9092e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 8.807229791845673e-05.\n",
      "learning rate: 8.81e-05, weight decay: 4.40e-06\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 1.0887 - acc: 0.7500 - top_5_acc: 0.9750 - top_10_acc: 0.9875 - val_loss: 0.9139 - val_acc: 0.7000 - val_top_5_acc: 0.9000 - val_top_10_acc: 1.0000 - lr: 8.8072e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 8.701389985376578e-05.\n",
      "learning rate: 8.70e-05, weight decay: 4.35e-06\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 1.0465 - acc: 0.7625 - top_5_acc: 0.9625 - top_10_acc: 1.0000 - val_loss: 0.7006 - val_acc: 0.9000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.7014e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 8.591746750488639e-05.\n",
      "learning rate: 8.59e-05, weight decay: 4.30e-06\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.8597 - acc: 0.8125 - top_5_acc: 0.9875 - top_10_acc: 1.0000 - val_loss: 0.5610 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.5917e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 8.478412753017433e-05.\n",
      "learning rate: 8.48e-05, weight decay: 4.24e-06\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.8122 - acc: 0.8125 - top_5_acc: 0.9875 - top_10_acc: 1.0000 - val_loss: 0.6289 - val_acc: 0.9000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.4784e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 8.361504451306585e-05.\n",
      "learning rate: 8.36e-05, weight decay: 4.18e-06\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.7471 - acc: 0.8500 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.5914 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.3615e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 8.241141976538943e-05.\n",
      "learning rate: 8.24e-05, weight decay: 4.12e-06\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.6711 - acc: 0.8875 - top_5_acc: 0.9875 - top_10_acc: 1.0000 - val_loss: 0.6053 - val_acc: 0.9000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.2411e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 8.117449009293668e-05.\n",
      "learning rate: 8.12e-05, weight decay: 4.06e-06\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.5703 - acc: 0.8750 - top_5_acc: 0.9625 - top_10_acc: 0.9875 - val_loss: 0.6016 - val_acc: 0.9000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.1174e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 7.990552652456081e-05.\n",
      "learning rate: 7.99e-05, weight decay: 4.00e-06\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.5597 - acc: 0.9125 - top_5_acc: 0.9750 - top_10_acc: 1.0000 - val_loss: 0.1816 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.9906e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 7.860583300610849e-05.\n",
      "learning rate: 7.86e-05, weight decay: 3.93e-06\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.4930 - acc: 0.8750 - top_5_acc: 0.9750 - top_10_acc: 0.9875 - val_loss: 0.3274 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.8606e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 7.727674506052743e-05.\n",
      "learning rate: 7.73e-05, weight decay: 3.86e-06\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.4511 - acc: 0.8750 - top_5_acc: 0.9750 - top_10_acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.9000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.7277e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 7.591962841552627e-05.\n",
      "learning rate: 7.59e-05, weight decay: 3.80e-06\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.4200 - acc: 0.9000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.4321 - val_acc: 0.9000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.5920e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 7.45358776001969e-05.\n",
      "learning rate: 7.45e-05, weight decay: 3.73e-06\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.4074 - acc: 0.9375 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.3045 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.4536e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 7.312691451204178e-05.\n",
      "learning rate: 7.31e-05, weight decay: 3.66e-06\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.3716 - acc: 0.9000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.2637 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.3127e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 7.169418695587791e-05.\n",
      "learning rate: 7.17e-05, weight decay: 3.58e-06\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2898 - acc: 0.9750 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0802 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.1694e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 7.023916715611969e-05.\n",
      "learning rate: 7.02e-05, weight decay: 3.51e-06\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.2802 - acc: 0.9500 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0705 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.0239e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 6.876335024396872e-05.\n",
      "learning rate: 6.88e-05, weight decay: 3.44e-06\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.2465 - acc: 0.9625 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1744 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.8763e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 6.726825272106538e-05.\n",
      "learning rate: 6.73e-05, weight decay: 3.36e-06\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.1898 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1089 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.7268e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 6.575541090118105e-05.\n",
      "learning rate: 6.58e-05, weight decay: 3.29e-06\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.1964 - acc: 0.9750 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1608 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.5755e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 6.422637933155162e-05.\n",
      "learning rate: 6.42e-05, weight decay: 3.21e-06\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.1911 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1297 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.4226e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 6.268272919547537e-05.\n",
      "learning rate: 6.27e-05, weight decay: 3.13e-06\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.1809 - acc: 0.9750 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1325 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.2683e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 6.112604669781572e-05.\n",
      "learning rate: 6.11e-05, weight decay: 3.06e-06\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.1479 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1213 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.1126e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 5.955793143506863e-05.\n",
      "learning rate: 5.96e-05, weight decay: 2.98e-06\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.1864 - acc: 0.9750 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1486 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.9558e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 5.7979994751668964e-05.\n",
      "learning rate: 5.80e-05, weight decay: 2.90e-06\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.1101 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.1306 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.7980e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 5.6393858084225305e-05.\n",
      "learning rate: 5.64e-05, weight decay: 2.82e-06\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.1318 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0711 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.6394e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 5.480115129538409e-05.\n",
      "learning rate: 5.48e-05, weight decay: 2.74e-06\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.1159 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0611 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.4801e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 5.320351099903565e-05.\n",
      "learning rate: 5.32e-05, weight decay: 2.66e-06\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.1212 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0474 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.3204e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 5.1602578878582776e-05.\n",
      "learning rate: 5.16e-05, weight decay: 2.58e-06\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.1100 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0601 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.1603e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 5e-05.\n",
      "learning rate: 5.00e-05, weight decay: 2.50e-06\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0991 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0552 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.0000e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 4.839742112141724e-05.\n",
      "learning rate: 4.84e-05, weight decay: 2.42e-06\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.1077 - acc: 0.9625 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0682 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.8397e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 4.679648900096436e-05.\n",
      "learning rate: 4.68e-05, weight decay: 2.34e-06\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.1187 - acc: 0.9750 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0601 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.6796e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 4.5198848704615914e-05.\n",
      "learning rate: 4.52e-05, weight decay: 2.26e-06\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0743 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0734 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.5199e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 4.3606141915774693e-05.\n",
      "learning rate: 4.36e-05, weight decay: 2.18e-06\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0712 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0560 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.3606e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 4.2020005248331054e-05.\n",
      "learning rate: 4.20e-05, weight decay: 2.10e-06\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0831 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0365 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.2020e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 4.04420685649314e-05.\n",
      "learning rate: 4.04e-05, weight decay: 2.02e-06\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0788 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0596 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.0442e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 3.887395330218429e-05.\n",
      "learning rate: 3.89e-05, weight decay: 1.94e-06\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0610 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.8874e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 3.731727080452464e-05.\n",
      "learning rate: 3.73e-05, weight decay: 1.87e-06\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0831 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.7317e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 3.5773620668448384e-05.\n",
      "learning rate: 3.58e-05, weight decay: 1.79e-06\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0575 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.5774e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 3.424458909881897e-05.\n",
      "learning rate: 3.42e-05, weight decay: 1.71e-06\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0577 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0581 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.4245e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 3.273174727893463e-05.\n",
      "learning rate: 3.27e-05, weight decay: 1.64e-06\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0679 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0405 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.2732e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 3.12366497560313e-05.\n",
      "learning rate: 3.12e-05, weight decay: 1.56e-06\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0657 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0483 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.1237e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 2.976083284388031e-05.\n",
      "learning rate: 2.98e-05, weight decay: 1.49e-06\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0397 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0433 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.9761e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 2.8305813044122097e-05.\n",
      "learning rate: 2.83e-05, weight decay: 1.42e-06\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0511 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.8306e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 2.687308548795825e-05.\n",
      "learning rate: 2.69e-05, weight decay: 1.34e-06\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0523 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0389 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.6873e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 2.5464122399803125e-05.\n",
      "learning rate: 2.55e-05, weight decay: 1.27e-06\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0541 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.5464e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 2.4080371584473748e-05.\n",
      "learning rate: 2.41e-05, weight decay: 1.20e-06\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0496 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.4080e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 2.272325493947257e-05.\n",
      "learning rate: 2.27e-05, weight decay: 1.14e-06\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0419 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.2723e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 2.139416699389153e-05.\n",
      "learning rate: 2.14e-05, weight decay: 1.07e-06\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0528 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.1394e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 2.0094473475439202e-05.\n",
      "learning rate: 2.01e-05, weight decay: 1.00e-06\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0370 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.0094e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.8825509907063327e-05.\n",
      "learning rate: 1.88e-05, weight decay: 9.41e-07\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0436 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0276 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.8826e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.758858023461059e-05.\n",
      "learning rate: 1.76e-05, weight decay: 8.79e-07\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0487 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.7589e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.6384955486934156e-05.\n",
      "learning rate: 1.64e-05, weight decay: 8.19e-07\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0385 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.6385e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.5215872469825682e-05.\n",
      "learning rate: 1.52e-05, weight decay: 7.61e-07\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0377 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.5216e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.4082532495113626e-05.\n",
      "learning rate: 1.41e-05, weight decay: 7.04e-07\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0622 - acc: 0.9750 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.4083e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.2986100146234232e-05.\n",
      "learning rate: 1.30e-05, weight decay: 6.49e-07\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0356 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0302 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.2986e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.1927702081543279e-05.\n",
      "learning rate: 1.19e-05, weight decay: 5.96e-07\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0499 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.1928e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.090842587659851e-05.\n",
      "learning rate: 1.09e-05, weight decay: 5.45e-07\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0432 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.0908e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 9.929318906602175e-06.\n",
      "learning rate: 9.93e-06, weight decay: 4.96e-07\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0390 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 9.9293e-06\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 8.991387270152201e-06.\n",
      "learning rate: 8.99e-06, weight decay: 4.50e-07\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0397 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.9914e-06\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 8.09559475540797e-06.\n",
      "learning rate: 8.10e-06, weight decay: 4.05e-07\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0476 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 8.0956e-06\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 7.242861849732696e-06.\n",
      "learning rate: 7.24e-06, weight decay: 3.62e-07\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0360 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 7.2429e-06\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 6.43406479383053e-06.\n",
      "learning rate: 6.43e-06, weight decay: 3.22e-07\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0324 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.4341e-06\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 5.670034681349995e-06.\n",
      "learning rate: 5.67e-06, weight decay: 2.84e-07\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0458 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 5.6700e-06\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 4.951556604879048e-06.\n",
      "learning rate: 4.95e-06, weight decay: 2.48e-07\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0412 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0266 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.9516e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 4.279368849209381e-06.\n",
      "learning rate: 4.28e-06, weight decay: 2.14e-07\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0466 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.2794e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 3.654162132698918e-06.\n",
      "learning rate: 3.65e-06, weight decay: 1.83e-07\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0367 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.6542e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 3.076578897511978e-06.\n",
      "learning rate: 3.08e-06, weight decay: 1.54e-07\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0405 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 3.0766e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 2.547212649466568e-06.\n",
      "learning rate: 2.55e-06, weight decay: 1.27e-07\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0360 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.5472e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 2.066607348166971e-06.\n",
      "learning rate: 2.07e-06, weight decay: 1.03e-07\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0329 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.0666e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 1.6352568480485276e-06.\n",
      "learning rate: 1.64e-06, weight decay: 8.18e-08\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0391 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0315 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.6353e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 1.2536043909088191e-06.\n",
      "learning rate: 1.25e-06, weight decay: 6.27e-08\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0356 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.2536e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 9.220421504467281e-07.\n",
      "learning rate: 9.22e-07, weight decay: 4.61e-08\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0337 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 9.2204e-07\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 6.409108292774913e-07.\n",
      "learning rate: 6.41e-07, weight decay: 3.20e-08\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0435 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0271 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 6.4091e-07\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 4.104993088376974e-07.\n",
      "learning rate: 4.10e-07, weight decay: 2.05e-08\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0398 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 4.1050e-07\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 2.310443525400885e-07.\n",
      "learning rate: 2.31e-07, weight decay: 1.16e-08\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0471 - acc: 0.9875 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0308 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.3104e-07\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 1.0273036248318324e-07.\n",
      "learning rate: 1.03e-07, weight decay: 5.14e-09\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0359 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 1.0273e-07\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.568918996560532e-08.\n",
      "learning rate: 2.57e-08, weight decay: 1.28e-09\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0425 - acc: 1.0000 - top_5_acc: 1.0000 - top_10_acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000 - val_top_5_acc: 1.0000 - val_top_10_acc: 1.0000 - lr: 2.5689e-08\n"
     ]
    }
   ],
   "source": [
    "# Clear all models in GPU\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Get new fresh model\n",
    "model = get_model()\n",
    "\n",
    "# Sanity Check\n",
    "model.summary()\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# Actual Training\n",
    "history = model.fit(\n",
    "        train.batch(config['TRAIN_BATCH_SIZE']),\n",
    "        epochs=config[\"N_EPOCHS\"],\n",
    "        validation_data=validation.batch(config[\"VAL_BATCH_SIZE\"]),\n",
    "        callbacks=[\n",
    "            lr_callback,\n",
    "            WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "            tensorboard_callback\n",
    "          ],\n",
    "        verbose = VERBOSE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bca04-9d51-4ebb-9e2d-7b25fe63d6c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Clear all models in GPU\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# # Get new fresh model\n",
    "# model = get_model()\n",
    "\n",
    "# # Sanity Check\n",
    "# model.summary()\n",
    "\n",
    "# log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# # Actual Training\n",
    "\n",
    "# history = model.fit(\n",
    "#     x=({ 'FRAMES': X, 'NON_EMPTY_FRAME_IDXS': NON_EMPTY_FRAME_IDXS }),\n",
    "#     y=y,\n",
    "#     batch_size=config['TRAIN_BATCH_SIZE'],\n",
    "#     epochs=config['N_EPOCHS'],\n",
    "#     verbose=VERBOSE,\n",
    "#     callbacks=[\n",
    "#             lr_callback,\n",
    "#             WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "#             tensorboard_callback\n",
    "#           ],\n",
    "#     validation_split=0.1,\n",
    "#     # shuffle=True,\n",
    "#     # steps_per_epoch=None,\n",
    "#     # validation_steps=None,\n",
    "#     # validation_batch_size=None,\n",
    "#     # validation_freq=1,\n",
    "#     # max_queue_size=10,\n",
    "#     # workers=1,\n",
    "#     # use_multiprocessing=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb34e2f",
   "metadata": {
    "papermill": {
     "duration": 2852.852405,
     "end_time": "2023-03-27T14:38:44.682355",
     "exception": false,
     "start_time": "2023-03-27T13:51:11.829950",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Clear all models in GPU\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# # Get new fresh model\n",
    "# model = get_model()\n",
    "\n",
    "# # Sanity Check\n",
    "# model.summary()\n",
    "\n",
    "# log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# # stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# # Actual Training\n",
    "# history = model.fit(\n",
    "#         x=get_train_batch(X_train, y_train, NON_EMPTY_FRAME_IDXS_train, batch_size=config['TRAIN_BATCH_SIZE']),\n",
    "#         steps_per_epoch= len(X_train) // config['TRAIN_BATCH_SIZE'],\n",
    "#         epochs=config[\"N_EPOCHS\"],\n",
    "#         validation_data= ({ 'FRAMES': X_val, 'NON_EMPTY_FRAME_IDXS': NON_EMPTY_FRAME_IDXS_val }, y_val),\n",
    "#         batch_size=config[\"BATCH_SIZE_VAL\"],\n",
    "#         callbacks=[\n",
    "#             lr_callback,\n",
    "#             WeightDecayCallback(config[\"WD_RATIO\"]),\n",
    "# #             tensorboard_callback\n",
    "#           ],\n",
    "#         verbose = VERBOSE,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78674927",
   "metadata": {
    "papermill": {
     "duration": 0.204275,
     "end_time": "2023-03-27T14:38:44.950811",
     "exception": false,
     "start_time": "2023-03-27T14:38:44.746536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Model Weights\n",
    "model.save_weights(f'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fdf980c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "# model.load_weights('tf_models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0df4e",
   "metadata": {
    "papermill": {
     "duration": 0.065813,
     "end_time": "2023-03-27T14:38:48.284324",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.218511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Submission code loosley based on [this notebook](https://www.kaggle.com/code/dschettler8845/gislr-learn-eda-baseline#baseline) by [Darien Schettler\n",
    "](https://www.kaggle.com/dschettler8845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f41ce3fe",
   "metadata": {
    "papermill": {
     "duration": 1.644953,
     "end_time": "2023-03-27T14:38:49.995113",
     "exception": false,
     "start_time": "2023-03-27T14:38:48.350160",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TFLite model for submission\n",
    "class TFLiteModel(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.preprocess_layer = preprocess_layer\n",
    "        self.model = model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, config[\"N_ROWS\"], config[\"N_DIMS\"]], dtype=tf.float32, name='inputs')])\n",
    "    def call(self, inputs):\n",
    "        # Preprocess Data\n",
    "        x, non_empty_frame_idxs = self.preprocess_layer(inputs)\n",
    "        # Add Batch Dimension\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
    "        # Make Prediction\n",
    "        outputs = self.model({'FRAMES': x, 'NON_EMPTY_FRAME_IDXS': non_empty_frame_idxs })\n",
    "        # Squeeze Output 1x250 -> 250\n",
    "        outputs = tf.squeeze(outputs, axis=0)\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n",
    "\n",
    "# Define TF Lite Model\n",
    "tflite_keras_model = TFLiteModel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee9cf4b6",
   "metadata": {
    "papermill": {
     "duration": 32.570402,
     "end_time": "2023-03-27T14:39:22.633212",
     "exception": false,
     "start_time": "2023-03-27T14:38:50.062810",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.TFLiteModel object at 0x7f74f0137f70>, because it is not built.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 00:43:29.627939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:29.628042: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocess_layer/1331035' with dtype int32 and shape [227]\n",
      "\t [[{{node preprocess_layer/1331035}}]]\n",
      "2023-04-20 00:43:29.984774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:29.984890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '1331752' with dtype int32 and shape [227]\n",
      "\t [[{{node 1331752}}]]\n",
      "2023-04-20 00:43:30.160284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'data' with dtype float and shape [?,543,2]\n",
      "\t [[{{node data}}]]\n",
      "2023-04-20 00:43:30.160387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '1332346' with dtype int32 and shape [227]\n",
      "\t [[{{node 1332346}}]]\n",
      "2023-04-20 00:43:30.195470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.214566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.223005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.228924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.235022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.240896: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face_embedding_dense_1_input' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.245204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.249633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.256106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.261927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.289928: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.308766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.316490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.322381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.328462: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.334364: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.338774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.343339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.349860: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.355554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.384237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.403922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.411943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.417788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.423907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.429744: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand_embedding_dense_1_input' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.434103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.438331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.444673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.450083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.477951: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.496586: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.504926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.510822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.516920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.522798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose_embedding_dense_1_input' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose_embedding_dense_1_input}}]]\n",
      "2023-04-20 00:43:30.527075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.531312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.537810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.543209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.570696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-20 00:43:30.589373: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-20 00:43:30.597063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.602960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-20 00:43:30.610049: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.616269: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fully_connected_1_input' with dtype float and shape [?,38,384]\n",
      "\t [[{{node fully_connected_1_input}}]]\n",
      "2023-04-20 00:43:30.620738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.625029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.631509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.636994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.697492: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-20 00:43:30.724595: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-20 00:43:30.736155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.744263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-20 00:43:30.750841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.758911: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_13_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_13_input}}]]\n",
      "2023-04-20 00:43:30.763797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.768073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.775982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.784021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.790346: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.823528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-20 00:43:30.850843: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-20 00:43:30.862372: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.870550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-20 00:43:30.877162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.885029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,38,512]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-04-20 00:43:30.889893: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.894050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.901411: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.909318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:30.915609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:32.318854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'FRAMES' with dtype float and shape [?,38,454]\n",
      "\t [[{{node FRAMES}}]]\n",
      "2023-04-20 00:43:32.443001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'FRAMES' with dtype float and shape [?,38,454]\n",
      "\t [[{{node FRAMES}}]]\n",
      "2023-04-20 00:43:32.464758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-20 00:43:32.464865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-20 00:43:32.464920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-20 00:43:32.464991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-20 00:43:32.481507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-20 00:43:32.481592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-20 00:43:32.481643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-20 00:43:32.481692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-20 00:43:32.521096: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-20 00:43:32.565417: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-20 00:43:32.574949: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:32.634601: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:32.689596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:32.753087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'data' with dtype float and shape [?,543,2]\n",
      "\t [[{{node data}}]]\n",
      "2023-04-20 00:43:32.753183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '1338216' with dtype int32 and shape [227]\n",
      "\t [[{{node 1338216}}]]\n",
      "2023-04-20 00:43:33.203053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-20 00:43:33.258996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,38,454]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-04-20 00:43:34.441750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-20 00:43:34.441851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-20 00:43:34.441902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-20 00:43:34.441950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-20 00:43:34.458307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'face0' with dtype float and shape [?,38,320]\n",
      "\t [[{{node face0}}]]\n",
      "2023-04-20 00:43:34.458395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'left_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node left_hand0}}]]\n",
      "2023-04-20 00:43:34.458446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'right_hand0' with dtype float and shape [?,38,42]\n",
      "\t [[{{node right_hand0}}]]\n",
      "2023-04-20 00:43:34.458494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pose0' with dtype float and shape [?,38,50]\n",
      "\t [[{{node pose0}}]]\n",
      "2023-04-20 00:43:34.794996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-20 00:43:34.837061: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,38,512]\n",
      "\t [[{{node x}}]]\n",
      "2023-04-20 00:43:35.692021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.742221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.748022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.840662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.846737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.912475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.918783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.983427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:35.989215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.054734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.060536: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.120684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.141298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.174410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.180843: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.256435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.263247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.336304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,320]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.356971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.374593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.394814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.412272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.432396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.450103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,50]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.470324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,384]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.522823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.546791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.564122: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.583246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.604267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:43:36.620792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,38,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, face_embedding_layer_call_fn, face_embedding_layer_call_and_return_conditional_losses, left_hand_embedding_layer_call_fn while saving (showing 5 of 78). These functions will not be directly callable after loading.\n",
      "2023-04-20 00:43:36.991701: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node serving_default_inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy065_rpk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy065_rpk/assets\n",
      "2023-04-20 00:43:44.332265: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node serving_default_inputs}}]]\n",
      "2023-04-20 00:43:46.906297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_begin_values_1' with dtype int32\n",
      "\t [[{{node slice_begin_values_1}}]]\n",
      "2023-04-20 00:43:46.906432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-20 00:43:46.907140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-20 00:43:46.907872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_1_x' with dtype int32\n",
      "\t [[{{node sub_1_x}}]]\n",
      "2023-04-20 00:43:46.908640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_3_x' with dtype int32\n",
      "\t [[{{node sub_3_x}}]]\n",
      "2023-04-20 00:43:47.073054: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_begin_values_1' with dtype int32\n",
      "\t [[{{node slice_begin_values_1}}]]\n",
      "2023-04-20 00:43:47.073194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-20 00:43:47.073898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-20 00:43:47.074636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_1_x' with dtype int32\n",
      "\t [[{{node sub_1_x}}]]\n",
      "2023-04-20 00:43:47.075410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_3_x' with dtype int32\n",
      "\t [[{{node sub_3_x}}]]\n",
      "2023-04-20 00:43:47.243995: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_begin_values_1' with dtype int32\n",
      "\t [[{{node slice_begin_values_1}}]]\n",
      "2023-04-20 00:43:47.244146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-20 00:43:47.244856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'slice_size_values_1' with dtype int32\n",
      "\t [[{{node slice_size_values_1}}]]\n",
      "2023-04-20 00:43:47.245590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_1_x' with dtype int32\n",
      "\t [[{{node sub_1_x}}]]\n",
      "2023-04-20 00:43:47.246360: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sub_3_x' with dtype int32\n",
      "\t [[{{node sub_3_x}}]]\n",
      "2023-04-20 00:43:49.111909: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-04-20 00:43:49.111956: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-04-20 00:43:49.113585: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpy065_rpk\n",
      "2023-04-20 00:43:49.135378: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-04-20 00:43:49.135419: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpy065_rpk\n",
      "2023-04-20 00:43:49.205442: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-04-20 00:43:49.220083: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-04-20 00:43:49.623045: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpy065_rpk\n",
      "2023-04-20 00:43:49.748953: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 635368 microseconds.\n",
      "2023-04-20 00:43:50.128790: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: /kaggle/working/model.tflite\n",
      "\n",
      "zip error: Nothing to do! (submission.zip)\n"
     ]
    }
   ],
   "source": [
    "# Create Model Converter\n",
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "keras_model_converter.experimental_new_converter = True\n",
    "\n",
    "# Convert Model\n",
    "tflite_model = keras_model_converter.convert()\n",
    "# Write Model\n",
    "with open(f'model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "# Zip Model\n",
    "# !zip submission.zip /kaggle/working/model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f15fede1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_raw_data shape: (105, 543, 2), dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 00:44:25.349372: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,543,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-20 00:44:25.349470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'preprocess_layer/1368868' with dtype int32 and shape [227]\n",
      "\t [[{{node preprocess_layer/1368868}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_output shape: (250,), dtype: <dtype: 'float32'>\n",
      "demo_prediction: 17, correct: 10\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "demo_raw_data = load_relevant_data_subset(train_metadata['file_path'].values[2])\n",
    "print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n",
    "demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n",
    "print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n",
    "demo_prediction = demo_output.numpy().argmax()\n",
    "print(f'demo_prediction: {demo_prediction}, correct: {train_metadata.iloc[0][\"sign_ord\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "343b01c0",
   "metadata": {
    "papermill": {
     "duration": 11.438209,
     "end_time": "2023-03-27T14:39:34.137659",
     "exception": false,
     "start_time": "2023-03-27T14:39:22.699450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED :  cloud [17]\n",
      "TRUE :  blow [10]\n"
     ]
    }
   ],
   "source": [
    "# Verify TFLite model can be loaded and used for prediction\n",
    "# !pip install tflite-runtime\n",
    "# import tf.lite.interpreter as tflite\n",
    "\n",
    "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
    "# interpreter = tf.lite.Interpreter(\"/kaggle/working/model.tflite\")\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "output = prediction_fn(inputs=demo_raw_data)\n",
    "sign = output['outputs'].argmax()\n",
    "\n",
    "print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')\n",
    "print(\"TRUE : \", train_metadata.sign.values[0], f'[{train_metadata.sign_ord.values[0]}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e85b52-0fd6-44fb-9ed7-6ef94fe810c1",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c6b0884-b6d7-46a0-ab45-80757ec9ec12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_classification_report():\n",
    "    # Classification report for all signs\n",
    "    classification_report = sklearn.metrics.classification_report(\n",
    "            y_test,\n",
    "            y_test_pred,\n",
    "            target_names=labels,\n",
    "            output_dict=True,\n",
    "        )\n",
    "    # Round Data for better readability\n",
    "    classification_report = pd.DataFrame(classification_report).T\n",
    "    classification_report = classification_report.round(2)\n",
    "    classification_report = classification_report.astype({\n",
    "            'support': np.uint16,\n",
    "        })\n",
    "    # Add signs\n",
    "    classification_report['sign'] = [e if e in SIGN2ORD else -1 for e in classification_report.index]\n",
    "    classification_report['sign_ord'] = classification_report['sign'].apply(SIGN2ORD.get).fillna(-1).astype(np.int16)\n",
    "    # Sort on F1-score\n",
    "    classification_report = pd.concat((\n",
    "        classification_report.head(config[\"NUM_CLASSES\"]).sort_values('f1-score', ascending=False),\n",
    "        classification_report.tail(3),\n",
    "    ))\n",
    "\n",
    "    pd.options.display.max_rows = 999\n",
    "    display(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65aa3d4e-f910-4cac-b691-7c6c5695ca0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 00:54:10.685466: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [100]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = []  # store predicted labels\n",
    "y_test = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in test.batch(1024):   # use dataset.unbatch() with repeat\n",
    "   # append true labels\n",
    "   y_test.append(label_batch)\n",
    "   # compute predictions\n",
    "   preds = model.predict(image_batch)\n",
    "   # append predicted labels\n",
    "   y_test_pred.append(np.argmax(preds, axis = - 1))\n",
    "    \n",
    "y_test = np.concatenate(y_test)\n",
    "y_test_pred = np.concatenate(y_test_pred)\n",
    "\n",
    "# labels = [ORD2SIGN.get(i).replace(' ', '_') for i in range(config[\"NUM_CLASSES\"])]\n",
    "labels = [ORD2SIGN.get(i).replace(' ', '_') for i in range(train_metadata.sign.nunique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3cedaf8-e34d-4ebd-b84b-cbf95b854ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprint_classification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m, in \u001b[0;36mprint_classification_report\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_classification_report\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Classification report for all signs\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     classification_report \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_val_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Round Data for better readability\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     classification_report \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(classification_report)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[1;32m   2196\u001b[0m     y_true,\n\u001b[1;32m   2197\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2205\u001b[0m ):\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m \n\u001b[1;32m   2208\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2313\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m/opt/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:106\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    109\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8238070a-77bb-43fa-901c-328ee023b738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "\n",
    "\n",
    "# Change figure size and increase dpi for better resolution\n",
    "plt.figure(figsize=(10,8), dpi=300)\n",
    "# Scale up the size of all text\n",
    "sns.set(font_scale = 0)\n",
    "\n",
    "# Plot Confusion Matrix using Seaborn heatmap()\n",
    "# Parameters:\n",
    "# fmt = 'd': show numbers as integers. \n",
    "ax = sns.heatmap(cm, annot=False,cmap=\"icefire\" )\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e114d9a-c6b9-4bd6-8e40-7c12af0f6329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prediction]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_preds = pd.DataFrame([ORD2SIGN[i] for i in y_test_pred[y_test != y_test_pred]],\n",
    "                               [ORD2SIGN[i] for i in y_test[y_test != y_test_pred]]).reset_index()\n",
    "\n",
    "incorrect_preds = incorrect_preds.rename(columns={'index':'prediction',0:'label'})\n",
    "print(len(incorrect_preds))\n",
    "incorrect_preds.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4bb45-d055-450d-a22d-e9d2b5209fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3038.388613,
   "end_time": "2023-03-27T14:39:37.370611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-27T13:48:58.981998",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03d6f570ff764870bb73ccfb8c6887af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49350bdfb80d4f00a698d195ad6cc3e3",
       "placeholder": "​",
       "style": "IPY_MODEL_6114b828351443dead1df1f805e5cfd7",
       "value": "100%"
      }
     },
     "07287dd36a6b457bab873107ef3a9a74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a3cb9fa235b4d3b9fe4729d0488ab41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0b6a231f62a24aae9fa0cbc3fb92820f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0bdd95bee39a4c0fba0d526a76e11ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5809fb0e32f44de489c4ffd133aed91d",
       "placeholder": "​",
       "style": "IPY_MODEL_ac638cb770cd4789a3ad5944574c0685",
       "value": " 1000/1000 [00:23&lt;00:00, 37.18it/s]"
      }
     },
     "0f47d306ae4c4968ae9578b5d3f96717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c0862516d904ef7a8308a72e5ae9f91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28320ac6793c47f69b05122f608c2d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0ef2e7de83043f5a1e56b8cbfdceb42",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b6a231f62a24aae9fa0cbc3fb92820f",
       "value": 1000
      }
     },
     "37eb2c935499475c89e659645e41c052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a30e5dd2b7e4e58b5f796dc56795f9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43441f82927941c183c36d4ba42c6839": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49104b8e9766498997f1c107709166cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49350bdfb80d4f00a698d195ad6cc3e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fb37e6c0a6849b0ae4fca96c98079d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50b095287b764b40bc01eecfb8e226ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "549182ad731149e196c24e0c65368459": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54d833de2b3e4368a09e8f2832ae582a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43441f82927941c183c36d4ba42c6839",
       "placeholder": "​",
       "style": "IPY_MODEL_549182ad731149e196c24e0c65368459",
       "value": " 42/42 [00:06&lt;00:00,  6.63it/s]"
      }
     },
     "5809fb0e32f44de489c4ffd133aed91d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b6ddc597476439b98e2a8572db415ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f60bd20e6054b8d9990b2b2804e19a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6114b828351443dead1df1f805e5cfd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a008f4929ca442296cb2159b02d1206": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "873e173a1a48496183ab1a8b2425b3f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89aab12028bb44f0a421c39e5407e2c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a757d761f004d7faf0e86f35c7cc2ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d56ea444a554a8d86255febcfa438ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f60bd20e6054b8d9990b2b2804e19a1",
       "placeholder": "​",
       "style": "IPY_MODEL_37eb2c935499475c89e659645e41c052",
       "value": "100%"
      }
     },
     "8e1a02523adf4a51928bd01fe6a016a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1b2e1be36c74ff5802bee0472d05a8c",
        "IPY_MODEL_974821174ce548f7ab78f2eb280a36bc",
        "IPY_MODEL_54d833de2b3e4368a09e8f2832ae582a"
       ],
       "layout": "IPY_MODEL_49104b8e9766498997f1c107709166cd"
      }
     },
     "974821174ce548f7ab78f2eb280a36bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fb37e6c0a6849b0ae4fca96c98079d3",
       "max": 42,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a3cb9fa235b4d3b9fe4729d0488ab41",
       "value": 42
      }
     },
     "97ebc5f11183491097eaa468c8f8d6ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fdf9f1a806d45d8afc6aa7674799d7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d56ea444a554a8d86255febcfa438ef",
        "IPY_MODEL_bc93196873734683876ec5f8b4b4c62c",
        "IPY_MODEL_d34a43c029834695b633aa4d4d941930"
       ],
       "layout": "IPY_MODEL_873e173a1a48496183ab1a8b2425b3f1"
      }
     },
     "a1b2e1be36c74ff5802bee0472d05a8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07287dd36a6b457bab873107ef3a9a74",
       "placeholder": "​",
       "style": "IPY_MODEL_fc0e155d7357432c9976cb2ac7c68b3a",
       "value": "100%"
      }
     },
     "ac638cb770cd4789a3ad5944574c0685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b0ba62ab3b254a6897d45bb7a753f044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b5005dde82d843e7a0b50cdf2669d881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d7996506467449ad9ba51cfb1e6db002",
        "IPY_MODEL_d0ff43d2109d482884de8add17da97e7",
        "IPY_MODEL_f9647d54b313481eaa72a3093a5dbc0a"
       ],
       "layout": "IPY_MODEL_1c0862516d904ef7a8308a72e5ae9f91"
      }
     },
     "bc93196873734683876ec5f8b4b4c62c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa12da626fe2424eb7a18e996ed1fb96",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b6ddc597476439b98e2a8572db415ee",
       "value": 10
      }
     },
     "d0ef2e7de83043f5a1e56b8cbfdceb42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0ff43d2109d482884de8add17da97e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a30e5dd2b7e4e58b5f796dc56795f9d",
       "max": 40,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_97ebc5f11183491097eaa468c8f8d6ba",
       "value": 40
      }
     },
     "d34a43c029834695b633aa4d4d941930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_50b095287b764b40bc01eecfb8e226ce",
       "placeholder": "​",
       "style": "IPY_MODEL_7a008f4929ca442296cb2159b02d1206",
       "value": " 10/10 [00:02&lt;00:00,  5.02it/s]"
      }
     },
     "d7996506467449ad9ba51cfb1e6db002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8ec2cab76c64079add86c4cd9e47463",
       "placeholder": "​",
       "style": "IPY_MODEL_0f47d306ae4c4968ae9578b5d3f96717",
       "value": "100%"
      }
     },
     "e8ec2cab76c64079add86c4cd9e47463": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edea63966eb74395b1ccf14ba9265099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_03d6f570ff764870bb73ccfb8c6887af",
        "IPY_MODEL_28320ac6793c47f69b05122f608c2d44",
        "IPY_MODEL_0bdd95bee39a4c0fba0d526a76e11ed7"
       ],
       "layout": "IPY_MODEL_89aab12028bb44f0a421c39e5407e2c2"
      }
     },
     "f9647d54b313481eaa72a3093a5dbc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a757d761f004d7faf0e86f35c7cc2ef",
       "placeholder": "​",
       "style": "IPY_MODEL_b0ba62ab3b254a6897d45bb7a753f044",
       "value": " 40/40 [00:07&lt;00:00,  4.48it/s]"
      }
     },
     "fa12da626fe2424eb7a18e996ed1fb96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc0e155d7357432c9976cb2ac7c68b3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
